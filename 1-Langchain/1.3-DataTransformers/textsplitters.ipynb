{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Published as a conference paper at ICLR 2015\\nNEURAL MACHINE TRANSLATION\\nBY JOINTLY LEARNING TO ALIGN AND TRANSLATE\\nDzmitry Bahdanau\\nJacobs University Bremen, Germany\\nKyungHyun Cho Yoshua Bengio ∗\\nUniversit´e de Montr´eal\\nABSTRACT\\nNeural machine translation is a recently proposed approach to machine transla-\\ntion. Unlike the traditional statistical machine translation, the neural machine\\ntranslation aims at building a single neural network that can be jointly tuned to\\nmaximize the translation performance. The models proposed recently for neu-\\nral machine translation often belong to a family of encoder–decoders and encode\\na source sentence into a ﬁxed-length vector from which a decoder generates a\\ntranslation. In this paper, we conjecture that the use of a ﬁxed-length vector is a\\nbottleneck in improving the performance of this basic encoder–decoder architec-\\nture, and propose to extend this by allowing a model to automatically (soft-)search\\nfor parts of a source sentence that are relevant to predicting a target word, without\\nhaving to form these parts as a hard segment explicitly. With this new approach,\\nwe achieve a translation performance comparable to the existing state-of-the-art\\nphrase-based system on the task of English-to-French translation. Furthermore,\\nqualitative analysis reveals that the (soft-)alignments found by the model agree\\nwell with our intuition.\\n1 I NTRODUCTION\\nNeural machine translation is a newly emerging approach to machine translation, recently proposed\\nby Kalchbrenner and Blunsom (2013), Sutskever et al. (2014) and Cho et al. (2014b). Unlike the\\ntraditional phrase-based translation system (see, e.g., Koehn et al., 2003) which consists of many\\nsmall sub-components that are tuned separately, neural machine translation attempts to build and\\ntrain a single, large neural network that reads a sentence and outputs a correct translation.\\nMost of the proposed neural machine translation models belong to a family of encoder–\\ndecoders (Sutskever et al., 2014; Cho et al., 2014a), with an encoder and a decoder for each lan-\\nguage, or involve a language-speciﬁc encoder applied to each sentence whose outputs are then com-\\npared (Hermann and Blunsom, 2014). An encoder neural network reads and encodes a source sen-\\ntence into a ﬁxed-length vector. A decoder then outputs a translation from the encoded vector. The\\nwhole encoder–decoder system, which consists of the encoder and the decoder for a language pair,\\nis jointly trained to maximize the probability of a correct translation given a source sentence.\\nA potential issue with this encoder–decoder approach is that a neural network needs to be able to\\ncompress all the necessary information of a source sentence into a ﬁxed-length vector. This may\\nmake it difﬁcult for the neural network to cope with long sentences, especially those that are longer\\nthan the sentences in the training corpus. Cho et al. (2014b) showed that indeed the performance of\\na basic encoder–decoder deteriorates rapidly as the length of an input sentence increases.\\nIn order to address this issue, we introduce an extension to the encoder–decoder model which learns\\nto align and translate jointly. Each time the proposed model generates a word in a translation, it\\n(soft-)searches for a set of positions in a source sentence where the most relevant information is\\nconcentrated. The model then predicts a target word based on the context vectors associated with\\nthese source positions and all the previous generated target words.\\n∗CIFAR Senior Fellow\\n1\\narXiv:1409.0473v7  [cs.CL]  19 May 2016'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='Published as a conference paper at ICLR 2015\\nThe most important distinguishing feature of this approach from the basic encoder–decoder is that\\nit does not attempt to encode a whole input sentence into a single ﬁxed-length vector. Instead, it en-\\ncodes the input sentence into a sequence of vectors and chooses a subset of these vectors adaptively\\nwhile decoding the translation. This frees a neural translation model from having to squash all the\\ninformation of a source sentence, regardless of its length, into a ﬁxed-length vector. We show this\\nallows a model to cope better with long sentences.\\nIn this paper, we show that the proposed approach of jointly learning to align and translate achieves\\nsigniﬁcantly improved translation performance over the basic encoder–decoder approach. The im-\\nprovement is more apparent with longer sentences, but can be observed with sentences of any\\nlength. On the task of English-to-French translation, the proposed approach achieves, with a single\\nmodel, a translation performance comparable, or close, to the conventional phrase-based system.\\nFurthermore, qualitative analysis reveals that the proposed model ﬁnds a linguistically plausible\\n(soft-)alignment between a source sentence and the corresponding target sentence.\\n2 B ACKGROUND : N EURAL MACHINE TRANSLATION\\nFrom a probabilistic perspective, translation is equivalent to ﬁnding a target sentence y that max-\\nimizes the conditional probability of y given a source sentence x, i.e., arg maxy p(y | x). In\\nneural machine translation, we ﬁt a parameterized model to maximize the conditional probability\\nof sentence pairs using a parallel training corpus. Once the conditional distribution is learned by a\\ntranslation model, given a source sentence a corresponding translation can be generated by searching\\nfor the sentence that maximizes the conditional probability.\\nRecently, a number of papers have proposed the use of neural networks to directly learn this condi-\\ntional distribution (see, e.g., Kalchbrenner and Blunsom, 2013; Cho et al., 2014a; Sutskever et al.,\\n2014; Cho et al., 2014b; Forcada and ˜Neco, 1997). This neural machine translation approach typ-\\nically consists of two components, the ﬁrst of which encodes a source sentence x and the second\\ndecodes to a target sentence y. For instance, two recurrent neural networks (RNN) were used by\\n(Cho et al., 2014a) and (Sutskever et al., 2014) to encode a variable-length source sentence into a\\nﬁxed-length vector and to decode the vector into a variable-length target sentence.\\nDespite being a quite new approach, neural machine translation has already shown promising results.\\nSutskever et al. (2014) reported that the neural machine translation based on RNNs with long short-\\nterm memory (LSTM) units achieves close to the state-of-the-art performance of the conventional\\nphrase-based machine translation system on an English-to-French translation task. 1 Adding neural\\ncomponents to existing translation systems, for instance, to score the phrase pairs in the phrase\\ntable (Cho et al., 2014a) or to re-rank candidate translations (Sutskever et al., 2014), has allowed to\\nsurpass the previous state-of-the-art performance level.\\n2.1 RNN E NCODER –DECODER\\nHere, we describe brieﬂy the underlying framework, called RNN Encoder–Decoder, proposed by\\nCho et al. (2014a) and Sutskever et al. (2014) upon which we build a novel architecture that learns\\nto align and translate simultaneously.\\nIn the Encoder–Decoder framework, an encoder reads the input sentence, a sequence of vectors\\nx = (x1,··· ,xTx ), into a vector c.2 The most common approach is to use an RNN such that\\nht = f(xt,ht−1) (1)\\nand\\nc= q({h1,··· ,hTx }) ,\\nwhere ht ∈Rn is a hidden state at time t, and c is a vector generated from the sequence of the\\nhidden states. f and qare some nonlinear functions. Sutskever et al. (2014) used an LSTM as f and\\nq({h1,··· ,hT }) =hT , for instance.\\n1 We mean by the state-of-the-art performance, the performance of the conventional phrase-based system\\nwithout using any neural network-based component.\\n2 Although most of the previous works (see, e.g., Choet al., 2014a; Sutskeveret al., 2014; Kalchbrenner and\\nBlunsom, 2013) used to encode a variable-length input sentence into a ﬁxed-length vector, it is not necessary,\\nand even it may be beneﬁcial to have a variable-length vector, as we will show later.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Published as a conference paper at ICLR 2015\\nThe decoder is often trained to predict the next word yt′ given the context vector c and all the\\npreviously predicted words {y1,··· ,yt′−1}. In other words, the decoder deﬁnes a probability over\\nthe translation y by decomposing the joint probability into the ordered conditionals:\\np(y) =\\nT∏\\nt=1\\np(yt |{y1,··· ,yt−1},c), (2)\\nwhere y =\\n(\\ny1,··· ,yTy\\n)\\n. With an RNN, each conditional probability is modeled as\\np(yt |{y1,··· ,yt−1},c) =g(yt−1,st,c), (3)\\nwhere gis a nonlinear, potentially multi-layered, function that outputs the probability ofyt, and st is\\nthe hidden state of the RNN. It should be noted that other architectures such as a hybrid of an RNN\\nand a de-convolutional neural network can be used (Kalchbrenner and Blunsom, 2013).\\n3 L EARNING TO ALIGN AND TRANSLATE\\nIn this section, we propose a novel architecture for neural machine translation. The new architecture\\nconsists of a bidirectional RNN as an encoder (Sec. 3.2) and a decoder that emulates searching\\nthrough a source sentence during decoding a translation (Sec. 3.1).\\n3.1 D ECODER : G ENERAL DESCRIPTION\\nx1 x2 x3 xT\\n+\\nαt,1\\nαt,2 αt,3\\nαt,T\\nyt-1 yt\\nh1 h2 h3 hT\\nh1 h2 h3 hT\\nst-1 st\\nFigure 1: The graphical illus-\\ntration of the proposed model\\ntrying to generate the t-th tar-\\nget word yt given a source\\nsentence (x1,x2,...,x T ).\\nIn a new model architecture, we deﬁne each conditional probability\\nin Eq. (2) as:\\np(yi|y1,...,y i−1,x) =g(yi−1,si,ci), (4)\\nwhere si is an RNN hidden state for time i, computed by\\nsi = f(si−1,yi−1,ci).\\nIt should be noted that unlike the existing encoder–decoder ap-\\nproach (see Eq. (2)), here the probability is conditioned on a distinct\\ncontext vector ci for each target word yi.\\nThe context vector ci depends on a sequence of annotations\\n(h1,··· ,hTx ) to which an encoder maps the input sentence. Each\\nannotation hi contains information about the whole input sequence\\nwith a strong focus on the parts surrounding the i-th word of the\\ninput sequence. We explain in detail how the annotations are com-\\nputed in the next section.\\nThe context vector ci is, then, computed as a weighted sum of these\\nannotations hi:\\nci =\\nTx∑\\nj=1\\nαijhj. (5)\\nThe weight αij of each annotation hj is computed by\\nαij = exp (eij)∑Tx\\nk=1 exp (eik)\\n, (6)\\nwhere\\neij = a(si−1,hj)\\nis an alignment model which scores how well the inputs around positionjand the output at position\\nimatch. The score is based on the RNN hidden state si−1 (just before emitting yi, Eq. (4)) and the\\nj-th annotation hj of the input sentence.\\nWe parametrize the alignment modelaas a feedforward neural network which is jointly trained with\\nall the other components of the proposed system. Note that unlike in traditional machine translation,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Published as a conference paper at ICLR 2015\\nthe alignment is not considered to be a latent variable. Instead, the alignment model directly com-\\nputes a soft alignment, which allows the gradient of the cost function to be backpropagated through.\\nThis gradient can be used to train the alignment model as well as the whole translation model jointly.\\nWe can understand the approach of taking a weighted sum of all the annotations as computing an\\nexpected annotation, where the expectation is over possible alignments. Letαij be a probability that\\nthe target word yi is aligned to, or translated from, a source word xj. Then, the i-th context vector\\nci is the expected annotation over all the annotations with probabilities αij.\\nThe probability αij, or its associated energy eij, reﬂects the importance of the annotation hj with\\nrespect to the previous hidden state si−1 in deciding the next state si and generating yi. Intuitively,\\nthis implements a mechanism of attention in the decoder. The decoder decides parts of the source\\nsentence to pay attention to. By letting the decoder have an attention mechanism, we relieve the\\nencoder from the burden of having to encode all information in the source sentence into a ﬁxed-\\nlength vector. With this new approach the information can be spread throughout the sequence of\\nannotations, which can be selectively retrieved by the decoder accordingly.\\n3.2 E NCODER : B IDIRECTIONAL RNN FOR ANNOTATING SEQUENCES\\nThe usual RNN, described in Eq. (1), reads an input sequence x in order starting from the ﬁrst\\nsymbol x1 to the last one xTx . However, in the proposed scheme, we would like the annotation\\nof each word to summarize not only the preceding words, but also the following words. Hence,\\nwe propose to use a bidirectional RNN (BiRNN, Schuster and Paliwal, 1997), which has been\\nsuccessfully used recently in speech recognition (see, e.g., Graves et al., 2013).\\nA BiRNN consists of forward and backward RNN’s. The forward RNN− →f reads the input sequence\\nas it is ordered (fromx1 to xTx ) and calculates a sequence offorward hidden states(− →h1,··· ,− →hTx ).\\nThe backward RNN ← −f reads the sequence in the reverse order (from xTx to x1), resulting in a\\nsequence of backward hidden states (← −h1,··· ,← −hTx ).\\nWe obtain an annotation for each word xj by concatenating the forward hidden state − →hj and the\\nbackward one ← −hj, i.e., hj =\\n[− →h⊤\\nj ; ← −h⊤\\nj\\n]⊤\\n. In this way, the annotation hj contains the summaries\\nof both the preceding words and the following words. Due to the tendency of RNNs to better\\nrepresent recent inputs, the annotation hj will be focused on the words around xj. This sequence\\nof annotations is used by the decoder and the alignment model later to compute the context vector\\n(Eqs. (5)–(6)).\\nSee Fig. 1 for the graphical illustration of the proposed model.\\n4 E XPERIMENT SETTINGS\\nWe evaluate the proposed approach on the task of English-to-French translation. We use the bilin-\\ngual, parallel corpora provided by ACL WMT ’14. 3 As a comparison, we also report the perfor-\\nmance of an RNN Encoder–Decoder which was proposed recently by Cho et al. (2014a). We use\\nthe same training procedures and the same dataset for both models.4\\n4.1 D ATASET\\nWMT ’14 contains the following English-French parallel corpora: Europarl (61M words), news\\ncommentary (5.5M), UN (421M) and two crawled corpora of 90M and 272.5M words respectively,\\ntotaling 850M words. Following the procedure described in Choet al. (2014a), we reduce the size of\\nthe combined corpus to have 348M words using the data selection method by Axelrodet al. (2011).5\\nWe do not use any monolingual data other than the mentioned parallel corpora, although it may be\\npossible to use a much larger monolingual corpus to pretrain an encoder. We concatenate news-test-\\n3 http://www.statmt.org/wmt14/translation-task.html\\n4 Implementations are available at https://github.com/lisa-groundhog/GroundHog.\\n5 Available online athttp://www-lium.univ-lemans.fr/˜schwenk/cslm_joint_paper/.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='Published as a conference paper at ICLR 2015\\n0 10 20 30 40 50 60\\nSentence length\\n0\\n5\\n10\\n15\\n20\\n25\\n30BLEU scoreRNNsearch-50\\nRNNsearch-30\\nRNNenc-50\\nRNNenc-30\\nFigure 2: The BLEU scores\\nof the generated translations\\non the test set with respect\\nto the lengths of the sen-\\ntences. The results are on\\nthe full test set which in-\\ncludes sentences having un-\\nknown words to the models.\\n2012 and news-test-2013 to make a development (validation) set, and evaluate the models on the test\\nset (news-test-2014) from WMT ’14, which consists of 3003 sentences not present in the training\\ndata.\\nAfter a usual tokenization 6, we use a shortlist of 30,000 most frequent words in each language to\\ntrain our models. Any word not included in the shortlist is mapped to a special token ( [UNK]). We\\ndo not apply any other special preprocessing, such as lowercasing or stemming, to the data.\\n4.2 M ODELS\\nWe train two types of models. The ﬁrst one is an RNN Encoder–Decoder (RNNencdec, Cho et al.,\\n2014a), and the other is the proposed model, to which we refer as RNNsearch. We train each model\\ntwice: ﬁrst with the sentences of length up to 30 words (RNNencdec-30, RNNsearch-30) and then\\nwith the sentences of length up to 50 word (RNNencdec-50, RNNsearch-50).\\nThe encoder and decoder of the RNNencdec have 1000 hidden units each. 7 The encoder of the\\nRNNsearch consists of forward and backward recurrent neural networks (RNN) each having 1000\\nhidden units. Its decoder has 1000 hidden units. In both cases, we use a multilayer network with a\\nsingle maxout (Goodfellow et al., 2013) hidden layer to compute the conditional probability of each\\ntarget word (Pascanu et al., 2014).\\nWe use a minibatch stochastic gradient descent (SGD) algorithm together with Adadelta (Zeiler,\\n2012) to train each model. Each SGD update direction is computed using a minibatch of 80 sen-\\ntences. We trained each model for approximately 5 days.\\nOnce a model is trained, we use a beam search to ﬁnd a translation that approximately maximizes the\\nconditional probability (see, e.g., Graves, 2012; Boulanger-Lewandowski et al., 2013). Sutskever\\net al. (2014) used this approach to generate translations from their neural machine translation model.\\nFor more details on the architectures of the models and training procedure used in the experiments,\\nsee Appendices A and B.\\n5 R ESULTS\\n5.1 Q UANTITATIVE RESULTS\\nIn Table 1, we list the translation performances measured in BLEU score. It is clear from the table\\nthat in all the cases, the proposed RNNsearch outperforms the conventional RNNencdec. More\\nimportantly, the performance of the RNNsearch is as high as that of the conventional phrase-based\\ntranslation system (Moses), when only the sentences consisting of known words are considered.\\nThis is a signiﬁcant achievement, considering that Moses uses a separate monolingual corpus (418M\\nwords) in addition to the parallel corpora we used to train the RNNsearch and RNNencdec.\\n6 We used the tokenization script from the open-source machine translation package, Moses.\\n7 In this paper, by a ’hidden unit’, we always mean the gated hidden unit (see Appendix A.1.1).\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Published as a conference paper at ICLR 2015\\nThe\\nagreement\\non\\nthe\\nEuropean\\nEconomic\\nArea\\nwas\\nsigned\\nin\\nAugust\\n1992\\n.\\n<end>\\nL\\'\\naccord\\nsur\\nla\\nzone\\néconomique\\neuropéenne\\na\\nété\\nsigné\\nen\\naoût\\n1992\\n.\\n<end>\\nIt\\nshould\\nbe\\nnoted\\nthat\\nthe\\nmarine\\nenvironment\\nis\\nthe\\nleast\\nknown\\nof\\nenvironments\\n.\\n<end>\\nIl\\nconvient\\nde\\nnoter\\nque\\nl\\'\\nenvironnement\\nmarin\\nest\\nle\\nmoins\\nconnu\\nde\\nl\\'\\nenvironnement\\n.\\n<end>\\n(a) (b)\\nDestruction\\nof\\nthe\\nequipment\\nmeans\\nthat\\nSyria\\ncan\\nno\\nlonger\\nproduce\\nnew\\nchemical\\nweapons\\n.\\n<end>\\nLa\\ndestruction\\nde\\nl\\'\\néquipement\\nsignifie\\nque\\nla\\nSyrie\\nne\\npeut\\nplus\\nproduire\\nde\\nnouvelles\\narmes\\nchimiques\\n.\\n<end>\\n\"\\nThis\\nwill\\nchange\\nmy\\nfuture\\nwith\\nmy\\nfamily\\n,\\n\"\\nthe\\nman\\nsaid\\n.\\n<end>\\n\"\\nCela\\nva\\nchanger\\nmon\\navenir\\navec\\nma\\nfamille\\n\"\\n,\\na\\ndit\\nl\\'\\nhomme\\n.\\n<end>\\n(c) (d)\\nFigure 3: Four sample alignments found by RNNsearch-50. The x-axis and y-axis of each plot\\ncorrespond to the words in the source sentence (English) and the generated translation (French),\\nrespectively. Each pixel shows the weight αij of the annotation of the j-th source word for the i-th\\ntarget word (see Eq. (6)), in grayscale ( 0: black, 1: white). (a) an arbitrary sentence. (b–d) three\\nrandomly selected samples among the sentences without any unknown words and of length between\\n10 and 20 words from the test set.\\nOne of the motivations behind the proposed approach was the use of a ﬁxed-length context vector\\nin the basic encoder–decoder approach. We conjectured that this limitation may make the basic\\nencoder–decoder approach to underperform with long sentences. In Fig. 2, we see that the perfor-\\nmance of RNNencdec dramatically drops as the length of the sentences increases. On the other hand,\\nboth RNNsearch-30 and RNNsearch-50 are more robust to the length of the sentences. RNNsearch-\\n50, especially, shows no performance deterioration even with sentences of length 50 or more. This\\nsuperiority of the proposed model over the basic encoder–decoder is further conﬁrmed by the fact\\nthat the RNNsearch-30 even outperforms RNNencdec-50 (see Table 1).\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Published as a conference paper at ICLR 2015\\nModel All No UNK◦\\nRNNencdec-30 13.93 24.19\\nRNNsearch-30 21.50 31.44\\nRNNencdec-50 17.82 26.71\\nRNNsearch-50 26.75 34.16\\nRNNsearch-50⋆ 28.45 36.15\\nMoses 33.30 35.63\\nTable 1: BLEU scores of the trained models com-\\nputed on the test set. The second and third columns\\nshow respectively the scores on all the sentences and,\\non the sentences without any unknown word in them-\\nselves and in the reference translations. Note that\\nRNNsearch-50⋆ was trained much longer until the\\nperformance on the development set stopped improv-\\ning. (◦) We disallowed the models to generate [UNK]\\ntokens when only the sentences having no unknown\\nwords were evaluated (last column).\\n5.2 Q UALITATIVE ANALYSIS\\n5.2.1 A LIGNMENT\\nThe proposed approach provides an intuitive way to inspect the (soft-)alignment between the words\\nin a generated translation and those in a source sentence. This is done by visualizing the annotation\\nweights αij from Eq. (6), as in Fig. 3. Each row of a matrix in each plot indicates the weights\\nassociated with the annotations. From this we see which positions in the source sentence were\\nconsidered more important when generating the target word.\\nWe can see from the alignments in Fig. 3 that the alignment of words between English and French\\nis largely monotonic. We see strong weights along the diagonal of each matrix. However, we also\\nobserve a number of non-trivial, non-monotonic alignments. Adjectives and nouns are typically\\nordered differently between French and English, and we see an example in Fig. 3 (a). From this\\nﬁgure, we see that the model correctly translates a phrase [European Economic Area] into [zone\\n´economique europ ´een]. The RNNsearch was able to correctly align [zone] with [Area], jumping\\nover the two words ([European] and [Economic]), and then looked one word back at a time to\\ncomplete the whole phrase [zone ´economique europ´eenne].\\nThe strength of the soft-alignment, opposed to a hard-alignment, is evident, for instance, from\\nFig. 3 (d). Consider the source phrase [the man] which was translated into [l’ homme]. Any hard\\nalignment will map [the] to [l’] and [man] to [homme]. This is not helpful for translation, as one\\nmust consider the word following [the] to determine whether it should be translated into [le], [la],\\n[les] or [l’]. Our soft-alignment solves this issue naturally by letting the model look at both [the] and\\n[man], and in this example, we see that the model was able to correctly translate [the] into [l’]. We\\nobserve similar behaviors in all the presented cases in Fig. 3. An additional beneﬁt of the soft align-\\nment is that it naturally deals with source and target phrases of different lengths, without requiring a\\ncounter-intuitive way of mapping some words to or from nowhere ([NULL]) (see, e.g., Chapters 4\\nand 5 of Koehn, 2010).\\n5.2.2 L ONG SENTENCES\\nAs clearly visible from Fig. 2 the proposed model (RNNsearch) is much better than the conventional\\nmodel (RNNencdec) at translating long sentences. This is likely due to the fact that the RNNsearch\\ndoes not require encoding a long sentence into a ﬁxed-length vector perfectly, but only accurately\\nencoding the parts of the input sentence that surround a particular word.\\nAs an example, consider this source sentence from the test set:\\nAn admitting privilege is the right of a doctor to admit a patient to a hospital or\\na medical centre to carry out a diagnosis or a procedure, based on his status as a\\nhealth care worker at a hospital.\\nThe RNNencdec-50 translated this sentence into:\\nUn privil `ege d’admission est le droit d’un m ´edecin de reconna ˆıtre un patient `a\\nl’hˆopital ou un centre m ´edical d’un diagnostic ou de prendre un diagnostic en\\nfonction de son ´etat de sant´e.\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Published as a conference paper at ICLR 2015\\nThe RNNencdec-50 correctly translated the source sentence until [a medical center]. However, from\\nthere on (underlined), it deviated from the original meaning of the source sentence. For instance, it\\nreplaced [based on his status as a health care worker at a hospital] in the source sentence with [en\\nfonction de son ´etat de sant´e] (“based on his state of health”).\\nOn the other hand, the RNNsearch-50 generated the following correct translation, preserving the\\nwhole meaning of the input sentence without omitting any details:\\nUn privil `ege d’admission est le droit d’un m ´edecin d’admettre un patient `a un\\nhˆopital ou un centre m´edical pour effectuer un diagnostic ou une proc´edure, selon\\nson statut de travailleur des soins de sant´e `a l’hˆopital.\\nLet us consider another sentence from the test set:\\nThis kind of experience is part of Disney’s efforts to ”extend the lifetime of its\\nseries and build new relationships with audiences via digital platforms that are\\nbecoming ever more important, ”he added.\\nThe translation by the RNNencdec-50 is\\nCe type d’exp´erience fait partie des initiatives du Disney pour ”prolonger la dur´ee\\nde vie de ses nouvelles et de d´evelopper des liens avec leslecteurs num´eriques qui\\ndeviennent plus complexes.\\nAs with the previous example, the RNNencdec began deviating from the actual meaning of the\\nsource sentence after generating approximately 30 words (see the underlined phrase). After that\\npoint, the quality of the translation deteriorates, with basic mistakes such as the lack of a closing\\nquotation mark.\\nAgain, the RNNsearch-50 was able to translate this long sentence correctly:\\nCe genre d’exp´erience fait partie des efforts de Disney pour ”prolonger la dur ´ee\\nde vie de ses s ´eries et cr ´eer de nouvelles relations avec des publics via des\\nplateformes num´eriques de plus en plus importantes”, a-t-il ajout´e.\\nIn conjunction with the quantitative results presented already, these qualitative observations con-\\nﬁrm our hypotheses that the RNNsearch architecture enables far more reliable translation of long\\nsentences than the standard RNNencdec model.\\nIn Appendix C, we provide a few more sample translations of long source sentences generated by\\nthe RNNencdec-50, RNNsearch-50 and Google Translate along with the reference translations.\\n6 R ELATED WORK\\n6.1 L EARNING TO ALIGN\\nA similar approach of aligning an output symbol with an input symbol was proposed recently by\\nGraves (2013) in the context of handwriting synthesis. Handwriting synthesis is a task where the\\nmodel is asked to generate handwriting of a given sequence of characters. In his work, he used a\\nmixture of Gaussian kernels to compute the weights of the annotations, where the location, width\\nand mixture coefﬁcient of each kernel was predicted from an alignment model. More speciﬁcally,\\nhis alignment was restricted to predict the location such that the location increases monotonically.\\nThe main difference from our approach is that, in (Graves, 2013), the modes of the weights of the\\nannotations only move in one direction. In the context of machine translation, this is a severe limi-\\ntation, as (long-distance) reordering is often needed to generate a grammatically correct translation\\n(for instance, English-to-German).\\nOur approach, on the other hand, requires computing the annotation weight of every word in the\\nsource sentence for each word in the translation. This drawback is not severe with the task of\\ntranslation in which most of input and output sentences are only 15–40 words. However, this may\\nlimit the applicability of the proposed scheme to other tasks.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='Published as a conference paper at ICLR 2015\\n6.2 N EURAL NETWORKS FOR MACHINE TRANSLATION\\nSince Bengio et al. (2003) introduced a neural probabilistic language model which uses a neural net-\\nwork to model the conditional probability of a word given a ﬁxed number of the preceding words,\\nneural networks have widely been used in machine translation. However, the role of neural net-\\nworks has been largely limited to simply providing a single feature to an existing statistical machine\\ntranslation system or to re-rank a list of candidate translations provided by an existing system.\\nFor instance, Schwenk (2012) proposed using a feedforward neural network to compute the score of\\na pair of source and target phrases and to use the score as an additional feature in the phrase-based\\nstatistical machine translation system. More recently, Kalchbrenner and Blunsom (2013) and Devlin\\net al. (2014) reported the successful use of the neural networks as a sub-component of the existing\\ntranslation system. Traditionally, a neural network trained as a target-side language model has been\\nused to rescore or rerank a list of candidate translations (see, e.g., Schwenk et al., 2006).\\nAlthough the above approaches were shown to improve the translation performance over the state-\\nof-the-art machine translation systems, we are more interested in a more ambitious objective of\\ndesigning a completely new translation system based on neural networks. The neural machine trans-\\nlation approach we consider in this paper is therefore a radical departure from these earlier works.\\nRather than using a neural network as a part of the existing system, our model works on its own and\\ngenerates a translation from a source sentence directly.\\n7 C ONCLUSION\\nThe conventional approach to neural machine translation, called an encoder–decoder approach, en-\\ncodes a whole input sentence into a ﬁxed-length vector from which a translation will be decoded.\\nWe conjectured that the use of a ﬁxed-length context vector is problematic for translating long sen-\\ntences, based on a recent empirical study reported by Cho et al. (2014b) and Pouget-Abadie et al.\\n(2014).\\nIn this paper, we proposed a novel architecture that addresses this issue. We extended the basic\\nencoder–decoder by letting a model (soft-)search for a set of input words, or their annotations com-\\nputed by an encoder, when generating each target word. This frees the model from having to encode\\na whole source sentence into a ﬁxed-length vector, and also lets the model focus only on information\\nrelevant to the generation of the next target word. This has a major positive impact on the ability\\nof the neural machine translation system to yield good results on longer sentences. Unlike with\\nthe traditional machine translation systems, all of the pieces of the translation system, including\\nthe alignment mechanism, are jointly trained towards a better log-probability of producing correct\\ntranslations.\\nWe tested the proposed model, called RNNsearch, on the task of English-to-French translation. The\\nexperiment revealed that the proposed RNNsearch outperforms the conventional encoder–decoder\\nmodel (RNNencdec) signiﬁcantly, regardless of the sentence length and that it is much more ro-\\nbust to the length of a source sentence. From the qualitative analysis where we investigated the\\n(soft-)alignment generated by the RNNsearch, we were able to conclude that the model can cor-\\nrectly align each target word with the relevant words, or their annotations, in the source sentence as\\nit generated a correct translation.\\nPerhaps more importantly, the proposed approach achieved a translation performance comparable to\\nthe existing phrase-based statistical machine translation. It is a striking result, considering that the\\nproposed architecture, or the whole family of neural machine translation, has only been proposed\\nas recently as this year. We believe the architecture proposed here is a promising step toward better\\nmachine translation and a better understanding of natural languages in general.\\nOne of challenges left for the future is to better handle unknown, or rare words. This will be required\\nfor the model to be more widely used and to match the performance of current state-of-the-art\\nmachine translation systems in all contexts.\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Published as a conference paper at ICLR 2015\\nACKNOWLEDGMENTS\\nThe authors would like to thank the developers of Theano (Bergstra et al., 2010; Bastien et al.,\\n2012). We acknowledge the support of the following agencies for research funding and computing\\nsupport: NSERC, Calcul Qu ´ebec, Compute Canada, the Canada Research Chairs and CIFAR. Bah-\\ndanau thanks the support from Planet Intelligent Systems GmbH. We also thank Felix Hill, Bart van\\nMerri´enboer, Jean Pouget-Abadie, Coline Devin and Tae-Ho Kim.\\nREFERENCES\\nAxelrod, A., He, X., and Gao, J. (2011). Domain adaptation via pseudo in-domain data selection.\\nIn Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing\\n(EMNLP), pages 355–362. Association for Computational Linguistics.\\nBastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N.,\\nand Bengio, Y . (2012). Theano: new features and speed improvements. Deep Learning and\\nUnsupervised Feature Learning NIPS 2012 Workshop.\\nBengio, Y ., Simard, P., and Frasconi, P. (1994). Learning long-term dependencies with gradient\\ndescent is difﬁcult. IEEE Transactions on Neural Networks, 5(2), 157–166.\\nBengio, Y ., Ducharme, R., Vincent, P., and Janvin, C. (2003). A neural probabilistic language model.\\nJ. Mach. Learn. Res., 3, 1137–1155.\\nBergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-\\nFarley, D., and Bengio, Y . (2010). Theano: a CPU and GPU math expression compiler. In\\nProceedings of the Python for Scientiﬁc Computing Conference (SciPy). Oral Presentation.\\nBoulanger-Lewandowski, N., Bengio, Y ., and Vincent, P. (2013). Audio chord recognition with\\nrecurrent neural networks. In ISMIR.\\nCho, K., van Merrienboer, B., Gulcehre, C., Bougares, F., Schwenk, H., and Bengio, Y . (2014a).\\nLearning phrase representations using RNN encoder-decoder for statistical machine translation.\\nIn Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014) . to\\nappear.\\nCho, K., van Merri ¨enboer, B., Bahdanau, D., and Bengio, Y . (2014b). On the properties of neural\\nmachine translation: Encoder–Decoder approaches. In Eighth Workshop on Syntax, Semantics\\nand Structure in Statistical Translation. to appear.\\nDevlin, J., Zbib, R., Huang, Z., Lamar, T., Schwartz, R., and Makhoul, J. (2014). Fast and robust\\nneural network joint models for statistical machine translation. In Association for Computational\\nLinguistics.\\nForcada, M. L. and ˜Neco, R. P. (1997). Recursive hetero-associative memories for translation. In\\nJ. Mira, R. Moreno-D´ıaz, and J. Cabestany, editors,Biological and Artiﬁcial Computation: From\\nNeuroscience to Technology, volume 1240 ofLecture Notes in Computer Science, pages 453–462.\\nSpringer Berlin Heidelberg.\\nGoodfellow, I., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y . (2013). Maxout net-\\nworks. In Proceedings of The 30th International Conference on Machine Learning, pages 1319–\\n1327.\\nGraves, A. (2012). Sequence transduction with recurrent neural networks. In Proceedings of the\\n29th International Conference on Machine Learning (ICML 2012).\\nGraves, A. (2013). Generating sequences with recurrent neural networks. arXiv:1308.0850\\n[cs.NE].\\nGraves, A., Jaitly, N., and Mohamed, A.-R. (2013). Hybrid speech recognition with deep bidirec-\\ntional LSTM. In Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Work-\\nshop on, pages 273–278.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='Published as a conference paper at ICLR 2015\\nHermann, K. and Blunsom, P. (2014). Multilingual distributed representations without word align-\\nment. In Proceedings of the Second International Conference on Learning Representations (ICLR\\n2014).\\nHochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut\\nf¨ur Informatik, Lehrstuhl Prof. Brauer, Technische Universit¨at M¨unchen.\\nHochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9(8),\\n1735–1780.\\nKalchbrenner, N. and Blunsom, P. (2013). Recurrent continuous translation models. InProceedings\\nof the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pages\\n1700–1709. Association for Computational Linguistics.\\nKoehn, P. (2010). Statistical Machine Translation. Cambridge University Press, New York, NY ,\\nUSA.\\nKoehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase-based translation. In Proceedings\\nof the 2003 Conference of the North American Chapter of the Association for Computational\\nLinguistics on Human Language Technology - Volume 1, NAACL ’03, pages 48–54, Stroudsburg,\\nPA, USA. Association for Computational Linguistics.\\nPascanu, R., Mikolov, T., and Bengio, Y . (2013a). On the difﬁculty of training recurrent neural\\nnetworks. In ICML’2013.\\nPascanu, R., Mikolov, T., and Bengio, Y . (2013b). On the difﬁculty of training recurrent neural\\nnetworks. In Proceedings of the 30th International Conference on Machine Learning (ICML\\n2013).\\nPascanu, R., Gulcehre, C., Cho, K., and Bengio, Y . (2014). How to construct deep recurrent neural\\nnetworks. In Proceedings of the Second International Conference on Learning Representations\\n(ICLR 2014).\\nPouget-Abadie, J., Bahdanau, D., van Merri¨enboer, B., Cho, K., and Bengio, Y . (2014). Overcoming\\nthe curse of sentence length for neural machine translation using automatic segmentation. In\\nEighth Workshop on Syntax, Semantics and Structure in Statistical Translation. to appear.\\nSchuster, M. and Paliwal, K. K. (1997). Bidirectional recurrent neural networks. Signal Processing,\\nIEEE Transactions on, 45(11), 2673–2681.\\nSchwenk, H. (2012). Continuous space translation models for phrase-based statistical machine\\ntranslation. In M. Kay and C. Boitet, editors,Proceedings of the 24th International Conference on\\nComputational Linguistics (COLIN), pages 1071–1080. Indian Institute of Technology Bombay.\\nSchwenk, H., Dchelotte, D., and Gauvain, J.-L. (2006). Continuous space language models for\\nstatistical machine translation. In Proceedings of the COLING/ACL on Main conference poster\\nsessions, pages 723–730. Association for Computational Linguistics.\\nSutskever, I., Vinyals, O., and Le, Q. (2014). Sequence to sequence learning with neural networks.\\nIn Advances in Neural Information Processing Systems (NIPS 2014).\\nZeiler, M. D. (2012). ADADELTA: An adaptive learning rate method. arXiv:1212.5701\\n[cs.LG].\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='Published as a conference paper at ICLR 2015\\nA M ODEL ARCHITECTURE\\nA.1 A RCHITECTURAL CHOICES\\nThe proposed scheme in Section 3 is a general framework where one can freely deﬁne, for instance,\\nthe activation functions f of recurrent neural networks (RNN) and the alignment model a. Here, we\\ndescribe the choices we made for the experiments in this paper.\\nA.1.1 R ECURRENT NEURAL NETWORK\\nFor the activation function f of an RNN, we use the gated hidden unit recently proposed by Cho\\net al. (2014a). The gated hidden unit is an alternative to the conventional simple units such as an\\nelement-wise tanh. This gated unit is similar to a long short-term memory (LSTM) unit proposed\\nearlier by Hochreiter and Schmidhuber (1997), sharing with it the ability to better model and learn\\nlong-term dependencies. This is made possible by having computation paths in the unfolded RNN\\nfor which the product of derivatives is close to 1. These paths allow gradients to ﬂow backward\\neasily without suffering too much from the vanishing effect (Hochreiter, 1991; Bengio et al., 1994;\\nPascanu et al., 2013a). It is therefore possible to use LSTM units instead of the gated hidden unit\\ndescribed here, as was done in a similar context by Sutskever et al. (2014).\\nThe new state si of the RNN employing ngated hidden units8 is computed by\\nsi = f(si−1,yi−1,ci) = (1−zi) ◦si−1 + zi ◦˜si,\\nwhere ◦is an element-wise multiplication, and zi is the output of the update gates (see below). The\\nproposed updated state ˜si is computed by\\n˜si = tanh (We(yi−1) +U[ri ◦si−1] +Cci) ,\\nwhere e(yi−1) ∈Rm is an m-dimensional embedding of a word yi−1, and ri is the output of the\\nreset gates (see below). When yi is represented as a 1-of-K vector, e(yi) is simply a column of an\\nembedding matrix E ∈Rm×K. Whenever possible, we omit bias terms to make the equations less\\ncluttered.\\nThe update gates zi allow each hidden unit to maintain its previous activation, and the reset gatesri\\ncontrol how much and what information from the previous state should be reset. We compute them\\nby\\nzi = σ(Wze(yi−1) +Uzsi−1 + Czci) ,\\nri = σ(Wre(yi−1) +Ursi−1 + Crci) ,\\nwhere σ(·) is a logistic sigmoid function.\\nAt each step of the decoder, we compute the output probability (Eq. (4)) as a multi-layered func-\\ntion (Pascanu et al., 2014). We use a single hidden layer of maxout units (Goodfellow et al., 2013)\\nand normalize the output probabilities (one for each word) with a softmax function (see Eq. (6)).\\nA.1.2 A LIGNMENT MODEL\\nThe alignment model should be designed considering that the model needs to be evaluated Tx ×Ty\\ntimes for each sentence pair of lengths Tx and Ty. In order to reduce computation, we use a single-\\nlayer multilayer perceptron such that\\na(si−1,hj) =v⊤\\na tanh (Wasi−1 + Uahj) ,\\nwhere Wa ∈Rn×n,Ua ∈Rn×2n and va ∈Rn are the weight matrices. Since Uahj does not\\ndepend on i, we can pre-compute it in advance to minimize the computational cost.\\n8 Here, we show the formula of the decoder. The same formula can be used in the encoder by simply\\nignoring the context vector ci and the related terms.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Published as a conference paper at ICLR 2015\\nA.2 D ETAILED DESCRIPTION OF THE MODEL\\nA.2.1 E NCODER\\nIn this section, we describe in detail the architecture of the proposed model (RNNsearch) used in the\\nexperiments (see Sec. 4–5). From here on, we omit all bias terms in order to increase readability.\\nThe model takes a source sentence of 1-of-K coded word vectors as input\\nx = (x1,...,x Tx ), xi ∈RKx\\nand outputs a translated sentence of 1-of-K coded word vectors\\ny = (y1,...,y Ty ), yi ∈RKy ,\\nwhere Kx and Ky are the vocabulary sizes of source and target languages, respectively. Tx and Ty\\nrespectively denote the lengths of source and target sentences.\\nFirst, the forward states of the bidirectional recurrent neural network (BiRNN) are computed:\\n− →hi =\\n{\\n(1 −− →zi) ◦− →hi−1 + − →zi ◦− →hi , if i> 0\\n0 , if i= 0\\nwhere\\n− →hi = tanh\\n(− →WExi + − →U\\n[− →ri ◦− →hi−1\\n])\\n− →zi =σ\\n(− →WzExi + − →Uz\\n− →hi−1\\n)\\n− →ri =σ\\n(− →WrExi + − →Ur\\n− →hi−1\\n)\\n.\\nE ∈Rm×Kx is the word embedding matrix. − →W,− →Wz,− →Wr ∈Rn×m, − →U, − →Uz,− →Ur ∈Rn×n are\\nweight matrices. mand nare the word embedding dimensionality and the number of hidden units,\\nrespectively. σ(·) is as usual a logistic sigmoid function.\\nThe backward states (← −h1,··· ,← −hTx ) are computed similarly. We share the word embedding matrix\\nEbetween the forward and backward RNNs, unlike the weight matrices.\\nWe concatenate the forward and backward states to to obtain the annotations (h1,h2,··· ,hTx ),\\nwhere\\nhi =\\n[ − →hi← −hi\\n]\\n(7)\\nA.2.2 D ECODER\\nThe hidden state si of the decoder given the annotations from the encoder is computed by\\nsi =(1 −zi) ◦si−1 + zi ◦˜si,\\nwhere\\n˜si = tanh (WEyi−1 + U[ri ◦si−1] +Cci)\\nzi =σ(WzEyi−1 + Uzsi−1 + Czci)\\nri =σ(WrEyi−1 + Ursi−1 + Crci)\\nEis the word embedding matrix for the target language. W,Wz,Wr ∈Rn×m, U,Uz,Ur ∈Rn×n,\\nand C,Cz,Cr ∈ Rn×2n are weights. Again, m and n are the word embedding dimensionality\\nand the number of hidden units, respectively. The initial hidden state s0 is computed by s0 =\\ntanh\\n(\\nWs\\n← −h1\\n)\\n,where Ws ∈Rn×n.\\nThe context vector ci are recomputed at each step by the alignment model:\\nci =\\nTx∑\\nj=1\\nαijhj,\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='Published as a conference paper at ICLR 2015\\nModel Updates (×105) Epochs Hours GPU Train NLL Dev. NLL\\nRNNenc-30 8.46 6.4 109 TITAN BLACK 28.1 53.0\\nRNNenc-50 6.00 4.5 108 Quadro K-6000 44.0 43.6\\nRNNsearch-30 4.71 3.6 113 TITAN BLACK 26.7 47.2\\nRNNsearch-50 2.88 2.2 111 Quadro K-6000 40.7 38.1\\nRNNsearch-50⋆ 6.67 5.0 252 Quadro K-6000 36.7 35.2\\nTable 2: Learning statistics and relevant information. Each update corresponds to updating the\\nparameters once using a single minibatch. One epoch is one pass through the training set. NLL is\\nthe average conditional log-probabilities of the sentences in either the training set or the development\\nset. Note that the lengths of the sentences differ.\\nwhere\\nαij = exp (eij)∑Tx\\nk=1 exp (eik)\\neij =v⊤\\na tanh (Wasi−1 + Uahj) ,\\nand hj is the j-th annotation in the source sentence (see Eq. (7)). va ∈Rn′\\n,Wa ∈Rn′×n and\\nUa ∈Rn′×2n are weight matrices. Note that the model becomes RNN Encoder–Decoder (Cho\\net al., 2014a), if we ﬁx ci to − →hTx .\\nWith the decoder statesi−1, the contextci and the last generated wordyi−1, we deﬁne the probability\\nof a target word yi as\\np(yi|si,yi−1,ci) ∝exp\\n(\\ny⊤\\ni Woti\\n)\\n,\\nwhere\\nti =\\n[\\nmax\\n{˜ti,2j−1,˜ti,2j\\n}]⊤\\nj=1,...,l\\nand ˜ti,k is the k-th element of a vector ˜ti which is computed by\\n˜ti =Uosi−1 + VoEyi−1 + Coci.\\nWo ∈RKy×l, Uo ∈R2l×n, Vo ∈R2l×m and Co ∈R2l×2n are weight matrices. This can be under-\\nstood as having a deep output (Pascanu et al., 2014) with a single maxout hidden layer (Goodfellow\\net al., 2013).\\nA.2.3 M ODEL SIZE\\nFor all the models used in this paper, the size of a hidden layer n is 1000, the word embedding\\ndimensionality mis 620 and the size of the maxout hidden layer in the deep output l is 500. The\\nnumber of hidden units in the alignment model n′is 1000.\\nB T RAINING PROCEDURE\\nB.1 P ARAMETER INITIALIZATION\\nWe initialized the recurrent weight matrices U,Uz,Ur,← −U, ← −Uz,← −Ur,− →U, − →Uz and − →Ur as random or-\\nthogonal matrices. For Wa and Ua, we initialized them by sampling each element from the Gaussian\\ndistribution of mean 0 and variance 0.0012. All the elements of Va and all the bias vectors were ini-\\ntialized to zero. Any other weight matrix was initialized by sampling from the Gaussian distribution\\nof mean 0 and variance 0.012.\\nB.2 T RAINING\\nWe used the stochastic gradient descent (SGD) algorithm. Adadelta (Zeiler, 2012) was used to\\nautomatically adapt the learning rate of each parameter ( ϵ = 10−6 and ρ = 0.95). We explicitly\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='Published as a conference paper at ICLR 2015\\nnormalized the L2-norm of the gradient of the cost function each time to be at most a predeﬁned\\nthreshold of 1, when the norm was larger than the threshold (Pascanu et al., 2013b). Each SGD\\nupdate direction was computed with a minibatch of 80 sentences.\\nAt each update our implementation requires time proportional to the length of the longest sentence in\\na minibatch. Hence, to minimize the waste of computation, before every 20-th update, we retrieved\\n1600 sentence pairs, sorted them according to the lengths and split them into 20 minibatches. The\\ntraining data was shufﬂed once before training and was traversed sequentially in this manner.\\nIn Tables 2 we present the statistics related to training all the models used in the experiments.\\nC T RANSLATIONS OF LONG SENTENCES\\nSource An admitting privilege is the right of a doctor to admit a patient to a hospital or a medical centre\\nto carry out a diagnosis or a procedure, based on his status as a health care worker at a hospital.\\nReference Le privil`ege d’admission est le droit d’un m´edecin, en vertu de son statut de membre soignant\\nd’un hˆopital, d’admettre un patient dans un h ˆopital ou un centre m ´edical aﬁn d’y d ´elivrer un\\ndiagnostic ou un traitement.\\nRNNenc-50 Un privil`ege d’admission est le droit d’un m´edecin de reconnaˆıtre un patient `a l’hˆopital ou un\\ncentre m´edical d’un diagnostic ou de prendre un diagnostic en fonction de son ´etat de sant´e.\\nRNNsearch-50 Un privil`ege d’admission est le droit d’un m ´edecin d’admettre un patient `a un h ˆopital ou un\\ncentre m´edical pour effectuer un diagnostic ou une proc´edure, selon son statut de travailleur des\\nsoins de sant´e `a l’hˆopital.\\nGoogle\\nTranslate\\nUn privil`ege admettre est le droit d’un m ´edecin d’admettre un patient dans un h ˆopital ou un\\ncentre m ´edical pour effectuer un diagnostic ou une proc ´edure, fond ´ee sur sa situation en tant\\nque travailleur de soins de sant´e dans un hˆopital.\\nSource This kind of experience is part of Disney’s efforts to ”extend the lifetime of its series and build\\nnew relationships with audiences via digital platforms that are becoming ever more important,”\\nhe added.\\nReference Ce type d’exp ´erience entre dans le cadre des efforts de Disney pour ” ´etendre la dur ´ee de\\nvie de ses s ´eries et construire de nouvelles relations avec son public gr ˆace `a des plateformes\\nnum´eriques qui sont de plus en plus importantes”, a-t-il ajout´e.\\nRNNenc-50 Ce type d’exp´erience fait partie des initiatives du Disney pour ”prolonger la dur ´ee de vie de\\nses nouvelles et de d´evelopper des liens avec les lecteurs num´eriques qui deviennent plus com-\\nplexes.\\nRNNsearch-50 Ce genre d’exp´erience fait partie des efforts de Disney pour ”prolonger la dur ´ee de vie de ses\\ns´eries et cr ´eer de nouvelles relations avec des publics via des plateformes num ´eriques de plus\\nen plus importantes”, a-t-il ajout´e.\\nGoogle\\nTranslate\\nCe genre d’exp´erience fait partie des efforts de Disney `a “´etendre la dur´ee de vie de sa s ´erie et\\nconstruire de nouvelles relations avec le public par le biais des plates-formes num ´eriques qui\\ndeviennent de plus en plus important”, at-il ajout´e.\\nSource In a press conference on Thursday, Mr Blair stated that there was nothing in this video that might\\nconstitute a ”reasonable motive” that could lead to criminal charges being brought against the\\nmayor.\\nReference En conf´erence de presse, jeudi, M. Blair a afﬁrm´e qu’il n’y avait rien dans cette vid´eo qui puisse\\nconstituer des ”motifs raisonnables” pouvant mener au d´epˆot d’une accusation criminelle contre\\nle maire.\\nRNNenc-50 Lors de la conf´erence de presse de jeudi, M. Blair a dit qu’il n’y avait rien dans cette vid´eo qui\\npourrait constituer une ”motivation raisonnable” pouvant entraˆıner des accusations criminelles\\nport´ees contre le maire.\\nRNNsearch-50 Lors d’une conf´erence de presse jeudi, M. Blair a d´eclar´e qu’il n’y avait rien dans cette vid´eo qui\\npourrait constituer un ”motif raisonnable” qui pourrait conduire `a des accusations criminelles\\ncontre le maire.\\nGoogle\\nTranslate\\nLors d’une conf´erence de presse jeudi, M. Blair a d ´eclar´e qu’il n’y avait rien dans cette vido\\nqui pourrait constituer un ”motif raisonnable” qui pourrait mener `a des accusations criminelles\\nportes contre le maire.\\nTable 3: The translations generated by RNNenc-50 and RNNsearch-50 from long source sentences\\n(30 words or more) selected from the test set. For each source sentence, we also show the gold-\\nstandard translation. The translations by Google Translate were made on 27 August 2014.\\n15')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PDF Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader=PyPDFLoader('attention.pdf')\n",
    "docs=pdf_loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Text Splitters by Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Published as a conference paper at ICLR 2015\\nNEURAL MACHINE TRANSLATION\\nBY JOINTLY LEARNING TO ALIGN AND TRANSLATE\\nDzmitry Bahdanau\\nJacobs University Bremen, Germany\\nKyungHyun Cho Yoshua Bengio ∗\\nUniversit´e de Montr´eal\\nABSTRACT\\nNeural machine translation is a recently proposed approach to machine transla-\\ntion. Unlike the traditional statistical machine translation, the neural machine\\ntranslation aims at building a single neural network that can be jointly tuned to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='maximize the translation performance. The models proposed recently for neu-\\nral machine translation often belong to a family of encoder–decoders and encode\\na source sentence into a ﬁxed-length vector from which a decoder generates a\\ntranslation. In this paper, we conjecture that the use of a ﬁxed-length vector is a\\nbottleneck in improving the performance of this basic encoder–decoder architec-\\nture, and propose to extend this by allowing a model to automatically (soft-)search'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='for parts of a source sentence that are relevant to predicting a target word, without\\nhaving to form these parts as a hard segment explicitly. With this new approach,\\nwe achieve a translation performance comparable to the existing state-of-the-art\\nphrase-based system on the task of English-to-French translation. Furthermore,\\nqualitative analysis reveals that the (soft-)alignments found by the model agree\\nwell with our intuition.\\n1 I NTRODUCTION'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='well with our intuition.\\n1 I NTRODUCTION\\nNeural machine translation is a newly emerging approach to machine translation, recently proposed\\nby Kalchbrenner and Blunsom (2013), Sutskever et al. (2014) and Cho et al. (2014b). Unlike the\\ntraditional phrase-based translation system (see, e.g., Koehn et al., 2003) which consists of many\\nsmall sub-components that are tuned separately, neural machine translation attempts to build and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='train a single, large neural network that reads a sentence and outputs a correct translation.\\nMost of the proposed neural machine translation models belong to a family of encoder–\\ndecoders (Sutskever et al., 2014; Cho et al., 2014a), with an encoder and a decoder for each lan-\\nguage, or involve a language-speciﬁc encoder applied to each sentence whose outputs are then com-\\npared (Hermann and Blunsom, 2014). An encoder neural network reads and encodes a source sen-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='tence into a ﬁxed-length vector. A decoder then outputs a translation from the encoded vector. The\\nwhole encoder–decoder system, which consists of the encoder and the decoder for a language pair,\\nis jointly trained to maximize the probability of a correct translation given a source sentence.\\nA potential issue with this encoder–decoder approach is that a neural network needs to be able to\\ncompress all the necessary information of a source sentence into a ﬁxed-length vector. This may'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='make it difﬁcult for the neural network to cope with long sentences, especially those that are longer\\nthan the sentences in the training corpus. Cho et al. (2014b) showed that indeed the performance of\\na basic encoder–decoder deteriorates rapidly as the length of an input sentence increases.\\nIn order to address this issue, we introduce an extension to the encoder–decoder model which learns\\nto align and translate jointly. Each time the proposed model generates a word in a translation, it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='(soft-)searches for a set of positions in a source sentence where the most relevant information is\\nconcentrated. The model then predicts a target word based on the context vectors associated with\\nthese source positions and all the previous generated target words.\\n∗CIFAR Senior Fellow\\n1\\narXiv:1409.0473v7  [cs.CL]  19 May 2016'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='Published as a conference paper at ICLR 2015\\nThe most important distinguishing feature of this approach from the basic encoder–decoder is that\\nit does not attempt to encode a whole input sentence into a single ﬁxed-length vector. Instead, it en-\\ncodes the input sentence into a sequence of vectors and chooses a subset of these vectors adaptively\\nwhile decoding the translation. This frees a neural translation model from having to squash all the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='information of a source sentence, regardless of its length, into a ﬁxed-length vector. We show this\\nallows a model to cope better with long sentences.\\nIn this paper, we show that the proposed approach of jointly learning to align and translate achieves\\nsigniﬁcantly improved translation performance over the basic encoder–decoder approach. The im-\\nprovement is more apparent with longer sentences, but can be observed with sentences of any'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='length. On the task of English-to-French translation, the proposed approach achieves, with a single\\nmodel, a translation performance comparable, or close, to the conventional phrase-based system.\\nFurthermore, qualitative analysis reveals that the proposed model ﬁnds a linguistically plausible\\n(soft-)alignment between a source sentence and the corresponding target sentence.\\n2 B ACKGROUND : N EURAL MACHINE TRANSLATION'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='2 B ACKGROUND : N EURAL MACHINE TRANSLATION\\nFrom a probabilistic perspective, translation is equivalent to ﬁnding a target sentence y that max-\\nimizes the conditional probability of y given a source sentence x, i.e., arg maxy p(y | x). In\\nneural machine translation, we ﬁt a parameterized model to maximize the conditional probability\\nof sentence pairs using a parallel training corpus. Once the conditional distribution is learned by a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='translation model, given a source sentence a corresponding translation can be generated by searching\\nfor the sentence that maximizes the conditional probability.\\nRecently, a number of papers have proposed the use of neural networks to directly learn this condi-\\ntional distribution (see, e.g., Kalchbrenner and Blunsom, 2013; Cho et al., 2014a; Sutskever et al.,\\n2014; Cho et al., 2014b; Forcada and ˜Neco, 1997). This neural machine translation approach typ-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='ically consists of two components, the ﬁrst of which encodes a source sentence x and the second\\ndecodes to a target sentence y. For instance, two recurrent neural networks (RNN) were used by\\n(Cho et al., 2014a) and (Sutskever et al., 2014) to encode a variable-length source sentence into a\\nﬁxed-length vector and to decode the vector into a variable-length target sentence.\\nDespite being a quite new approach, neural machine translation has already shown promising results.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='Sutskever et al. (2014) reported that the neural machine translation based on RNNs with long short-\\nterm memory (LSTM) units achieves close to the state-of-the-art performance of the conventional\\nphrase-based machine translation system on an English-to-French translation task. 1 Adding neural\\ncomponents to existing translation systems, for instance, to score the phrase pairs in the phrase\\ntable (Cho et al., 2014a) or to re-rank candidate translations (Sutskever et al., 2014), has allowed to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='surpass the previous state-of-the-art performance level.\\n2.1 RNN E NCODER –DECODER\\nHere, we describe brieﬂy the underlying framework, called RNN Encoder–Decoder, proposed by\\nCho et al. (2014a) and Sutskever et al. (2014) upon which we build a novel architecture that learns\\nto align and translate simultaneously.\\nIn the Encoder–Decoder framework, an encoder reads the input sentence, a sequence of vectors\\nx = (x1,··· ,xTx ), into a vector c.2 The most common approach is to use an RNN such that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='ht = f(xt,ht−1) (1)\\nand\\nc= q({h1,··· ,hTx }) ,\\nwhere ht ∈Rn is a hidden state at time t, and c is a vector generated from the sequence of the\\nhidden states. f and qare some nonlinear functions. Sutskever et al. (2014) used an LSTM as f and\\nq({h1,··· ,hT }) =hT , for instance.\\n1 We mean by the state-of-the-art performance, the performance of the conventional phrase-based system\\nwithout using any neural network-based component.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='without using any neural network-based component.\\n2 Although most of the previous works (see, e.g., Choet al., 2014a; Sutskeveret al., 2014; Kalchbrenner and\\nBlunsom, 2013) used to encode a variable-length input sentence into a ﬁxed-length vector, it is not necessary,\\nand even it may be beneﬁcial to have a variable-length vector, as we will show later.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Published as a conference paper at ICLR 2015\\nThe decoder is often trained to predict the next word yt′ given the context vector c and all the\\npreviously predicted words {y1,··· ,yt′−1}. In other words, the decoder deﬁnes a probability over\\nthe translation y by decomposing the joint probability into the ordered conditionals:\\np(y) =\\nT∏\\nt=1\\np(yt |{y1,··· ,yt−1},c), (2)\\nwhere y =\\n(\\ny1,··· ,yTy\\n)\\n. With an RNN, each conditional probability is modeled as\\np(yt |{y1,··· ,yt−1},c) =g(yt−1,st,c), (3)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='p(yt |{y1,··· ,yt−1},c) =g(yt−1,st,c), (3)\\nwhere gis a nonlinear, potentially multi-layered, function that outputs the probability ofyt, and st is\\nthe hidden state of the RNN. It should be noted that other architectures such as a hybrid of an RNN\\nand a de-convolutional neural network can be used (Kalchbrenner and Blunsom, 2013).\\n3 L EARNING TO ALIGN AND TRANSLATE\\nIn this section, we propose a novel architecture for neural machine translation. The new architecture'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='consists of a bidirectional RNN as an encoder (Sec. 3.2) and a decoder that emulates searching\\nthrough a source sentence during decoding a translation (Sec. 3.1).\\n3.1 D ECODER : G ENERAL DESCRIPTION\\nx1 x2 x3 xT\\n+\\nαt,1\\nαt,2 αt,3\\nαt,T\\nyt-1 yt\\nh1 h2 h3 hT\\nh1 h2 h3 hT\\nst-1 st\\nFigure 1: The graphical illus-\\ntration of the proposed model\\ntrying to generate the t-th tar-\\nget word yt given a source\\nsentence (x1,x2,...,x T ).\\nIn a new model architecture, we deﬁne each conditional probability'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='in Eq. (2) as:\\np(yi|y1,...,y i−1,x) =g(yi−1,si,ci), (4)\\nwhere si is an RNN hidden state for time i, computed by\\nsi = f(si−1,yi−1,ci).\\nIt should be noted that unlike the existing encoder–decoder ap-\\nproach (see Eq. (2)), here the probability is conditioned on a distinct\\ncontext vector ci for each target word yi.\\nThe context vector ci depends on a sequence of annotations\\n(h1,··· ,hTx ) to which an encoder maps the input sentence. Each'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='annotation hi contains information about the whole input sequence\\nwith a strong focus on the parts surrounding the i-th word of the\\ninput sequence. We explain in detail how the annotations are com-\\nputed in the next section.\\nThe context vector ci is, then, computed as a weighted sum of these\\nannotations hi:\\nci =\\nTx∑\\nj=1\\nαijhj. (5)\\nThe weight αij of each annotation hj is computed by\\nαij = exp (eij)∑Tx\\nk=1 exp (eik)\\n, (6)\\nwhere\\neij = a(si−1,hj)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='k=1 exp (eik)\\n, (6)\\nwhere\\neij = a(si−1,hj)\\nis an alignment model which scores how well the inputs around positionjand the output at position\\nimatch. The score is based on the RNN hidden state si−1 (just before emitting yi, Eq. (4)) and the\\nj-th annotation hj of the input sentence.\\nWe parametrize the alignment modelaas a feedforward neural network which is jointly trained with\\nall the other components of the proposed system. Note that unlike in traditional machine translation,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Published as a conference paper at ICLR 2015\\nthe alignment is not considered to be a latent variable. Instead, the alignment model directly com-\\nputes a soft alignment, which allows the gradient of the cost function to be backpropagated through.\\nThis gradient can be used to train the alignment model as well as the whole translation model jointly.\\nWe can understand the approach of taking a weighted sum of all the annotations as computing an'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='expected annotation, where the expectation is over possible alignments. Letαij be a probability that\\nthe target word yi is aligned to, or translated from, a source word xj. Then, the i-th context vector\\nci is the expected annotation over all the annotations with probabilities αij.\\nThe probability αij, or its associated energy eij, reﬂects the importance of the annotation hj with\\nrespect to the previous hidden state si−1 in deciding the next state si and generating yi. Intuitively,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='this implements a mechanism of attention in the decoder. The decoder decides parts of the source\\nsentence to pay attention to. By letting the decoder have an attention mechanism, we relieve the\\nencoder from the burden of having to encode all information in the source sentence into a ﬁxed-\\nlength vector. With this new approach the information can be spread throughout the sequence of\\nannotations, which can be selectively retrieved by the decoder accordingly.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='3.2 E NCODER : B IDIRECTIONAL RNN FOR ANNOTATING SEQUENCES\\nThe usual RNN, described in Eq. (1), reads an input sequence x in order starting from the ﬁrst\\nsymbol x1 to the last one xTx . However, in the proposed scheme, we would like the annotation\\nof each word to summarize not only the preceding words, but also the following words. Hence,\\nwe propose to use a bidirectional RNN (BiRNN, Schuster and Paliwal, 1997), which has been'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='successfully used recently in speech recognition (see, e.g., Graves et al., 2013).\\nA BiRNN consists of forward and backward RNN’s. The forward RNN− →f reads the input sequence\\nas it is ordered (fromx1 to xTx ) and calculates a sequence offorward hidden states(− →h1,··· ,− →hTx ).\\nThe backward RNN ← −f reads the sequence in the reverse order (from xTx to x1), resulting in a\\nsequence of backward hidden states (← −h1,··· ,← −hTx ).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='We obtain an annotation for each word xj by concatenating the forward hidden state − →hj and the\\nbackward one ← −hj, i.e., hj =\\n[− →h⊤\\nj ; ← −h⊤\\nj\\n]⊤\\n. In this way, the annotation hj contains the summaries\\nof both the preceding words and the following words. Due to the tendency of RNNs to better\\nrepresent recent inputs, the annotation hj will be focused on the words around xj. This sequence\\nof annotations is used by the decoder and the alignment model later to compute the context vector'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='(Eqs. (5)–(6)).\\nSee Fig. 1 for the graphical illustration of the proposed model.\\n4 E XPERIMENT SETTINGS\\nWe evaluate the proposed approach on the task of English-to-French translation. We use the bilin-\\ngual, parallel corpora provided by ACL WMT ’14. 3 As a comparison, we also report the perfor-\\nmance of an RNN Encoder–Decoder which was proposed recently by Cho et al. (2014a). We use\\nthe same training procedures and the same dataset for both models.4\\n4.1 D ATASET'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='4.1 D ATASET\\nWMT ’14 contains the following English-French parallel corpora: Europarl (61M words), news\\ncommentary (5.5M), UN (421M) and two crawled corpora of 90M and 272.5M words respectively,\\ntotaling 850M words. Following the procedure described in Choet al. (2014a), we reduce the size of\\nthe combined corpus to have 348M words using the data selection method by Axelrodet al. (2011).5\\nWe do not use any monolingual data other than the mentioned parallel corpora, although it may be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='possible to use a much larger monolingual corpus to pretrain an encoder. We concatenate news-test-\\n3 http://www.statmt.org/wmt14/translation-task.html\\n4 Implementations are available at https://github.com/lisa-groundhog/GroundHog.\\n5 Available online athttp://www-lium.univ-lemans.fr/˜schwenk/cslm_joint_paper/.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='Published as a conference paper at ICLR 2015\\n0 10 20 30 40 50 60\\nSentence length\\n0\\n5\\n10\\n15\\n20\\n25\\n30BLEU scoreRNNsearch-50\\nRNNsearch-30\\nRNNenc-50\\nRNNenc-30\\nFigure 2: The BLEU scores\\nof the generated translations\\non the test set with respect\\nto the lengths of the sen-\\ntences. The results are on\\nthe full test set which in-\\ncludes sentences having un-\\nknown words to the models.\\n2012 and news-test-2013 to make a development (validation) set, and evaluate the models on the test'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='set (news-test-2014) from WMT ’14, which consists of 3003 sentences not present in the training\\ndata.\\nAfter a usual tokenization 6, we use a shortlist of 30,000 most frequent words in each language to\\ntrain our models. Any word not included in the shortlist is mapped to a special token ( [UNK]). We\\ndo not apply any other special preprocessing, such as lowercasing or stemming, to the data.\\n4.2 M ODELS\\nWe train two types of models. The ﬁrst one is an RNN Encoder–Decoder (RNNencdec, Cho et al.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='2014a), and the other is the proposed model, to which we refer as RNNsearch. We train each model\\ntwice: ﬁrst with the sentences of length up to 30 words (RNNencdec-30, RNNsearch-30) and then\\nwith the sentences of length up to 50 word (RNNencdec-50, RNNsearch-50).\\nThe encoder and decoder of the RNNencdec have 1000 hidden units each. 7 The encoder of the\\nRNNsearch consists of forward and backward recurrent neural networks (RNN) each having 1000'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='hidden units. Its decoder has 1000 hidden units. In both cases, we use a multilayer network with a\\nsingle maxout (Goodfellow et al., 2013) hidden layer to compute the conditional probability of each\\ntarget word (Pascanu et al., 2014).\\nWe use a minibatch stochastic gradient descent (SGD) algorithm together with Adadelta (Zeiler,\\n2012) to train each model. Each SGD update direction is computed using a minibatch of 80 sen-\\ntences. We trained each model for approximately 5 days.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='Once a model is trained, we use a beam search to ﬁnd a translation that approximately maximizes the\\nconditional probability (see, e.g., Graves, 2012; Boulanger-Lewandowski et al., 2013). Sutskever\\net al. (2014) used this approach to generate translations from their neural machine translation model.\\nFor more details on the architectures of the models and training procedure used in the experiments,\\nsee Appendices A and B.\\n5 R ESULTS\\n5.1 Q UANTITATIVE RESULTS'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='5 R ESULTS\\n5.1 Q UANTITATIVE RESULTS\\nIn Table 1, we list the translation performances measured in BLEU score. It is clear from the table\\nthat in all the cases, the proposed RNNsearch outperforms the conventional RNNencdec. More\\nimportantly, the performance of the RNNsearch is as high as that of the conventional phrase-based\\ntranslation system (Moses), when only the sentences consisting of known words are considered.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='This is a signiﬁcant achievement, considering that Moses uses a separate monolingual corpus (418M\\nwords) in addition to the parallel corpora we used to train the RNNsearch and RNNencdec.\\n6 We used the tokenization script from the open-source machine translation package, Moses.\\n7 In this paper, by a ’hidden unit’, we always mean the gated hidden unit (see Appendix A.1.1).\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content=\"Published as a conference paper at ICLR 2015\\nThe\\nagreement\\non\\nthe\\nEuropean\\nEconomic\\nArea\\nwas\\nsigned\\nin\\nAugust\\n1992\\n.\\n<end>\\nL'\\naccord\\nsur\\nla\\nzone\\néconomique\\neuropéenne\\na\\nété\\nsigné\\nen\\naoût\\n1992\\n.\\n<end>\\nIt\\nshould\\nbe\\nnoted\\nthat\\nthe\\nmarine\\nenvironment\\nis\\nthe\\nleast\\nknown\\nof\\nenvironments\\n.\\n<end>\\nIl\\nconvient\\nde\\nnoter\\nque\\nl'\\nenvironnement\\nmarin\\nest\\nle\\nmoins\\nconnu\\nde\\nl'\\nenvironnement\\n.\\n<end>\\n(a) (b)\\nDestruction\\nof\\nthe\\nequipment\\nmeans\\nthat\\nSyria\\ncan\\nno\\nlonger\\nproduce\\nnew\\nchemical\\nweapons\\n.\\n<end>\\nLa\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='no\\nlonger\\nproduce\\nnew\\nchemical\\nweapons\\n.\\n<end>\\nLa\\ndestruction\\nde\\nl\\'\\néquipement\\nsignifie\\nque\\nla\\nSyrie\\nne\\npeut\\nplus\\nproduire\\nde\\nnouvelles\\narmes\\nchimiques\\n.\\n<end>\\n\"\\nThis\\nwill\\nchange\\nmy\\nfuture\\nwith\\nmy\\nfamily\\n,\\n\"\\nthe\\nman\\nsaid\\n.\\n<end>\\n\"\\nCela\\nva\\nchanger\\nmon\\navenir\\navec\\nma\\nfamille\\n\"\\n,\\na\\ndit\\nl\\'\\nhomme\\n.\\n<end>\\n(c) (d)\\nFigure 3: Four sample alignments found by RNNsearch-50. The x-axis and y-axis of each plot\\ncorrespond to the words in the source sentence (English) and the generated translation (French),'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='respectively. Each pixel shows the weight αij of the annotation of the j-th source word for the i-th\\ntarget word (see Eq. (6)), in grayscale ( 0: black, 1: white). (a) an arbitrary sentence. (b–d) three\\nrandomly selected samples among the sentences without any unknown words and of length between\\n10 and 20 words from the test set.\\nOne of the motivations behind the proposed approach was the use of a ﬁxed-length context vector'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='in the basic encoder–decoder approach. We conjectured that this limitation may make the basic\\nencoder–decoder approach to underperform with long sentences. In Fig. 2, we see that the perfor-\\nmance of RNNencdec dramatically drops as the length of the sentences increases. On the other hand,\\nboth RNNsearch-30 and RNNsearch-50 are more robust to the length of the sentences. RNNsearch-\\n50, especially, shows no performance deterioration even with sentences of length 50 or more. This'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='superiority of the proposed model over the basic encoder–decoder is further conﬁrmed by the fact\\nthat the RNNsearch-30 even outperforms RNNencdec-50 (see Table 1).\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='Published as a conference paper at ICLR 2015\\nModel All No UNK◦\\nRNNencdec-30 13.93 24.19\\nRNNsearch-30 21.50 31.44\\nRNNencdec-50 17.82 26.71\\nRNNsearch-50 26.75 34.16\\nRNNsearch-50⋆ 28.45 36.15\\nMoses 33.30 35.63\\nTable 1: BLEU scores of the trained models com-\\nputed on the test set. The second and third columns\\nshow respectively the scores on all the sentences and,\\non the sentences without any unknown word in them-\\nselves and in the reference translations. Note that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='RNNsearch-50⋆ was trained much longer until the\\nperformance on the development set stopped improv-\\ning. (◦) We disallowed the models to generate [UNK]\\ntokens when only the sentences having no unknown\\nwords were evaluated (last column).\\n5.2 Q UALITATIVE ANALYSIS\\n5.2.1 A LIGNMENT\\nThe proposed approach provides an intuitive way to inspect the (soft-)alignment between the words\\nin a generated translation and those in a source sentence. This is done by visualizing the annotation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='weights αij from Eq. (6), as in Fig. 3. Each row of a matrix in each plot indicates the weights\\nassociated with the annotations. From this we see which positions in the source sentence were\\nconsidered more important when generating the target word.\\nWe can see from the alignments in Fig. 3 that the alignment of words between English and French\\nis largely monotonic. We see strong weights along the diagonal of each matrix. However, we also'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='observe a number of non-trivial, non-monotonic alignments. Adjectives and nouns are typically\\nordered differently between French and English, and we see an example in Fig. 3 (a). From this\\nﬁgure, we see that the model correctly translates a phrase [European Economic Area] into [zone\\n´economique europ ´een]. The RNNsearch was able to correctly align [zone] with [Area], jumping\\nover the two words ([European] and [Economic]), and then looked one word back at a time to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='complete the whole phrase [zone ´economique europ´eenne].\\nThe strength of the soft-alignment, opposed to a hard-alignment, is evident, for instance, from\\nFig. 3 (d). Consider the source phrase [the man] which was translated into [l’ homme]. Any hard\\nalignment will map [the] to [l’] and [man] to [homme]. This is not helpful for translation, as one\\nmust consider the word following [the] to determine whether it should be translated into [le], [la],'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='[les] or [l’]. Our soft-alignment solves this issue naturally by letting the model look at both [the] and\\n[man], and in this example, we see that the model was able to correctly translate [the] into [l’]. We\\nobserve similar behaviors in all the presented cases in Fig. 3. An additional beneﬁt of the soft align-\\nment is that it naturally deals with source and target phrases of different lengths, without requiring a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='counter-intuitive way of mapping some words to or from nowhere ([NULL]) (see, e.g., Chapters 4\\nand 5 of Koehn, 2010).\\n5.2.2 L ONG SENTENCES\\nAs clearly visible from Fig. 2 the proposed model (RNNsearch) is much better than the conventional\\nmodel (RNNencdec) at translating long sentences. This is likely due to the fact that the RNNsearch\\ndoes not require encoding a long sentence into a ﬁxed-length vector perfectly, but only accurately'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='encoding the parts of the input sentence that surround a particular word.\\nAs an example, consider this source sentence from the test set:\\nAn admitting privilege is the right of a doctor to admit a patient to a hospital or\\na medical centre to carry out a diagnosis or a procedure, based on his status as a\\nhealth care worker at a hospital.\\nThe RNNencdec-50 translated this sentence into:\\nUn privil `ege d’admission est le droit d’un m ´edecin de reconna ˆıtre un patient `a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='l’hˆopital ou un centre m ´edical d’un diagnostic ou de prendre un diagnostic en\\nfonction de son ´etat de sant´e.\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Published as a conference paper at ICLR 2015\\nThe RNNencdec-50 correctly translated the source sentence until [a medical center]. However, from\\nthere on (underlined), it deviated from the original meaning of the source sentence. For instance, it\\nreplaced [based on his status as a health care worker at a hospital] in the source sentence with [en\\nfonction de son ´etat de sant´e] (“based on his state of health”).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='On the other hand, the RNNsearch-50 generated the following correct translation, preserving the\\nwhole meaning of the input sentence without omitting any details:\\nUn privil `ege d’admission est le droit d’un m ´edecin d’admettre un patient `a un\\nhˆopital ou un centre m´edical pour effectuer un diagnostic ou une proc´edure, selon\\nson statut de travailleur des soins de sant´e `a l’hˆopital.\\nLet us consider another sentence from the test set:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='This kind of experience is part of Disney’s efforts to ”extend the lifetime of its\\nseries and build new relationships with audiences via digital platforms that are\\nbecoming ever more important, ”he added.\\nThe translation by the RNNencdec-50 is\\nCe type d’exp´erience fait partie des initiatives du Disney pour ”prolonger la dur´ee\\nde vie de ses nouvelles et de d´evelopper des liens avec leslecteurs num´eriques qui\\ndeviennent plus complexes.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='deviennent plus complexes.\\nAs with the previous example, the RNNencdec began deviating from the actual meaning of the\\nsource sentence after generating approximately 30 words (see the underlined phrase). After that\\npoint, the quality of the translation deteriorates, with basic mistakes such as the lack of a closing\\nquotation mark.\\nAgain, the RNNsearch-50 was able to translate this long sentence correctly:\\nCe genre d’exp´erience fait partie des efforts de Disney pour ”prolonger la dur ´ee'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='de vie de ses s ´eries et cr ´eer de nouvelles relations avec des publics via des\\nplateformes num´eriques de plus en plus importantes”, a-t-il ajout´e.\\nIn conjunction with the quantitative results presented already, these qualitative observations con-\\nﬁrm our hypotheses that the RNNsearch architecture enables far more reliable translation of long\\nsentences than the standard RNNencdec model.\\nIn Appendix C, we provide a few more sample translations of long source sentences generated by'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='the RNNencdec-50, RNNsearch-50 and Google Translate along with the reference translations.\\n6 R ELATED WORK\\n6.1 L EARNING TO ALIGN\\nA similar approach of aligning an output symbol with an input symbol was proposed recently by\\nGraves (2013) in the context of handwriting synthesis. Handwriting synthesis is a task where the\\nmodel is asked to generate handwriting of a given sequence of characters. In his work, he used a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='mixture of Gaussian kernels to compute the weights of the annotations, where the location, width\\nand mixture coefﬁcient of each kernel was predicted from an alignment model. More speciﬁcally,\\nhis alignment was restricted to predict the location such that the location increases monotonically.\\nThe main difference from our approach is that, in (Graves, 2013), the modes of the weights of the\\nannotations only move in one direction. In the context of machine translation, this is a severe limi-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='tation, as (long-distance) reordering is often needed to generate a grammatically correct translation\\n(for instance, English-to-German).\\nOur approach, on the other hand, requires computing the annotation weight of every word in the\\nsource sentence for each word in the translation. This drawback is not severe with the task of\\ntranslation in which most of input and output sentences are only 15–40 words. However, this may\\nlimit the applicability of the proposed scheme to other tasks.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='Published as a conference paper at ICLR 2015\\n6.2 N EURAL NETWORKS FOR MACHINE TRANSLATION\\nSince Bengio et al. (2003) introduced a neural probabilistic language model which uses a neural net-\\nwork to model the conditional probability of a word given a ﬁxed number of the preceding words,\\nneural networks have widely been used in machine translation. However, the role of neural net-\\nworks has been largely limited to simply providing a single feature to an existing statistical machine'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='translation system or to re-rank a list of candidate translations provided by an existing system.\\nFor instance, Schwenk (2012) proposed using a feedforward neural network to compute the score of\\na pair of source and target phrases and to use the score as an additional feature in the phrase-based\\nstatistical machine translation system. More recently, Kalchbrenner and Blunsom (2013) and Devlin\\net al. (2014) reported the successful use of the neural networks as a sub-component of the existing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='translation system. Traditionally, a neural network trained as a target-side language model has been\\nused to rescore or rerank a list of candidate translations (see, e.g., Schwenk et al., 2006).\\nAlthough the above approaches were shown to improve the translation performance over the state-\\nof-the-art machine translation systems, we are more interested in a more ambitious objective of\\ndesigning a completely new translation system based on neural networks. The neural machine trans-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='lation approach we consider in this paper is therefore a radical departure from these earlier works.\\nRather than using a neural network as a part of the existing system, our model works on its own and\\ngenerates a translation from a source sentence directly.\\n7 C ONCLUSION\\nThe conventional approach to neural machine translation, called an encoder–decoder approach, en-\\ncodes a whole input sentence into a ﬁxed-length vector from which a translation will be decoded.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='We conjectured that the use of a ﬁxed-length context vector is problematic for translating long sen-\\ntences, based on a recent empirical study reported by Cho et al. (2014b) and Pouget-Abadie et al.\\n(2014).\\nIn this paper, we proposed a novel architecture that addresses this issue. We extended the basic\\nencoder–decoder by letting a model (soft-)search for a set of input words, or their annotations com-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='puted by an encoder, when generating each target word. This frees the model from having to encode\\na whole source sentence into a ﬁxed-length vector, and also lets the model focus only on information\\nrelevant to the generation of the next target word. This has a major positive impact on the ability\\nof the neural machine translation system to yield good results on longer sentences. Unlike with\\nthe traditional machine translation systems, all of the pieces of the translation system, including'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='the alignment mechanism, are jointly trained towards a better log-probability of producing correct\\ntranslations.\\nWe tested the proposed model, called RNNsearch, on the task of English-to-French translation. The\\nexperiment revealed that the proposed RNNsearch outperforms the conventional encoder–decoder\\nmodel (RNNencdec) signiﬁcantly, regardless of the sentence length and that it is much more ro-\\nbust to the length of a source sentence. From the qualitative analysis where we investigated the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='(soft-)alignment generated by the RNNsearch, we were able to conclude that the model can cor-\\nrectly align each target word with the relevant words, or their annotations, in the source sentence as\\nit generated a correct translation.\\nPerhaps more importantly, the proposed approach achieved a translation performance comparable to\\nthe existing phrase-based statistical machine translation. It is a striking result, considering that the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='proposed architecture, or the whole family of neural machine translation, has only been proposed\\nas recently as this year. We believe the architecture proposed here is a promising step toward better\\nmachine translation and a better understanding of natural languages in general.\\nOne of challenges left for the future is to better handle unknown, or rare words. This will be required\\nfor the model to be more widely used and to match the performance of current state-of-the-art'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='machine translation systems in all contexts.\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Published as a conference paper at ICLR 2015\\nACKNOWLEDGMENTS\\nThe authors would like to thank the developers of Theano (Bergstra et al., 2010; Bastien et al.,\\n2012). We acknowledge the support of the following agencies for research funding and computing\\nsupport: NSERC, Calcul Qu ´ebec, Compute Canada, the Canada Research Chairs and CIFAR. Bah-\\ndanau thanks the support from Planet Intelligent Systems GmbH. We also thank Felix Hill, Bart van'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Merri´enboer, Jean Pouget-Abadie, Coline Devin and Tae-Ho Kim.\\nREFERENCES\\nAxelrod, A., He, X., and Gao, J. (2011). Domain adaptation via pseudo in-domain data selection.\\nIn Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing\\n(EMNLP), pages 355–362. Association for Computational Linguistics.\\nBastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='and Bengio, Y . (2012). Theano: new features and speed improvements. Deep Learning and\\nUnsupervised Feature Learning NIPS 2012 Workshop.\\nBengio, Y ., Simard, P., and Frasconi, P. (1994). Learning long-term dependencies with gradient\\ndescent is difﬁcult. IEEE Transactions on Neural Networks, 5(2), 157–166.\\nBengio, Y ., Ducharme, R., Vincent, P., and Janvin, C. (2003). A neural probabilistic language model.\\nJ. Mach. Learn. Res., 3, 1137–1155.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='J. Mach. Learn. Res., 3, 1137–1155.\\nBergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-\\nFarley, D., and Bengio, Y . (2010). Theano: a CPU and GPU math expression compiler. In\\nProceedings of the Python for Scientiﬁc Computing Conference (SciPy). Oral Presentation.\\nBoulanger-Lewandowski, N., Bengio, Y ., and Vincent, P. (2013). Audio chord recognition with\\nrecurrent neural networks. In ISMIR.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='recurrent neural networks. In ISMIR.\\nCho, K., van Merrienboer, B., Gulcehre, C., Bougares, F., Schwenk, H., and Bengio, Y . (2014a).\\nLearning phrase representations using RNN encoder-decoder for statistical machine translation.\\nIn Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014) . to\\nappear.\\nCho, K., van Merri ¨enboer, B., Bahdanau, D., and Bengio, Y . (2014b). On the properties of neural'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='machine translation: Encoder–Decoder approaches. In Eighth Workshop on Syntax, Semantics\\nand Structure in Statistical Translation. to appear.\\nDevlin, J., Zbib, R., Huang, Z., Lamar, T., Schwartz, R., and Makhoul, J. (2014). Fast and robust\\nneural network joint models for statistical machine translation. In Association for Computational\\nLinguistics.\\nForcada, M. L. and ˜Neco, R. P. (1997). Recursive hetero-associative memories for translation. In'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='J. Mira, R. Moreno-D´ıaz, and J. Cabestany, editors,Biological and Artiﬁcial Computation: From\\nNeuroscience to Technology, volume 1240 ofLecture Notes in Computer Science, pages 453–462.\\nSpringer Berlin Heidelberg.\\nGoodfellow, I., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y . (2013). Maxout net-\\nworks. In Proceedings of The 30th International Conference on Machine Learning, pages 1319–\\n1327.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='1327.\\nGraves, A. (2012). Sequence transduction with recurrent neural networks. In Proceedings of the\\n29th International Conference on Machine Learning (ICML 2012).\\nGraves, A. (2013). Generating sequences with recurrent neural networks. arXiv:1308.0850\\n[cs.NE].\\nGraves, A., Jaitly, N., and Mohamed, A.-R. (2013). Hybrid speech recognition with deep bidirec-\\ntional LSTM. In Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Work-\\nshop on, pages 273–278.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='Published as a conference paper at ICLR 2015\\nHermann, K. and Blunsom, P. (2014). Multilingual distributed representations without word align-\\nment. In Proceedings of the Second International Conference on Learning Representations (ICLR\\n2014).\\nHochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut\\nf¨ur Informatik, Lehrstuhl Prof. Brauer, Technische Universit¨at M¨unchen.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9(8),\\n1735–1780.\\nKalchbrenner, N. and Blunsom, P. (2013). Recurrent continuous translation models. InProceedings\\nof the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pages\\n1700–1709. Association for Computational Linguistics.\\nKoehn, P. (2010). Statistical Machine Translation. Cambridge University Press, New York, NY ,\\nUSA.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='USA.\\nKoehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase-based translation. In Proceedings\\nof the 2003 Conference of the North American Chapter of the Association for Computational\\nLinguistics on Human Language Technology - Volume 1, NAACL ’03, pages 48–54, Stroudsburg,\\nPA, USA. Association for Computational Linguistics.\\nPascanu, R., Mikolov, T., and Bengio, Y . (2013a). On the difﬁculty of training recurrent neural\\nnetworks. In ICML’2013.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='networks. In ICML’2013.\\nPascanu, R., Mikolov, T., and Bengio, Y . (2013b). On the difﬁculty of training recurrent neural\\nnetworks. In Proceedings of the 30th International Conference on Machine Learning (ICML\\n2013).\\nPascanu, R., Gulcehre, C., Cho, K., and Bengio, Y . (2014). How to construct deep recurrent neural\\nnetworks. In Proceedings of the Second International Conference on Learning Representations\\n(ICLR 2014).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='(ICLR 2014).\\nPouget-Abadie, J., Bahdanau, D., van Merri¨enboer, B., Cho, K., and Bengio, Y . (2014). Overcoming\\nthe curse of sentence length for neural machine translation using automatic segmentation. In\\nEighth Workshop on Syntax, Semantics and Structure in Statistical Translation. to appear.\\nSchuster, M. and Paliwal, K. K. (1997). Bidirectional recurrent neural networks. Signal Processing,\\nIEEE Transactions on, 45(11), 2673–2681.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='IEEE Transactions on, 45(11), 2673–2681.\\nSchwenk, H. (2012). Continuous space translation models for phrase-based statistical machine\\ntranslation. In M. Kay and C. Boitet, editors,Proceedings of the 24th International Conference on\\nComputational Linguistics (COLIN), pages 1071–1080. Indian Institute of Technology Bombay.\\nSchwenk, H., Dchelotte, D., and Gauvain, J.-L. (2006). Continuous space language models for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='statistical machine translation. In Proceedings of the COLING/ACL on Main conference poster\\nsessions, pages 723–730. Association for Computational Linguistics.\\nSutskever, I., Vinyals, O., and Le, Q. (2014). Sequence to sequence learning with neural networks.\\nIn Advances in Neural Information Processing Systems (NIPS 2014).\\nZeiler, M. D. (2012). ADADELTA: An adaptive learning rate method. arXiv:1212.5701\\n[cs.LG].\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='Published as a conference paper at ICLR 2015\\nA M ODEL ARCHITECTURE\\nA.1 A RCHITECTURAL CHOICES\\nThe proposed scheme in Section 3 is a general framework where one can freely deﬁne, for instance,\\nthe activation functions f of recurrent neural networks (RNN) and the alignment model a. Here, we\\ndescribe the choices we made for the experiments in this paper.\\nA.1.1 R ECURRENT NEURAL NETWORK\\nFor the activation function f of an RNN, we use the gated hidden unit recently proposed by Cho'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='et al. (2014a). The gated hidden unit is an alternative to the conventional simple units such as an\\nelement-wise tanh. This gated unit is similar to a long short-term memory (LSTM) unit proposed\\nearlier by Hochreiter and Schmidhuber (1997), sharing with it the ability to better model and learn\\nlong-term dependencies. This is made possible by having computation paths in the unfolded RNN\\nfor which the product of derivatives is close to 1. These paths allow gradients to ﬂow backward'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='easily without suffering too much from the vanishing effect (Hochreiter, 1991; Bengio et al., 1994;\\nPascanu et al., 2013a). It is therefore possible to use LSTM units instead of the gated hidden unit\\ndescribed here, as was done in a similar context by Sutskever et al. (2014).\\nThe new state si of the RNN employing ngated hidden units8 is computed by\\nsi = f(si−1,yi−1,ci) = (1−zi) ◦si−1 + zi ◦˜si,\\nwhere ◦is an element-wise multiplication, and zi is the output of the update gates (see below). The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='proposed updated state ˜si is computed by\\n˜si = tanh (We(yi−1) +U[ri ◦si−1] +Cci) ,\\nwhere e(yi−1) ∈Rm is an m-dimensional embedding of a word yi−1, and ri is the output of the\\nreset gates (see below). When yi is represented as a 1-of-K vector, e(yi) is simply a column of an\\nembedding matrix E ∈Rm×K. Whenever possible, we omit bias terms to make the equations less\\ncluttered.\\nThe update gates zi allow each hidden unit to maintain its previous activation, and the reset gatesri'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='control how much and what information from the previous state should be reset. We compute them\\nby\\nzi = σ(Wze(yi−1) +Uzsi−1 + Czci) ,\\nri = σ(Wre(yi−1) +Ursi−1 + Crci) ,\\nwhere σ(·) is a logistic sigmoid function.\\nAt each step of the decoder, we compute the output probability (Eq. (4)) as a multi-layered func-\\ntion (Pascanu et al., 2014). We use a single hidden layer of maxout units (Goodfellow et al., 2013)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='and normalize the output probabilities (one for each word) with a softmax function (see Eq. (6)).\\nA.1.2 A LIGNMENT MODEL\\nThe alignment model should be designed considering that the model needs to be evaluated Tx ×Ty\\ntimes for each sentence pair of lengths Tx and Ty. In order to reduce computation, we use a single-\\nlayer multilayer perceptron such that\\na(si−1,hj) =v⊤\\na tanh (Wasi−1 + Uahj) ,\\nwhere Wa ∈Rn×n,Ua ∈Rn×2n and va ∈Rn are the weight matrices. Since Uahj does not'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='depend on i, we can pre-compute it in advance to minimize the computational cost.\\n8 Here, we show the formula of the decoder. The same formula can be used in the encoder by simply\\nignoring the context vector ci and the related terms.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Published as a conference paper at ICLR 2015\\nA.2 D ETAILED DESCRIPTION OF THE MODEL\\nA.2.1 E NCODER\\nIn this section, we describe in detail the architecture of the proposed model (RNNsearch) used in the\\nexperiments (see Sec. 4–5). From here on, we omit all bias terms in order to increase readability.\\nThe model takes a source sentence of 1-of-K coded word vectors as input\\nx = (x1,...,x Tx ), xi ∈RKx\\nand outputs a translated sentence of 1-of-K coded word vectors\\ny = (y1,...,y Ty ), yi ∈RKy ,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='y = (y1,...,y Ty ), yi ∈RKy ,\\nwhere Kx and Ky are the vocabulary sizes of source and target languages, respectively. Tx and Ty\\nrespectively denote the lengths of source and target sentences.\\nFirst, the forward states of the bidirectional recurrent neural network (BiRNN) are computed:\\n− →hi =\\n{\\n(1 −− →zi) ◦− →hi−1 + − →zi ◦− →hi , if i> 0\\n0 , if i= 0\\nwhere\\n− →hi = tanh\\n(− →WExi + − →U\\n[− →ri ◦− →hi−1\\n])\\n− →zi =σ\\n(− →WzExi + − →Uz\\n− →hi−1\\n)\\n− →ri =σ\\n(− →WrExi + − →Ur\\n− →hi−1\\n)\\n.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='− →hi−1\\n)\\n− →ri =σ\\n(− →WrExi + − →Ur\\n− →hi−1\\n)\\n.\\nE ∈Rm×Kx is the word embedding matrix. − →W,− →Wz,− →Wr ∈Rn×m, − →U, − →Uz,− →Ur ∈Rn×n are\\nweight matrices. mand nare the word embedding dimensionality and the number of hidden units,\\nrespectively. σ(·) is as usual a logistic sigmoid function.\\nThe backward states (← −h1,··· ,← −hTx ) are computed similarly. We share the word embedding matrix\\nEbetween the forward and backward RNNs, unlike the weight matrices.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='We concatenate the forward and backward states to to obtain the annotations (h1,h2,··· ,hTx ),\\nwhere\\nhi =\\n[ − →hi← −hi\\n]\\n(7)\\nA.2.2 D ECODER\\nThe hidden state si of the decoder given the annotations from the encoder is computed by\\nsi =(1 −zi) ◦si−1 + zi ◦˜si,\\nwhere\\n˜si = tanh (WEyi−1 + U[ri ◦si−1] +Cci)\\nzi =σ(WzEyi−1 + Uzsi−1 + Czci)\\nri =σ(WrEyi−1 + Ursi−1 + Crci)\\nEis the word embedding matrix for the target language. W,Wz,Wr ∈Rn×m, U,Uz,Ur ∈Rn×n,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='and C,Cz,Cr ∈ Rn×2n are weights. Again, m and n are the word embedding dimensionality\\nand the number of hidden units, respectively. The initial hidden state s0 is computed by s0 =\\ntanh\\n(\\nWs\\n← −h1\\n)\\n,where Ws ∈Rn×n.\\nThe context vector ci are recomputed at each step by the alignment model:\\nci =\\nTx∑\\nj=1\\nαijhj,\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='Published as a conference paper at ICLR 2015\\nModel Updates (×105) Epochs Hours GPU Train NLL Dev. NLL\\nRNNenc-30 8.46 6.4 109 TITAN BLACK 28.1 53.0\\nRNNenc-50 6.00 4.5 108 Quadro K-6000 44.0 43.6\\nRNNsearch-30 4.71 3.6 113 TITAN BLACK 26.7 47.2\\nRNNsearch-50 2.88 2.2 111 Quadro K-6000 40.7 38.1\\nRNNsearch-50⋆ 6.67 5.0 252 Quadro K-6000 36.7 35.2\\nTable 2: Learning statistics and relevant information. Each update corresponds to updating the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='parameters once using a single minibatch. One epoch is one pass through the training set. NLL is\\nthe average conditional log-probabilities of the sentences in either the training set or the development\\nset. Note that the lengths of the sentences differ.\\nwhere\\nαij = exp (eij)∑Tx\\nk=1 exp (eik)\\neij =v⊤\\na tanh (Wasi−1 + Uahj) ,\\nand hj is the j-th annotation in the source sentence (see Eq. (7)). va ∈Rn′\\n,Wa ∈Rn′×n and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content=',Wa ∈Rn′×n and\\nUa ∈Rn′×2n are weight matrices. Note that the model becomes RNN Encoder–Decoder (Cho\\net al., 2014a), if we ﬁx ci to − →hTx .\\nWith the decoder statesi−1, the contextci and the last generated wordyi−1, we deﬁne the probability\\nof a target word yi as\\np(yi|si,yi−1,ci) ∝exp\\n(\\ny⊤\\ni Woti\\n)\\n,\\nwhere\\nti =\\n[\\nmax\\n{˜ti,2j−1,˜ti,2j\\n}]⊤\\nj=1,...,l\\nand ˜ti,k is the k-th element of a vector ˜ti which is computed by\\n˜ti =Uosi−1 + VoEyi−1 + Coci.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='˜ti =Uosi−1 + VoEyi−1 + Coci.\\nWo ∈RKy×l, Uo ∈R2l×n, Vo ∈R2l×m and Co ∈R2l×2n are weight matrices. This can be under-\\nstood as having a deep output (Pascanu et al., 2014) with a single maxout hidden layer (Goodfellow\\net al., 2013).\\nA.2.3 M ODEL SIZE\\nFor all the models used in this paper, the size of a hidden layer n is 1000, the word embedding\\ndimensionality mis 620 and the size of the maxout hidden layer in the deep output l is 500. The\\nnumber of hidden units in the alignment model n′is 1000.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='B T RAINING PROCEDURE\\nB.1 P ARAMETER INITIALIZATION\\nWe initialized the recurrent weight matrices U,Uz,Ur,← −U, ← −Uz,← −Ur,− →U, − →Uz and − →Ur as random or-\\nthogonal matrices. For Wa and Ua, we initialized them by sampling each element from the Gaussian\\ndistribution of mean 0 and variance 0.0012. All the elements of Va and all the bias vectors were ini-\\ntialized to zero. Any other weight matrix was initialized by sampling from the Gaussian distribution\\nof mean 0 and variance 0.012.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='of mean 0 and variance 0.012.\\nB.2 T RAINING\\nWe used the stochastic gradient descent (SGD) algorithm. Adadelta (Zeiler, 2012) was used to\\nautomatically adapt the learning rate of each parameter ( ϵ = 10−6 and ρ = 0.95). We explicitly\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='Published as a conference paper at ICLR 2015\\nnormalized the L2-norm of the gradient of the cost function each time to be at most a predeﬁned\\nthreshold of 1, when the norm was larger than the threshold (Pascanu et al., 2013b). Each SGD\\nupdate direction was computed with a minibatch of 80 sentences.\\nAt each update our implementation requires time proportional to the length of the longest sentence in\\na minibatch. Hence, to minimize the waste of computation, before every 20-th update, we retrieved'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='1600 sentence pairs, sorted them according to the lengths and split them into 20 minibatches. The\\ntraining data was shufﬂed once before training and was traversed sequentially in this manner.\\nIn Tables 2 we present the statistics related to training all the models used in the experiments.\\nC T RANSLATIONS OF LONG SENTENCES\\nSource An admitting privilege is the right of a doctor to admit a patient to a hospital or a medical centre'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='to carry out a diagnosis or a procedure, based on his status as a health care worker at a hospital.\\nReference Le privil`ege d’admission est le droit d’un m´edecin, en vertu de son statut de membre soignant\\nd’un hˆopital, d’admettre un patient dans un h ˆopital ou un centre m ´edical aﬁn d’y d ´elivrer un\\ndiagnostic ou un traitement.\\nRNNenc-50 Un privil`ege d’admission est le droit d’un m´edecin de reconnaˆıtre un patient `a l’hˆopital ou un'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='centre m´edical d’un diagnostic ou de prendre un diagnostic en fonction de son ´etat de sant´e.\\nRNNsearch-50 Un privil`ege d’admission est le droit d’un m ´edecin d’admettre un patient `a un h ˆopital ou un\\ncentre m´edical pour effectuer un diagnostic ou une proc´edure, selon son statut de travailleur des\\nsoins de sant´e `a l’hˆopital.\\nGoogle\\nTranslate\\nUn privil`ege admettre est le droit d’un m ´edecin d’admettre un patient dans un h ˆopital ou un'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='centre m ´edical pour effectuer un diagnostic ou une proc ´edure, fond ´ee sur sa situation en tant\\nque travailleur de soins de sant´e dans un hˆopital.\\nSource This kind of experience is part of Disney’s efforts to ”extend the lifetime of its series and build\\nnew relationships with audiences via digital platforms that are becoming ever more important,”\\nhe added.\\nReference Ce type d’exp ´erience entre dans le cadre des efforts de Disney pour ” ´etendre la dur ´ee de'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='vie de ses s ´eries et construire de nouvelles relations avec son public gr ˆace `a des plateformes\\nnum´eriques qui sont de plus en plus importantes”, a-t-il ajout´e.\\nRNNenc-50 Ce type d’exp´erience fait partie des initiatives du Disney pour ”prolonger la dur ´ee de vie de\\nses nouvelles et de d´evelopper des liens avec les lecteurs num´eriques qui deviennent plus com-\\nplexes.\\nRNNsearch-50 Ce genre d’exp´erience fait partie des efforts de Disney pour ”prolonger la dur ´ee de vie de ses'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='s´eries et cr ´eer de nouvelles relations avec des publics via des plateformes num ´eriques de plus\\nen plus importantes”, a-t-il ajout´e.\\nGoogle\\nTranslate\\nCe genre d’exp´erience fait partie des efforts de Disney `a “´etendre la dur´ee de vie de sa s ´erie et\\nconstruire de nouvelles relations avec le public par le biais des plates-formes num ´eriques qui\\ndeviennent de plus en plus important”, at-il ajout´e.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='Source In a press conference on Thursday, Mr Blair stated that there was nothing in this video that might\\nconstitute a ”reasonable motive” that could lead to criminal charges being brought against the\\nmayor.\\nReference En conf´erence de presse, jeudi, M. Blair a afﬁrm´e qu’il n’y avait rien dans cette vid´eo qui puisse\\nconstituer des ”motifs raisonnables” pouvant mener au d´epˆot d’une accusation criminelle contre\\nle maire.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='le maire.\\nRNNenc-50 Lors de la conf´erence de presse de jeudi, M. Blair a dit qu’il n’y avait rien dans cette vid´eo qui\\npourrait constituer une ”motivation raisonnable” pouvant entraˆıner des accusations criminelles\\nport´ees contre le maire.\\nRNNsearch-50 Lors d’une conf´erence de presse jeudi, M. Blair a d´eclar´e qu’il n’y avait rien dans cette vid´eo qui\\npourrait constituer un ”motif raisonnable” qui pourrait conduire `a des accusations criminelles\\ncontre le maire.\\nGoogle\\nTranslate'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='contre le maire.\\nGoogle\\nTranslate\\nLors d’une conf´erence de presse jeudi, M. Blair a d ´eclar´e qu’il n’y avait rien dans cette vido\\nqui pourrait constituer un ”motif raisonnable” qui pourrait mener `a des accusations criminelles\\nportes contre le maire.\\nTable 3: The translations generated by RNNenc-50 and RNNsearch-50 from long source sentences\\n(30 words or more) selected from the test set. For each source sentence, we also show the gold-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2016-05-23T00:19:15+00:00', 'author': '', 'keywords': '', 'moddate': '2016-05-23T00:19:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='standard translation. The translations by Google Translate were made on 27 August 2014.\\n15')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "final_documents=text_splitter.split_documents(docs)\n",
    "final_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Header Text Splitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Heading Example</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            text-align: center;\n",
    "            padding: 20px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Main Heading (H1)</h1>\n",
    "    <p>This is the primary heading of the page.</p>\n",
    "\n",
    "    <h2>Subheading (H2)</h2>\n",
    "    <p>This is a subheading that provides more details.</p>\n",
    "\n",
    "    <h3>Smaller Heading (H3)</h3>\n",
    "    <p>This heading is used for further subdivisions.</p>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\")\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Main Heading (H1)'}, page_content='Main Heading (H1)'),\n",
       " Document(metadata={'Header 1': 'Main Heading (H1)'}, page_content='This is the primary heading of the page.'),\n",
       " Document(metadata={'Header 1': 'Main Heading (H1)', 'Header 2': 'Subheading (H2)'}, page_content='Subheading (H2)'),\n",
       " Document(metadata={'Header 1': 'Main Heading (H1)', 'Header 2': 'Subheading (H2)'}, page_content='This is a subheading that provides more details.'),\n",
       " Document(metadata={'Header 1': 'Main Heading (H1)', 'Header 2': 'Subheading (H2)', 'Header 3': 'Smaller Heading (H3)'}, page_content='Smaller Heading (H3)'),\n",
       " Document(metadata={'Header 1': 'Main Heading (H1)', 'Header 2': 'Subheading (H2)', 'Header 3': 'Smaller Heading (H3)'}, page_content='This heading is used for further subdivisions.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='End header wrapper  \\n    End content  \\n    End footer  \\nEnd header  \\nEnd navigation  \\n \\n  End search  \\nStanford Encyclopedia of Philosophy  \\nMenu  \\nBrowse  \\nTable of Contents  \\nWhat\\'s New  \\nRandom Entry  \\nChronological  \\nArchives  \\nAbout  \\nEditorial Information  \\nAbout the SEP  \\nEditorial Board  \\nHow to Cite the SEP  \\nSpecial Characters  \\nAdvanced Tools  \\nContact  \\nSupport SEP  \\nSupport the SEP  \\nPDFs for SEP Friends  \\nMake a Donation  \\nSEPIA for Libraries  \\nBegin article sidebar  \\n \\n  End article sidebar  \\n  NOTE: Article content must have two wrapper divs: id=\"article\" and id=\"article-content\"  \\n    End article  \\n  NOTE: article banner is outside of the id=\"article\" div.  \\n    End article-banner  \\nEntry Navigation  \\nEntry Contents  \\nBibliography  \\nAcademic Tools  \\nFriends PDF Preview  \\nAuthor and Citation Info  \\nBack to Top  \\nEnd article-content  \\nBEGIN ARTICLE HTML  \\n  #aueditable  DO NOT MODIFY THIS LINE AND BELOW \\n  END ARTICLE HTML  \\nDO NOT MODIFY THIS LINE AND ABOVE'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='Kurt Gödel'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='First published Tue Feb 13, 2007; substantive revision Fri Dec 11, 2015  \\nKurt Friedrich Gödel (b. 1906, d. 1978) was one of the principal\\nfounders of the modern, metamathematical era in mathematical logic. He\\nis widely known for his Incompleteness Theorems, which are among the\\nhandful of landmark theorems in twentieth century mathematics, but his\\nwork touched every field of mathematical logic, if it was not in most\\ncases their original stimulus. In his philosophical work Gödel\\nformulated and defended mathematical Platonism, the view that\\nmathematics is a descriptive science, or alternatively the view that\\nthe concept of mathematical truth is objective. On the basis of that\\nviewpoint he laid the foundation for the program of conceptual\\nanalysis within set theory (see below). He adhered to Hilbert’s\\n“original rationalistic conception” in mathematics (as he\\ncalled\\n it); \\n and he was prophetic in anticipating and emphasizing the importance\\nof large cardinals in set theory before their importance became\\nclear.  \\n[ ]  \\n1  \\nEntry Contents \\n \\n Entry Contents  \\n1. Biographical Sketch  \\n2. Gödel’s Mathematical Work  \\n2.1 The Completeness Theorem  \\n2.1.1 Introduction  \\n2.1.2 Proof of the Completeness Theorem  \\n2.1.3 An Important Consequence of the Completeness Theorem  \\n2.2 The Incompleteness Theorems  \\n2.2.1 The First Incompleteness Theorem  \\n2.2.2 The proof of the First Incompleteness Theorem  \\n2.2.3 The Second Incompleteness Theorem  \\nSupplementary Document: Did the Incompleteness Theorems Refute Hilbert’s Program?  \\n2.3 Speed-up Theorems  \\n2.4 Gödel’s Work in Set theory  \\n2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice  \\n2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory  \\n2.4.3 Consequences of Consistency  \\n2.4.4 Gödel’s view of the Axiom of Constructibility  \\n2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic  \\n2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued  \\n2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic  \\n2.5.3 Intuitionistic Propositional Logic is Interpretable in  \\nS4  \\n2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.  \\nSupplement Document: Gödel’s Documents  \\n3. Gödel’s Philosophical Views  \\n3.1 Gödel’s Rationalism  \\n3.2 Gödel’s Realism  \\nSupplementary Document: Gödel’s Turn to Phenomenology  \\nSupplementary Document: A Philosophical Argument About the Content of Mathematics  \\nBibliography  \\nPrimary Sources  \\nGödel’s Writings  \\nThe Collected Papers of Kurt Gödel  \\nSelected Works of Kurt Gödel  \\nSecondary Sources  \\nAcademic Tools  \\nOther Internet Resources  \\nRelated Entries  \\n1. Biographical Sketch  \\nKurt Gödel was born on April 28, 1906 in what was then the\\nAustro-Hungarian city of Brünn, and what is now Brno in the Czech\\nRepublic.  \\nGödel’s father Rudolf August was a businessman, and his\\nmother Marianne was a well-educated and cultured woman to whom\\nGödel remained close throughout his life, as witnessed by the\\nlong and wide-ranging correspondence between them. The family was well\\noff, and Gödel’s childhood was an uneventful one, with one\\nimportant exception; namely, from about the age of four Gödel\\nsuffered frequent episodes of poor health, and the health problems he\\nsuffered then as well as others of various kinds were to plague him\\nhis entire life.  \\nHealth problems notwithstanding, Gödel proved to be an exemplary\\nstudent at primary school and later the Gymnasium, excelling\\nespecially in mathematics, languages and religion. Upon his graduation\\nfrom the Gymnasium in Brno in 1924 Gödel enrolled in the\\nUniversity of Vienna, attending lectures on physics, his initial field\\nof interest, lectures on philosophy given by Heinrich Gomperz, and\\nlectures on mathematics. Gödel took a number of physics courses\\nduring his undergraduate years, as witnessed by his university\\ntranscript; this is notable in view of Gödel’s subsequent\\ncontributions to relativity in 1947. Philipp Furtwängler, cousin\\nof the great German conductor Wilhelm Furtwängler, was one of his\\nmathematics professors, and indeed Furtwängler’s course on\\nclass field theory almost tempted Gödel to pursue his studies in\\nthat area. Gödel learned his logic from Rudolph Carnap and from\\nHans Hahn, eventually graduating under Hahn with a Dr.phil. in\\nmathematics in 1929. The main theorem of his dissertation was the\\ncompleteness theorem for first order logic (Gödel\\n 1929).  \\n[ ]  \\n2  \\nGödel’s university years also marked the beginning of his\\nattendance at meetings of the Vienna Circle, a group around Moritz\\nSchlick that quickly became known as “logical\\npositivists,” a term coined by Feigl and Blumberg in their 1931\\n“Logical positivism: A new movement in European\\nphilosophy” (Feigl and Blumberg 1931). Though Gödel was not\\nhimself a logical positivist, those discussions were a crucial\\nformative influence.  \\nThe 1930s were a prodigious decade for Gödel. After publishing\\nhis 1929 dissertation in 1930, he published his groundbreaking\\nincompleteness theorems in 1931, on the basis of which he was granted\\nhis Habilitation in 1932 and a Privatdozentur at the University of\\nVienna in 1933.  \\nAmong his mathematical achievements at the decade’s close is the\\nproof of the consistency of both the Axiom of Choice and\\nCantor’s Continuum Hypothesis with the Zermelo-Fraenkel axioms\\nfor set theory, obtained in 1935 and 1937, respectively. Gödel\\nalso published a number of significant papers on modal and\\nintuitionistic logic and arithmetic during this period, principal\\namong which is his “On intuitionistic arithmetic and number\\ntheory,” (Gödel 1933e), in which he showed that classical\\nfirst order arithmetic is interpretable in Heyting arithmetic by a\\nsimple translation. Other publications of the 1930s include those on\\nthe decision problem for the predicate calculus, on the length of\\nproofs, and on differential and projective geometry.  \\nBy the end of the decade both Gödel’s advisor Hans Hahn and\\nMoritz Schlick had died (the latter was assassinated by an\\nex-student), two events which led to a personal crisis for Gödel.\\nAlso, his appointment at the University, that of Privatdozentur, was\\ncancelled, being replaced by the position “Dozentur neuer\\nOrdnung,” granted to candidates only after they had passed a\\nracial\\n test. \\n Gödel’s three trips the United States during that decade\\ntriggered an investigation. (See Sigmund 2006.) Finally, Gödel\\nwas found fit for military service by the Nazi government in 1939.  \\n[ ]  \\n3  \\nAll of these events were decisive in influencing his decision to leave\\nAustria in 1940, when he and his wife Adele emigrated to the United\\nStates. This long and difficult episode in their life is recounted by\\nJohn Dawson in his biography of Gödel called “Logical\\nDilemmas,” (Dawson 1997) as well as by Solomon Feferman in\\n“Gödel’s Life and Work,” (Feferman 1986) to\\nboth of which the reader is referred.  \\nUpon arrival Gödel took up an appointment as an ordinary member\\nat the Institute for Advanced Study; he would become a permanent\\nmember of the Institute in 1946 and would be granted his professorship\\nin 1953. (Gödel and his wife were granted American citizenship in\\nApril 1948.) He would remain at the Institute until his retirement in\\n1976. The Gödels never returned to Europe.  \\nGödel’s early years at the Institute were notable for his\\nclose friendship with his daily walking partner Albert Einstein, as\\nwell as for his turn to philosophy of mathematics, a field on which\\nGödel began to concentrate almost exclusively from about 1943.\\nThe initial period of his subsequent lifelong involvement with\\nphilosophy was a fruitful one (in terms of publications): in 1944 he\\npublished his first philosophical paper, entitled “On\\nRussell’s Mathematical Logic” (Gödel 1944), and in\\n1947 he published his second, entitled “What is Cantor’s\\nContinuum Hypothesis?” (Gödel 1947). In 1949 he published\\nhis third, entitled “A Remark on the Relationship between\\nRelativity Theory and Idealistic Philosophy.” (Gödel\\n1949a). The latter paper coincided with results on rotating universes\\nin relativity he had obtained in 1949, which were first published in\\nan article entitled: “An Example of a New Type of Cosmological\\nSolutions of Einstein’s Field Equations of Gravitation.”\\n(Gödel 1949).  \\nAmong Gödel’s other significant philosophical works of the\\n1940s must be counted his 1941 lecture entitled “In What Sense\\nis Intuitionistic Logic Constructive?” (Gödel *1941) in\\nwhich the notion: “computable function of finite type” is\\nintroduced. A paper based on the ideas in the lecture entitled\\n“Über eine bisher noch nicht benützte Erweiterung des\\nfiniten Standpunktes,” was published only in 1958, and the\\ninterpretation of Heyting arithmetic into the quantifier free calculus\\n  in it became known as the “Dialectica\\nInterpretation,” after the journal in which the article was\\npublished (Gödel 1958). (For the revision of it from 1972, see\\nGödel 1995.) Finally the decade saw the beginning of\\nGödel’s intensive study of Leibniz, which, Gödel\\nreports, occupied the period from 1943 to\\n 1946.  \\nT  \\n[ ]  \\n4  \\nThe 1950s saw a deepening of Gödel’s involvement with\\nphilosophy: In 1951 Gödel delivered a philosophical lecture at\\nBrown University, usually referred to as the Gibbs Lecture, entitled\\n“Some Basic Theorems on the Foundations of Mathematics and Their\\nPhilosophical Implications” (Gödel *1951). From 1953 to\\n1959 Gödel worked on a submission to the Schilpp volume on Rudolf\\nCarnap entitled “Is Mathematics a Syntax of Language?”\\n(Gödel *1953/9-III, Gödel *1953/9-V). Gödel published\\nneither of these two important manuscripts in his lifetime, although\\nboth would appear on two lists which were found in the Gödel\\nNachlass, entitled “Was ich publizieren könnte.” (In\\nEnglish: “What I could publish.” Both manuscripts\\neventually appeared in Gödel 1995.) By the decade’s close\\nGödel developed a serious interest in\\n phenomenology.  \\n[ ]  \\n5  \\nGödel’s final years are notable for his circulation of two\\nmanuscripts: “Some considerations leading to the probable\\nconclusion that the true power of the continuum is\\nℵ ,” (Gödel *1970a, *1970b) his attempt\\nto derive the value of the continuum from the so-called scale axioms\\nof Hausdorff, and his “Ontologischer Beweis,” (Gödel\\n*1970) which he entrusted to Dana Scott in 1970 (though it appears to\\nhave been written earlier). Taken together, the two manuscripts are\\nthe fitting last words of someone who, in a fifty year involvement\\nwith mathematics and philosophy, pursued, or more precisely,\\n  for pursuing those two subjects under the\\nsingle heading: “strenge Wissenschaft”—a turn of\\nmind that had been in place from Gödel’s start in 1929,\\nwhen at the age of twenty-three he opened his doctoral thesis with\\nsome philosophical remarks.  \\n2  \\nsought the grounds  \\nGödel died in Princeton on January 14, 1978 at the age of 71. His\\ndeath certificate records the cause of death as “starvation and\\ninanition, due to personality disorder.” His wife Adele survived\\nhim by three years.  \\nFor further biographical material, see Gödel 1987, Kleene 1987,\\nKreisel 1980, Taussky-Todd 1987 and Yourgrau 2005.  \\n2. Gödel’s Mathematical Work  \\nBelow is an examination of some of Gödel’s main\\ncontributions in logic and set theory. This treatment of\\nGödel’s technical work is not exhaustive, omitting\\ndiscussion of Gödel’s work in physics and his work on the\\ndecision problem. These will be treated in the sequel to this\\nentry.  \\nFor a complete chronology of Gödel’s work the reader is\\nreferred to that compiled by John Dawson in volume I of\\nGödel’s Collected Works (Gödel 1986, p. 37).  \\n2.1 The Completeness Theorem  \\n2.1.1 Introduction  \\nThe completeness question for the first order predicate calculus was\\nstated precisely and in print for the first time in 1928 by Hilbert\\nand Ackermann in their text   (Hilbert and Ackermann 1928), a text with which Gödel\\nwould have been quite\\n familiar.  \\nGrundzüge der theoretischen\\nLogik  \\n[ ]  \\n6  \\nThe question Hilbert and Ackermann pose is whether a certain\\nexplicitly given axiom system for the first order predicate calculus\\n“…is complete in the sense that from it all logical\\nformulas that are correct for each domain of individuals can be\\nderived…” (van Heijenoort 1967, p. 48).  \\n2.1.2 Proof of the Completeness Theorem  \\nWe give an outline of Gödel’s own proof in his doctoral\\nthesis (Gödel 1929). An essential difference with earlier efforts\\n(discussed below and elsewhere, e.g. in Zach 1999), is that Gödel\\ndefines meticulously all the relevant basic concepts.  \\nA “logical expression” in Gödel’s terminology\\nis a well-formed first order formula without identity. An expression\\nis “refutable” if its negation is provable,\\n“valid” if it is true in every interpretation and\\n“satisfiable” if it is true in some interpretation. The\\nCompleteness Theorem is stated as follows:  \\n.\\n \\nEvery valid logical expression is provable. Equivalently, every\\nlogical expression is either satisfiable or refutable.  \\nTheorem 1  \\nGödel’s proof calculus is that of Hilbert and\\nAckermann’s text. An expression is in normal form if all the\\nquantifiers occur at the beginning. The degree of an expression or\\nformula is the number of alternating blocks of quantifiers at the\\nbeginning of the formula, assumed to begin with universal quantifiers.\\nGödel shows that if the completeness theorem holds for formulas\\nof degree   it must hold for formulas of degree   +\\n1. Thus the question of completeness reduces to formulas of degree 1.\\nThat is, it is to be shown that any normal formula ( )φ\\nof degree 1 is either satisfiable or refutable, where\\n“( )” stands for a (non-empty) block of universal\\nquantifiers followed by a (possibly empty) block of existential\\nones.  \\nk  \\nk  \\nQ  \\nQ  \\nGödel defines a book-keeping device, a well-ordering of all\\ntuples of variables arising from a need to satisfy φ as dictated\\nby ( ). For example, if ( )φ is\\n∀ ∃ ψ( ,\\n ), we list the quantifier-free formulas\\nψ( ,\\n ). (Or more precisely, finite\\nconjunctions of these in increasing length. See below.) Then in any\\ndomain consisting of the values of the different\\n , in which each\\nψ( ,  ) is\\ntrue, the sentence ( )φ is clearly true. A crucial lemma\\nclaims the provability, for each  , of the formula\\n( )φ →\\n( )φ , where the\\nquantifier free formula φ  asserts the truth\\nof ψ for all tuples up to the kth tuple of variables arising from\\n( ), and\\n( )φ  is the\\nexistential closure of φ . (See the example\\nbelow where the definition of the φ s\\nis given.) This lemma is the main step missing from the various\\nearlier attempts at the proof due to Löwenheim and Skolem, and,\\nin the context of the completeness theorem for first order logic,\\nrenders the connection between syntax and semantics completely\\nexplicit.  \\nQ  \\nQ  \\nx  \\n0  \\nx  \\n1  \\nx  \\n0  \\nx  \\n1  \\nx  \\nn  \\nx  \\n+1  \\nn  \\nx  \\nn  \\nx  \\nn  \\nx  \\nn+1  \\nQ  \\nk  \\nQ  \\nQ  \\nk  \\nk  \\nk  \\nQ  \\nQ  \\nk  \\nk  \\nk  \\n′  \\nk  \\nLet us consider an example of how a particular formula would be found\\nto be either satisfiable or its negation provable, following\\nGödel’s method: Consider φ =\\n∀ ∃ ψ( ,\\n ), where ψ( ,\\n ) is quantifier-free. We show that this is\\neither refutable or satisfiable. We make the following\\ndefinitions:  \\nx  \\n0  \\nx  \\n1  \\nx  \\n0  \\nx  \\n1  \\nx  \\n0  \\nx  \\n1  \\nφ  is the expression\\nψ( ,  )  \\n0  \\nx  \\n0  \\nx  \\n1  \\nφ  is the expression\\nψ( ,  ) ∧\\nψ( ,  )  \\n1  \\nx  \\n0  \\nx  \\n1  \\nx  \\n1  \\nx  \\n2  \\n…  \\nφ  is the expression\\nψ( ,  ) ∧\\n…∧ ψ( ,\\n ).  \\nn  \\nx  \\n0  \\nx  \\n1  \\nx  \\nn  \\nx  \\n+1  \\nn  \\nThe crucial lemma, referred to above, shows that from φ we can\\nderive for each  ,\\n∃ …∃ φ .  \\nn  \\nx  \\n0  \\nx  \\n+1  \\nn  \\nn  \\nFor some  ,\\nφ  is not satisfiable. Then, Gödel\\nargued, using the already known completeness theorem for propositional\\n logic, \\n that ¬φ  is provable, and hence so is\\n∀ ,…,\\n ¬φ . Thus\\n¬∃ …∃ φ \\nis provable and therefore the ¬φ is provable, i.e., φ is\\nrefutable in the Hilbert-Ackermann system. (Some partial results about\\npropositional logic in addition to those already mentioned include the\\nsemantic completeness of the propositional calculus due to Post\\n(1921), as well as a more general completeness theorem for the same\\ndue to Bernays in 1918; the latter appears in Bernays’\\nunpublished   of 1918; see also Bernays\\n1926.)  \\nCase 1:  \\nn  \\nn  \\n[ ]  \\n7  \\nn  \\nx  \\n0  \\nx  \\n+1  \\nn  \\nn  \\nx  \\n0  \\nx  \\n+1  \\nn  \\nn  \\nHabilitationsschrift  \\nEach φ  is\\nsatisfiable. There are only finitely many possible models with\\nuniverse { ,…,  }.\\nGödel orders them as a tree by defining a model   to be\\nbelow a model  ′ if   is a submodel of\\n ′. In this way we obtain a tree which is finitely\\nbranching but infinite. By König’s Lemma there is an\\ninfinite branch  . (In the proof, Gödel explicitly\\nconstructs the branch given by König’s Lemma rather than\\nciting it by name.) The union of the models on   forms a\\nmodel   with universe { ,\\n ,…}. Since   satisfies each\\nφ , the original formula φ holds in\\n . So φ is satisfiable and we are done.  \\nCase 2:  \\nn  \\nx  \\n0  \\nx  \\nn+1  \\nM  \\nM  \\nM  \\nM  \\nB  \\nB  \\nM  \\nx  \\n0  \\nx  \\n1  \\nM  \\nn  \\nM  \\nNote that the model, in the satisfiability case of Gödel’s\\nproof, is always countable. Thus this proof of the Completeness\\nTheorem gives also the Löweheim-Skolem Theorem (see below).\\nGödel extends the result to countably many formulas and to the\\ncase of first order logic with identity. He also proves the\\nindependence of the axioms.  \\nIn 1930 Gödel published the paper based on his thesis (Gödel\\n1930) notable also for the inclusion of the compactness theorem, which\\nis only implicitly stated in the thesis. The theorem as stated by\\nGödel in Gödel 1930 is as follows: a countably infinite set\\nof quantificational formulas is satisfiable if and only if every\\nfinite subset of those formulas is satisfiable. Gödel uses\\ncompactness to derive a generalization of the completeness\\ntheorem.  \\nThe Compactness Theorem was extended to the case of uncountable\\nvocabularies by Maltsev in 1936 (see Mal’cev 1971), from which\\nthe Upward Löwenheim-Skolem theorem immediately follows. The\\nCompactness Theorem would become one of the main tools in the then\\nfledgling subject of model theory.  \\n2.1.3 An Important Consequence of the Completeness Theorem  \\nA theory is said to be categorical if it has only one model up to\\nisomorphism; it is λ-categorical if it has only one model of\\ncardinality λ, up to isomorphism. One of the main consequences\\nof the completeness theorem is that categoricity fails for Peano\\narithmetic and for Zermelo-Fraenkel set theory.  \\nIn detail, regarding the first order Peano axioms (henceforth\\n ), the existence of non-standard models of them actually\\nfollows from completeness together with compactness. One constructs\\nthese models, which contain infinitely large integers, as follows: add\\na new constant symbol   to the language of arithmetic. Extend\\n  to a new theory  * by adding to it the infinite\\ncollection of axioms: {  >  ,   >\\n , …}, where, e.g.,   is S(S(S(0))).  *\\nis finitely consistent (i.e., every finite subset of  * is\\nconsistent) hence consistent, hence by the Completeness Theorem it has\\na model.  \\nPA  \\nc  \\nPA  \\nPA  \\nc  \\n0  \\nc  \\n1  \\n3  \\nPA  \\nPA  \\nThis simple fact about models of Peano arithmetic was not pointed out\\nby Gödel in any of the publications connected with the\\nCompleteness Theorem from that time, and it seems not to have been\\nnoticed by the general logic community until much later.\\nSkolem’s definable ultrapower construction from 1933 (see Skolem\\n1933) gives a direct construction of a non-standard model of True\\nArithmetic (which extends Peano arithmetic, being the set of\\narithmetic sentences true in the natural numbers). But Skolem never\\nmentions the fact that the existence of such models follows from the\\ncompleteness and compactness theorems. Gödel in his review\\n(1934c) of Skolem’s paper also does not mention this fact,\\nrather observing that the failure of categoricity for arithmetic\\nfollows from the   theorem.  \\nincompleteness  \\nAs for set theory, the failure of categoricity was already taken note\\nof by Skolem in 1923, because it follows from the\\nLöwenheim-Skolem Theorem (which Skolem arrived at that year; see\\nSkolem 1923, based on Löwenheim 1915 and Skolem 1920): any first\\norder theory in a countable language that has a model has a countable\\nmodel.  \\nSkolem’s observation that categoricity fails for set theory\\nbecause it has countable models is now known as the Skolem\\n paradox. The\\n observation is strongly emphasized in Skolem’s paper, which is\\naccordingly entitled ‘An Observation on the Axiomatic\\nFoundations of Set Theory’ As he wrote in the conclusion of it,\\nhe had not pointed out the relativity in set theory already in 1915\\nbecause:  \\n[ ]  \\n8  \\n… first, I have in the meantime been occupied with other\\nproblems; second, I believed that it was so clear that axiomatization\\nin terms of sets was not a satisfactory ultimate foundation of\\nmathematics that mathematicians would, for the most part, not be very\\nmuch concerned with it. But in recent times I have seen to my surprise\\nthat so many mathematicians think that these axioms of set theory\\nprovide the ideal foundation for mathematics; therefore it seemed to\\nme that the time had come to publish a critique. (English translation\\ntaken from van Heijenoort 1967, p. 300.)  \\nAs an aside, in the proof of the Löwenheim-Skolem theorem,\\nspecifically that part of the theorem in which one constructs a model\\nfor a satisfiable sentence, Löwenheim and Skolem’s tree\\nconstruction was more or less the same as appears in\\nGödel’s thesis. In a 1967 letter to Hao Wang, Gödel\\ntakes note of the fact that his completeness proof had almost been\\nobtained by Skolem in 1923. Though van Heijenoort and Dreben (Dreben\\nand van Heijenoort 1986) remark that “Throughout much of the\\n1920s it was not semantic completeness but the decision problem for\\nquantificational validity, a problem originating from the work of\\nSchröder and Löwenheim, that was the dominant concern in\\nstudying quantification theory” (examples of such results would\\ninclude the decision procedure for the first order monadic predicate\\ncalculus due to Behmann, (Behmann 1922)), according to Gödel, the\\nreasons that Skolem did not obtain the complete proof are different\\nand philosophically important, having to do with the then dominant\\nbias against semantics and against infinitary methods:  \\nThe Completeness Theorem, mathematically, is indeed an almost trivial\\nconsequence of Skolem 1923. However, the fact is that, at that time,\\nnobody (including Skolem himself) drew this conclusion neither from\\nSkolem 1923 nor, as I did, from similar considerations of his own\\n…This blindness (or prejudice, or whatever you may call it) of\\nlogicians is indeed surprising. But I think the explanation is not\\nhard to find. It lies in the widespread lack, at that time, of the\\nrequired epistemological attitude toward metamathematics and toward\\nnon-finitary reasoning. (Gödel 2003b).  \\nThe matter of Skolem’s contribution to the Completeness Theorem\\nhas been extensively discussed in van Atten and Kennedy 2009, as well\\nas in van Atten 2005.  \\n2.2 The Incompleteness Theorems  \\nGödel mentioned the possibility of the unsolvability of a\\nquestion about the reals already in his 1929 thesis, in arguing\\nagainst the formalist principle of Hilbert’s, that consistency\\nis a criterion for existence. In fact, giving a finitary proof of the\\nconsistency of analysis was a key desideratum of what was then known\\nas the Hilbert program, along with proving its completeness.\\nAccordingly it was Gödel’s turn to these questions,\\nespecially the first, which led him to the two incompleteness\\ntheorems. (For a discussion of the Hilbert Program the reader is\\nreferred to the standard references: Sieg 1990, 1988, 1999; Mancosu\\n1998, Zach 2003, Tait 1981 and Tait 2002.)  \\nThe First Incompleteness Theorem provides a counterexample to\\ncompleteness by exhibiting an arithmetic statement which is neither\\nprovable nor refutable in Peano arithmetic, though true in the\\nstandard model. The Second Incompleteness Theorem shows that the\\nconsistency of arithmetic cannot be proved in arithmetic itself. Thus\\nGödel’s theorems demonstrated the infeasibility of the\\nHilbert program, if it is to be characterized by those particular\\ndesiderata, consistency and completeness.  \\nAs an aside, von Neumann understood the two theorems this way, even\\nbefore Gödel did. In fact von Neumann went much further in taking\\nthe view that they showed the infeasibility of classical mathematics\\naltogether. As he wrote to Carnap in June of 1931:  \\nThus today I am of the opinion that 1. Gödel has shown the\\nunrealizability of Hilbert’s program. 2. There is no more reason\\nto reject intuitionism (if one disregards the aesthetic issue, which\\nin practice will also for me be the decisive factor). Therefore I\\nconsider the state of the foundational discussion in Königsberg\\nto be outdated, for Gödel’s fundamental discoveries have\\nbrought the question to a completely different\\n level.  \\n[ ]  \\n9  \\nAnd the previous fall von Neumann had written to Gödel in even\\nstronger terms:  \\nThus, I think that your result has solved negatively the foundational\\nquestion: there is no rigorous justification for classical\\nmathematics. (Gödel 2003b, p. 339)  \\nIt would take Gödel himself a few years to see that those aspects\\nof the Hilbert Program had been decisively refuted by his results\\n(Mancosu 2004).  \\n2.2.1 The First Incompleteness Theorem  \\nIn his   (Wang 1996) Hao Wang published the\\nfull text of material Gödel had written (at Wang’s request)\\nabout his discovery of the incompleteness theorems. This material had\\nformed the basis of Wang’s “Some Facts about Kurt\\nGödel,” and was read and approved by Gödel:  \\nLogical Journey  \\nIn the summer of 1930 I began to study the consistency problem of\\nclassical analysis. It is mysterious why Hilbert wanted to prove\\ndirectly the consistency of analysis by finitary methods. I saw two\\ndistinguishable problems: to prove the consistency of number theory by\\nfinitary number theory and to prove the consistency of analysis by\\nnumber theory … Since the domain of finitary number theory was\\nnot well-defined, I began by tackling the second half… I\\nrepresented real numbers by predicates in number theory… and\\nfound that I had to use the concept of truth (for number theory) to\\nverify the axioms of analysis. By an enumeration of symbols, sentences\\nand proofs within the given system, I quickly discovered that the\\nconcept of arithmetic truth cannot be defined in arithmetic. If it\\nwere possible to define truth in the system itself, we would have\\nsomething like the liar paradox, showing the system to be\\ninconsistent… Note that this argument can be formalized to show\\nthe existence of undecidable propositions without giving any\\nindividual instances. (If there were no undecidable propositions, all\\n(and only) true propositions would be provable within the system. But\\nthen we would have a contradiction.)… In contrast to truth,\\nprovability in a given formal system is an explicit combinatorial\\nproperty of certain sentences of the system, which is formally\\nspecifiable by suitable elementary means…  \\nWe see that Gödel first tried to reduce the consistency problem\\nfor analysis to that of arithmetic. This seemed to require a truth\\ndefinition for arithmetic, which in turn led to paradoxes, such as the\\nLiar paradox (“This sentence is false”) and Berry’s\\nparadox (“The least number not defined by an expression\\nconsisting of just fourteen English words”). Gödel then\\nnoticed that such paradoxes would not necessarily arise if truth were\\nreplaced by provability. But this means that arithmetic truth and\\narithmetic provability are not co-extensive — whence the First\\nIncompleteness Theorem.  \\nThis account of Gödel’s discovery was told to Hao Wang very\\nmuch after the fact; but in Gödel’s contemporary\\ncorrespondence with Bernays and Zermelo, essentially the same\\ndescription of his path to the theorems is given. (See Gödel\\n2003a and Gödel 2003b respectively.) From those accounts we see\\nthat the undefinability of truth in arithmetic, a result credited to\\nTarski, was likely obtained in some form by Gödel by 1931. But he\\nneither publicized nor published the result; the biases logicians had\\nexpressed at the time concerning the notion of truth, biases which\\ncame vehemently to the fore when Tarski announced his results on the\\nundefinability of truth in formal systems 1935, may have served as a\\ndeterrent to Gödel’s publication of that theorem.  \\n2.2.2 The proof of the First Incompleteness Theorem  \\nWe now describe the proof of the two theorems, formulating\\nGödel’s results in Peano arithmetic. Gödel himself\\nused a system related to that defined in Principia Mathematica, but\\ncontaining Peano arithmetic. In our presentation of the First and\\nSecond Incompleteness Theorems we refer to Peano arithmetic as\\n , following Gödel’s notation.  \\nP  \\nBefore proceeding to the details of the formal proof, we define the\\nnotion of ω-consistency used by Gödel in the First\\nIncompleteness Theorem:   is   if\\n  ⊢ ¬φ( ) for all  \\nimplies   ⊬ ∃ φ( ).\\nNaturally this implies consistency and follows from the assumption\\nthat the natural numbers satisfy the axioms of Peano arithmetic.  \\nP  \\nω-consistent  \\nP  \\nn  \\nn  \\nP  \\nx  \\nx  \\nOne of the main technical tools used in the proof is  , a mechanism which assigns natural numbers to terms and\\nformulas of our formal theory  . There are different ways of\\ndoing this. The most common is based on the unique representation of\\nnatural numbers as products of powers of primes. Each symbol\\n  of number theory is assigned a positive natural number\\n#( ) in a fixed but arbitrary way, e.g.  \\nGödel\\nnumbering  \\nP  \\ns  \\ns  \\n#(0) = 1  \\n#(=) = 5  \\n#(¬) = 9  \\n#(1) = 2  \\n#(\\u2009(\\u2009) = 6  \\n#(∀) = 10  \\n#(+) = 3  \\n#(\\u2009)\\u2009) = 7  \\n#( ) = 11 +  \\nv  \\ni  \\ni  \\n#(×) = 4  \\n#(∧) = 8  \\nThe natural number corresponding to a sequence   = <\\n ,…,   >\\nof symbols is  \\nw  \\nw  \\n0  \\nw  \\nk  \\n=\\n2  ·\\n3  · … ·\\n ,  \\n⌈  \\nw  \\n⌉  \\n#( )  \\nw  \\n0  \\n#( )  \\nw  \\n1  \\np  \\nk  \\n#( )  \\nw  \\nk  \\nwhere   is the  +1st prime. It\\nis called its Gödel number and denoted by\\n . In this way we can\\nassign Gödel numbers to formulas, sequences of formulas (once a\\nmethod for distinguishing when one formula ends and another begins has\\nbeen adopted), and most notably, proofs.  \\np  \\nk  \\nk  \\n⌈  \\nw  \\n⌉  \\nAn essential point here is that when a formula is construed as a\\nnatural number, then the numeral corresponding to that natural number\\ncan occur as the argument of a formula, thus enabling the syntax to\\n“refer” to itself, so to speak (i.e., when a numeral is\\nsubstituted into a formula the Gödel number of which the numeral\\nrepresents). This will eventually allow Gödel to formalize the\\nLiar paradox (with “provability” in place of\\n“truth”) by substituting into the formula which says,\\n‘the formula, whose code is  , is unprovable,’\\nits own natural number code (or more precisely the corresponding\\nnumeral).  \\nx  \\nAnother concept required to carry out the formalization is the concept\\nof numeralwise expressibility of number theoretic predicates. A\\nnumber-theoretic formula φ( , …,\\n ) is   in\\n  if for each tuple of natural numbers\\n( , …,\\n ):  \\nn  \\n1  \\nn  \\nk  \\nnumeralwise expressible  \\nP  \\nn  \\n1  \\nn  \\nk  \\n⊨\\nφ( , …,\\n )  \\nN  \\nn  \\n1  \\nn  \\nk  \\n⇒  \\n⊢\\nφ( , …,\\n )  \\nP  \\nn  \\n1  \\nn  \\nk  \\n⊨\\n¬φ( , …,\\n )  \\nN  \\nn  \\n1  \\nn  \\nk  \\n⇒  \\n⊢\\n¬φ( , …,\\n )  \\nP  \\nn  \\n1  \\nn  \\nk  \\nwhere   is the formal term which denotes the natural\\nnumber  . (In  , this is\\n ( (… (0)…), where  \\nis the number of iterations of the successor function applied to the\\nconstant symbol 0.) One of the principal goals is to numeralwise\\nexpress the predicate  \\nn  \\nn  \\nP  \\nS  \\nS  \\nS  \\nn  \\nPrf( ,  ): ‘the sequence with Gödel\\nnumber   is a proof of the sentence with Gödel number\\n .’  \\nx  \\ny  \\nx  \\ny  \\nReaching this goal involves defining forty-five relations, each\\ndefined in terms of the preceding ones. These relations are all\\nprimitive\\n recursive. \\n Relations needed are, among others, those which assert of a natural\\nnumber that it codes a sequence, or a formula, or an axiom, or that it\\nis the code, denoted by\\nSb( ),\\nof a formula obtained from a formula with code   by\\nsubstituting for its free variable   the\\n  th numeral for   = 1,\\n…,  . The forty-fifth primitive recursive relation\\ndefined is Prf( ,  ), and the forty-sixth is  \\n[ ]  \\n10  \\nr  \\n…  \\nu  \\n1  \\nu  \\nn  \\n( )… ( )  \\nZ  \\nx  \\n1  \\nZ  \\nx  \\nn  \\nr  \\nu  \\ni  \\nx  \\ni  \\ni  \\nn  \\nx  \\ny  \\nProv( ): ‘the sentence with Gödel number\\n  is provable in  ’  \\ny  \\ny  \\nP  \\nwhich without being primitive recursive, is however obtained from\\nPrf( ,  ) by existentially quantifying  .\\n(Prov( ) satisfies only the ‘positive’ part of\\nnumeralwise expressibility, and not the negative part; but the\\nnegative part is not needed.)  \\nx  \\ny  \\nx  \\ny  \\nIn Theorem V of his paper, Gödel proves that any number theoretic\\npredicate which is primitive recursive is numeralwise expressible in\\n . Thus since Prf( ,  ) and substitution\\nare primitive recursive, these are decided by   when closed\\nterms are substituted for the free variables   and\\n . This is the heart of the matter as we will see. Another\\nkey point about numeralwise expressibility is that although we\\ninformally interpret, for example,\\nProv(Sb( )),\\nby: ‘the formula with Gödel number   is provable\\nif the Gödel number for the   th numeral is\\nsubstituted in place of the   th variable,’ neither the\\nformal statement within the theory   nor anything we prove\\nabout it appeals to such meanings. On the contrary\\nProv(Sb( )),\\nis a meaningless string of logical and arithmetical symbols. As\\nGödel puts it in his introduction to his theorem V, ‘The\\nfact that can be formulated vaguely by saying that every recursive\\nrelation is definable in the system   (if the usual meaning\\nis given to the formulas of this system) is expressed in precise\\nlanguage,   reference to any interpretation of the\\nformulas of  , by the following Theorem (V) (Gödel 1986,\\np. 171, italics Gödel’s).  \\nP  \\nx  \\ny  \\nP  \\nx  \\ny  \\nr  \\n…  \\nu  \\n1  \\nu  \\nn  \\n( )… ( )  \\nZ  \\nx  \\n1  \\nZ  \\nx  \\nn  \\nr  \\nx  \\ni  \\ni  \\nP  \\nr  \\n…  \\nu  \\n1  \\nu  \\nn  \\n( )… ( )  \\nZ  \\nx  \\n1  \\nZ  \\nx  \\nn  \\nP  \\nwithout  \\nP  \\nGödel in his incompleteness theorems uses a method given in what\\nis called nowadays Gödel’s Fixed Point Theorem. Although\\nGödel constructs a fixed point in the course of proving the\\nincompleteness theorem, he does not state the fixed point theorem\\nexplicitly. The fixed point theorem is as follows:  \\n(Gödel’s Fixed Point Theorem)\\n \\nIf φ( ) is a formula of number theory, then\\nthere is a sentence ψ such that   ⊢ ψ ↔\\nφ( ), where\\n  is the formal term\\ncorresponding to the natural number code of\\n ψ .  \\nTheorem 2  \\nv  \\n0  \\nP  \\n⌈  \\nψ  \\n⌉  \\n⌈  \\nψ  \\n⌉  \\n⌈  \\n⌉  \\nLet σ( , , ) be a\\nformula that numeralwise expresses the number theoretic predicate\\n‘  is the Gödel number of the formula obtained by\\nreplacing the variable   in the formula whose\\nGödel number is   by the term  ’.\\nLet θ( ) be the formula\\n∃ (φ( ) ∧\\nσ( ,  ,\\n )). Let   =\\n θ( ) \\nand ψ = θ( ). Now directly by the construction\\n  ⊢ ψ ↔\\nφ( ψ ).  \\nProof:  \\nx  \\ny  \\nz  \\ny  \\nv  \\n0  \\nx  \\nz  \\nv  \\n0  \\nv  \\n1  \\nv  \\n1  \\nv  \\n0  \\nv  \\n1  \\nv  \\n0  \\nk  \\n⌈  \\nv  \\n0  \\n⌉  \\nk  \\nP  \\n⌈  \\n⌉  \\nA sentence is refutable from a theory if its negation is provable. The\\nFirst Incompleteness Theorem as Gödel stated it is as\\nfollows:  \\n(Gödel’s First Incompleteness\\nTheorem)\\n \\nIf   is ω-consistent, then there is a sentence which is\\nneither provable nor refutable from  .  \\nTheorem 3  \\nP  \\nP  \\nBy judicious coding of syntax referred to above, write\\na formula\\n Prf( , ) \\n of number theory, representable in  , so that  \\nProof:  \\nx  \\ny  \\n[ ]  \\n11  \\nP  \\ncodes a proof of φ ⇒   ⊢\\nPrf( ,\\n ).  \\nn  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nand  \\ndoes not code a proof of φ ⇒  \\n⊢ ¬Prf( ,\\n ).  \\nn  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nLet Prov( ) denote the formula ∃ \\n Prf( , ) .\\n By Theorem 2 there is a sentence φ with the property  \\ny  \\nx  \\nx  \\ny  \\n[ ]  \\n12  \\n⊢ (φ ↔\\n¬Prov( )).  \\nP  \\n⌈  \\nφ  \\n⌉  \\nThus φ says ‘I am not provable.’ We now observe, if\\n  ⊢ φ, then by (1) there is   such that\\n  ⊢ Prf( ,\\n ), hence  \\n⊢ Prov( ), hence,\\nby (3)   ⊢ ¬φ, so   is inconsistent.\\nThus  \\nP  \\nn  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nP  \\n⌈  \\nφ  \\n⌉  \\nP  \\nP  \\n⊬ φ  \\nP  \\nFurthermore, by (4) and (2), we have   ⊢\\n¬Prf( ,\\n ) for all natural\\nnumbers  . By ω-consistency   ⊬\\n∃  Prf( ,\\n ). Thus (3) gives\\n  ⊬ ¬φ. We have shown that if   is\\nω-consistent, then φ is independent of  .  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nn  \\nP  \\nx  \\nx  \\n⌈  \\nφ  \\n⌉  \\nP  \\nP  \\nP  \\nOn concluding the proof of the first theorem, Gödel remarks,\\n“we can readily see that the proof just given is constructive;\\nthat is … proved in an intuitionistically unobjectionable\\nmanner…” (Gödel 1986, p. 177). This is because, as\\nhe points out, all the existential statements are based on his theorem\\nV (giving the numeralwise expressibility of primitive recursive\\nrelations), which is intuitionistically unobjectionable.  \\n2.2.3 The Second Incompleteness Theorem  \\nThe Second Incompleteness Theorem establishes the unprovability, in\\nnumber theory, of the consistency of number theory. First we have to\\nwrite down a number-theoretic formula that expresses the consistency\\nof the axioms. This is surprisingly simple. We just let\\nCon( ) be the sentence ¬Prov( ).  \\nP  \\n⌈  \\n0 =\\n1  \\n⌉  \\n(Gödel’s Second Incompleteness\\nTheorem) If   is consistent, then Con( ) is not\\nprovable from  .  \\nTheorem 4  \\nP  \\nP  \\nP  \\nLet φ be as in (3). The reasoning used to infer\\n‘if   ⊢ φ, then   ⊢ 0 ≠\\n1‘ does not go beyond elementary number theory, and can\\ntherefore, albeit with a lot of effort (see below), be formalized in\\n . This yields:   ⊢\\n(Prov( ) →\\n¬Con( )), and thus by (3),   ⊢\\n(Con( ) → φ). Since   ⊬ φ, we\\nmust have   ⊬ Con( ).  \\nProof:  \\nP  \\nP  \\nP  \\nP  \\n⌈  \\nφ  \\n⌉  \\nP  \\nP  \\nP  \\nP  \\nP  \\nP  \\nThe above proof (sketch) of the Second Incompleteness Theorem is\\ndeceptively simple as it avoids the formalization. A rigorous proof\\nwould have to establish the proof of ‘if   ⊢\\nφ, then   ⊢ 0 ≠ 1’ in  .  \\nP  \\nP  \\nP  \\nIt is noteworthy that ω-consistency is not needed in the proof\\nof Gödel’s Second Incompleteness Theorem. Also note that\\nneither is ¬Con( ) provable, by the consistency of\\n  and the fact, now known as Löb’s theorem, that\\n  ⊢\\nProv( ) implies\\n  ⊢ φ.  \\nP  \\nP  \\nP  \\n⌈  \\nφ  \\n⌉  \\nP  \\nThe assumption of ω-consistency in the First Incompleteness\\nTheorem was eliminated by Rosser in 1936, and replaced by the weaker\\nnotion of consistency. Rosser’s generalization involves applying\\nthe fixed point theorem to the formula  ( ):\\n‘for all  : either   is not the Gödel\\nnumber of a proof of the formula with Gödel number   or\\nthere is a proof shorter than   of the negation of (the\\nformula with Gödel number)  ’ (see Rosser\\n1936).  \\nR  \\nx  \\nz  \\nz  \\nx  \\nz  \\nx  \\nWith regard to the Second Incompleteness Theorem, the argument relies\\nin part on formalizing the proof of the First Incompleteness Theorem\\nas we saw. This step is omitted in Gödel 1931. He planned to\\ninclude the step in what would have been a second part II (see\\nfootnote 48a of Gödel 1931). But instead of writing it he turned\\nto the continuum\\n problem. \\n (Part II was to elaborate on other points too: the ‘true reason\\nfor incompleteness,’ and the applicability of the two theorems\\nto other systems.) He perhaps did not feel compelled to attend to what\\nlooked like an exercise in formalization, relying instead on the\\ninformal argument to convince (in which it succeeded). However this\\nstep turned out to be somewhat non-trivial. As Kleene puts it in his\\nintroduction to Gödel 1931, of the informal presentation,\\n“Certainly the idea of the argument for Theorem XI (consistency)\\nwas very convincing; but it turned out that the execution of the\\ndetails required somewhat more work and care than had been\\nanticipated.” (See pp. 126–141 of Gödel 1986.)\\nEventually a complete proof of the Second Theorem was given by Hilbert\\nand Bernays in some seventy pages in their Hilbert and Bernays 1939. A\\nmuch more compact treatment of the theorem was given by Löb in\\nhis Löb 1956, and subsequently Feferman, in his 1960\\n“Arithmetization of Metamathematics in a General Setting”\\n(Feferman 1960/1961), gave a succinct and completely general treatment\\nof both the First and Second Theorems. But see the supplementary\\ndocument:  \\n[ ]  \\n13  \\nDid the Incompleteness Theorems Refute Hilbert’s Program?  \\nFor more detailed discussion, see the entry on\\n  .  \\nGödel’s incompleteness theorems  \\n2.3 Speed-up Theorems  \\nGödel’s 1936 ‘Speed-up’ theorem, published in\\nan abstract “On the length of proofs”, Gödel 1936\\nsays that while some sentences of arithmetic are true but unprovable,\\nthere are other sentences which are provable, but even the shortest\\nproof is longer than any bound given in advance as a recursive\\nfunction of the sentence. More exactly:  \\n.\\n \\nGiven any recursive function   there are provable sentences\\nφ of arithmetic such that the shortest proof is greater than\\n ( φ ) in length.  \\nTheorem 5  \\nf  \\nf  \\n⌈  \\n⌉  \\nThe proof we will outline is sensitive to the particular concept we\\nuse for the length of a proof. Another possibility, and the one that\\nGödel has in mind, is the number of formulas in the proof. Buss\\n(see below) proves the theorem in either case, so both cases are\\nresolved.  \\nLet   be total recursive function. By\\nGödel’s Fixed Point theorem there is a formula\\nφ( ) stating ‘φ( ) has no proof in PA\\nshorter than  ( )’. This is tenable if the\\nlength is measured by number of symbols, because we only need to\\nsearch through finitely many proofs shorter than\\n ( ). Note that φ( ) is true for all\\n , for if φ( ) were false, then there would be a\\nshort proof of φ( ), and hence by soundness\\nφ( ) would be true, a contradiction: φ( )\\nwould both true and false. This can be formalized in PA and thus we\\nget the result that for each   the sentence φ( )\\nis provable in PA. Since φ( ) is true for all  ,\\nit cannot have a proof in PA which is shorter than\\n ( ).  \\nProof:  \\nf  \\nn  \\nn  \\nf  \\nn  \\nf  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nf  \\nn  \\nThe Speed-up Theorem is the result of contemplating and elaborating\\nthe proof of the incompleteness theorem. It applies the fixed-point\\ntechnique to the concept of unprovability by a short proof, as opposed\\nto the original idea of applying the fixed-point theorem to mere\\nunprovability. The proof has very much the same flavor as the proof of\\nthe incompleteness theorem. Interestingly, it dates from the same year\\nas the construction, due to Rosser, that eliminates the use of\\nω-consistency in the first Incompleteness Theorem; like the\\nSpeed-up Theorem of Gödel, Rosser’s construction exploits\\nthe issue of short and long proofs. Gödel never submitted a proof\\nfor the Speed-up Theorem. Over the years several related proofs were\\npublished, but the first full proof of Gödel’s original\\nresult was given only in 1994 by Sam Buss in his ‘On\\nGödel’s theorems on lengths of proofs I: Number of lines\\nand speedups for arithmetic.’ (Buss 1994). Buss also gives a\\nsecond proof of the theorem which avoids self-reference, following a\\ntechnique due to Statman. Gödel measures the length of proofs by\\nthe number of formulas; but there are also other possibilities, such\\nas the number of symbols in the proof. The case of the Speed-up\\nTheorem where the length of proof is measured by the number of symbols\\nwas proved by Mostowski in 1952 (Mostowski 1982). For proofs of\\nsimilar results see Ehrenfeucht and Mycieleski 1971, and Parikh 1971.\\nThough both measures may be equally natural candidates for measuring\\nthe length of a proof, proving the theorem for length measured by the\\nnumber of symbols avoids a technical complication introduced by the\\nother measure: there are only finitely many proofs with a given number\\nof symbols, whereas there are infinitely many proofs with a given\\nnumber of formulas.  \\nGödel states the Speed-up Theorem differently from the above. Let\\n  be the system of logic of the  -th\\norder, the variables of the first level being thought of as ranging\\nover natural numbers. In this setting, variables of the second level\\nrange over sets of natural numbers and so on. Gödel’s\\nformulation is:  \\nS  \\nn  \\nn  \\n.\\n \\nLet   be a natural number > 0. If   is a\\ncomputable function, then there are infinitely many formulas\\n , provable in  , such that if\\n  is the length of the shortest proof of   in\\n  and   is the length of the\\nshortest proof of   in  ,\\nthen   >  ( ).  \\nTheorem 6  \\nn  \\nf  \\nA  \\nS  \\nn  \\nk  \\nA  \\nS  \\nn  \\nl  \\nA  \\nS  \\n+1  \\nn  \\nk  \\nf  \\nl  \\nThe idea is the following: Let\\nφ( ) be a formula, like above, for which\\nφ( ) does not have a short proof in\\n  for any  . Suppose we have a\\nhigher type system   in which we can\\nprove ∀ φ( ). This proof is of constant\\nlength. Thus each φ( ) is derivable from this universal\\nstatement by one application of the logical rule\\n∀ φ( ) → φ( ). Thus\\nφ( ) has in that system for all   a short\\nproof.  \\nProof sketch:  \\nx  \\nm  \\nS  \\nn  \\nm  \\nS  \\n+1  \\nn  \\nx  \\nx  \\nm  \\nx  \\nx  \\nt  \\nm  \\nm  \\nWhat kind of stronger system can we have in which\\n∀ φ( ) is provable? We may consider\\nsecond order logic in which we can define a predicate\\n ( ) for the set of natural numbers and furthermore\\ncan prove of a new predicate symbol  ( ) that it\\nsatisfies the inductive clauses of the truth definition of first order\\nformulas of arithmetic, relativized to  . Then the stronger\\nsystem can prove that provable first order sentences of arithmetic\\nsatisfy the predicate   . By the above argument, we can\\nprove in the stronger system that ∀ φ( )\\nsatisfies  . Then by adding a few lines we can prove each\\nφ( ) satisfies  . Because of the nature of\\nφ( ), this implies the stronger system has a (short)\\nproof of φ( ). An alternative system is Peano’s\\naxioms PA in an extended language where we have a new predicate symbol\\n  and axioms stating that the predicate   codes\\nthe satisfaction relation for all sentences of the vocabulary not\\ncontaining  .  \\nx  \\nx  \\nN  \\nx  \\nTr  \\nx  \\nN  \\nTr  \\nx  \\nx  \\nTr  \\nn  \\nTr  \\nn  \\nn  \\nTr  \\nTr  \\nTr  \\n2.4 Gödel’s Work in Set theory  \\n2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice  \\nGödel’s proof of the consistency of the continuum\\nhypothesis with the axioms of Zermelo-Fraenkel set theory is a tour de\\nforce and arguably the greatest achievement of his mathematical life.\\nThis is because aside from the arithmetization, virtually all of the\\ntechnical machinery used in the proof had to be invented ab\\ninitio.  \\nThe Continuum Hypothesis (henceforth  ) was formulated by\\nGeorg Cantor, and was the first problem on Hilbert’s list of\\ntwenty-three unsolved problems as given in his famous address to the\\nInternational Mathematical Congress in Paris in 1900. The problem as\\nstated by Hilbert is as follows: Let   be an infinite set of\\nreal numbers. Then   is either countable, or has cardinality\\n2 , i.e.,   is in one-to-one\\ncorrespondence either with the set of natural numbers or with the set\\nof all real numbers (otherwise known as the continuum). Another way to\\nstate the continuum hypothesis is that (the first uncountably infinite\\ncardinal) ℵ  =\\n2 .  \\nCH  \\nA  \\nA  \\nℵ  \\n0  \\nA  \\n1  \\nℵ  \\n0  \\nAs early as 1922 Skolem speculated that the   was\\nindependent of the axioms for set theory given by Zermelo in 1908.\\nNevertheless Hilbert published a (false) proof of the   in\\nHilbert 1926. In 1937 Gödel proved its consistency with the\\naxioms of   set theory. (Henceforth we use the standard\\nabbreviations for Zermelo-Fraenkel set theory,  , and\\nZermelo-Fraenkel set theory with the Axiom of Choice,  .)\\nThe consistency of the negation of the   was shown by Paul\\nCohen in 1961 (see Cohen 1963) and hence together with\\nGödel’s result one infers that the   is\\nindependent of   (and  ).  \\nCH  \\nCH  \\nZF  \\nZF  \\nZFC  \\nCH  \\nCH  \\nZF  \\nZFC  \\nCohen invented an important new technique called forcing in the course\\nof proving his result; this technique is at present the main method\\nused to construct models of set theory. Forcing led to a revival of\\nformalism among set theorists, the plurality of models being an\\nindication of the “essential variability in set theory,”\\n(Dehornoy 2004) and away from the notion that there is an intended\\nmodel of set theory—a perspective Gödel advocated since at\\nleast 1947, if not\\n earlier. \\n Recently there have been signs that the   may again be\\ncoming to be regarded as a problem to be solved mathematically (with\\nthe help of course of some new evident axioms extending ZF). (See for\\nexample Woodin 2001a, 2002, 2001b, and Foreman 1998.) If any of the\\nproposed solutions gain acceptance, this would confirm\\nGödel’s view that the   would eventually be\\ndecided by finding an evident extension of the ZF axioms for set\\ntheory. The program associated with this view is called\\n“Gödel’s Large Cardinal Program.”  \\n[ ]  \\n14  \\nCH  \\nCH  \\n2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory  \\nThe continuum problem is shown to be consistent with ZF by finding an\\nenumeration of the reals which is indexed by the countable ordinals, a\\nstrategy which had been recognized as a promising one already by\\n Hilbert. \\n The problem, and the intuition behind the proof, is to build a\\n“small” model, one in which the absolute minimum number of\\nreals is allowed, while at the same time the model is large enough to\\nbe closed under all the operations the   axioms assert to\\nexist.  \\n[ ]  \\n15  \\nZF  \\nGödel’s is a relative consistency proof, obtained by\\nconstructing a so-called “inner model” for  \\ntogether with the  . An inner model is a subcollection\\n  of the collection   of all sets (see below) which\\nsatisfies the axioms of   when only sets in   are\\nconsidered. Gödel’s inner model is called the   (see below) and is denoted by\\n . Whatever is true in an inner model is consistent with\\n  for the same reason that any theory with a model is\\nconsistent. An artifact of the construction is that the Axiom of\\nChoice (henceforth  ) is satisfied in Gödel’s\\ninner model and hence the consistency of the   with\\n  was established by Gödel. Later on it was shown by\\nSierpinski that the   is actually a consequence of the\\nGeneralized Continuum Hypothesis or the   which states\\nthat for each κ, 2  = κ  (see\\nSierpinski 1947).  \\nZF  \\nCH  \\nM  \\nV  \\nZF  \\nM  \\ninner\\nmodel of constructible sets  \\nL  \\nZF  \\nAC  \\nAC  \\nZF  \\nAC  \\nGCH,  \\nκ  \\n+  \\nGödel published two versions of these theorems, in 1939 and in\\n1940, entitled “Consistency Proof for the Generalized Continuum\\nHypothesis,” and “The Consistency of the Axiom of Choice\\nand of the Generalized Continuum Hypothesis with the Axioms of Set\\nTheory,” respectively. Though completely definitive, the 1939\\nversion is lacking in a great many details, most notably the arguments\\nshowing that if   is built inside   itself, the same\\n  results; that is to say, the so-called absoluteness\\narguments are missing. Also missing are the details of the proofs that\\nthe   axioms hold in  . Unlike the case of the\\nSecond Incompleteness Theorem, however, Gödel subsequently gave a\\ncompletely detailed proof of the two theorems in the 1940 monograph.\\n(The 1940 proof differs substantially from the first version. For\\ndetails about the two proofs and the difference between them the\\nreader is referred to Solovay 1990 and Kanamori 2006.)  \\nL  \\nL  \\nL  \\nZF  \\nL  \\nWe now sketch the proof of the consistency of   and of\\n  with  , using modern terminology. Some\\npreliminary concepts before sketching the proof: We first define the\\nstratified set theoretic universe, denoted  . (  is\\nalso known as the cumulative hierarchy.) It is obtained by iteration\\nof the power set operation (℘) beginning with the null set:  \\nCH  \\nAC  \\nZFC  \\nV  \\nV  \\nV  \\n0  \\n=  \\n∅,  \\nV  \\nα+1  \\n=  \\n℘( ),  \\nV  \\nα  \\nV  \\nγ  \\n=  \\n,  \\n∪  \\nβ<γ  \\nV  \\nβ  \\nwhere α, β are any ordinals, γ is a limit ordinal and\\n℘( ) denotes the power set of  . Finally  \\nx  \\nx  \\nV  \\n=  \\n,  \\n∪  \\nα∈  \\nOrd  \\nV  \\nα  \\nwhere   denotes the class of all ordinals.  \\nOrd  \\nThe constructible hierarchy   is likewise defined by\\nrecursion on ordinals. But whereas the full power set operation is\\niterated to obtain the cumulative hierarchy, the levels of the\\nconstructible hierarchy are defined strictly predicatively, that is by\\nincluding at the next level only those sets which are first order\\ndefinable using parameters from the previous level. More exactly, let\\n ( ) denote the set of all subsets of  \\ndefinable in the structure <  , ∈ > by first order\\nformulas with parameters in  . (For more on definability see\\nthe entry on\\n  \\n in this encyclopedia.)  \\nL  \\nDef  \\nA  \\nA  \\nA  \\nA  \\nmodel theory  \\nWith this notation the constructible hierarchy is defined by induction\\nover the ordinals as follows:  \\nL  \\n0  \\n=  \\n∅,  \\nL  \\nα+1  \\n=  \\n( ),  \\nDef  \\nL  \\nα  \\nL  \\nγ  \\n=  \\n,  \\n∪  \\nα<γ  \\nL  \\nα  \\nL  \\n=  \\n,  \\n∪  \\nα∈  \\nOrd  \\nL  \\nα  \\nA set   is said to be   if  \\n∈  . The axiom which states that all sets are\\nconstructible is denoted   =   and is called the\\nAxiom of Constructibility. Note that   is a proper class and\\nnot a set; although as we will see, each  \\nis a set, and the predicate “  is constructible”\\nis actually a definable term of the language.  \\nx  \\nconstructible  \\nx  \\nL  \\nV  \\nL  \\nL  \\nL  \\nα  \\nx  \\nOur next task is to show that   is a model of  . A\\nset or a class is   if elements of it are also\\nsubsets. By a meticulous transfinite induction,   can be shown to be transitive for each α; and therefore\\nso is   itself. This fact, together with the observation that\\nsome elementary closure properties hold in  \\n \\n is enough to show that   is a model of  . (Indeed,\\nas it turns out,   is the minimal transitive model of the\\n  axioms containing all the ordinals, and is therefore in\\nthis sense canonical.)  \\nL  \\nZF  \\ntransitive  \\nL  \\nα  \\nL  \\nL  \\n[ ]  \\n16  \\nL  \\nZF  \\nL  \\nZF  \\nIn detail, proving that the   axioms, apart from the\\ncomprehension axiom, are true in  , amounts to showing that,\\nroughly speaking, any set with a property   that a\\n  axiom asserts to exist, can be seen to exist in  \\nby considering the relativization   of the\\nproperty   to  . (A property   is\\nrelativized to an inner model   by replacing every quantifier\\n∃ φ by ∃ (  ∈\\n  ∧ φ) and every quantifier ∀ φ\\nby ∀ (  ∈  → φ).) As\\nfor the comprehension axiom, verifying it requires showing that the\\nset asserted to exist is constructed at a particular successor level\\n . Proving this requires an important\\nprinciple of set theory which in modern terminology is called the Levy\\n(or  ) Reflection Principle. This principle says that any\\nstatement in the language of   which is true in  \\nis already true on some level of any continuously increasing hierarchy\\nsuch as  . (For the history of this principle, see Kanamori\\n2006.) The Levy Reflection Principle gives the level α at which\\nthe elements of the set are all constructed. Gödel did not\\nactually have the Levy Reflection Principle but used the argument\\nbehind the proof of the principle.  \\nZF  \\nL  \\nP  \\nZF  \\nL  \\nP  \\nL  \\nP  \\nL  \\nP  \\nM  \\nx  \\nx  \\nx  \\nM  \\nx  \\nx  \\nx  \\nM  \\nL  \\nα + 1  \\nZF  \\nZF  \\nV  \\nL  \\nOnce it is established that   is a model of  , one\\ncan now prove that both the   and the   hold in\\n . To this end, one first shows that the definition of\\n  is   for  , where absoluteness is\\ndefined as follows: given a class  , a predicate\\n ( ) is said to be absolute for   if and\\nonly if for all   ∈  ,  ( )\\n↔  ( ).  \\nL  \\nZF  \\nCH  \\nAC  \\nL  \\nL  \\nabsolute  \\nL  \\nM  \\nP  \\nx  \\nM  \\nx  \\nM  \\nP  \\nx  \\nP  \\nM  \\nx  \\nProving that the predicate “  is constructible”\\nis absolute requires formalizing the notion of definability, which in\\nturn requires formalizing the notion of satisfaction. This is because\\nthe predicate “  is constructible” says of a set,\\nthat for some ordinal α, and for some formula φ with\\nparameters in  ,   = { \\n∈   |  \\n⊨ φ( )}. This part of the proof is tedious but\\nunproblematic.  \\nx  \\nx  \\nL  \\nα  \\nx  \\ny  \\nL  \\nα  \\nL  \\nα  \\ny  \\nOnce the absoluteness of   is established, it follows that\\n  satisfies the axiom of constructibility if it is\\nrelativized to  ; that is,   ⊢\\n(V=L) . In particular, the axiom   =   is\\nconsistent if   is.  \\nL  \\nZF  \\nL  \\nZF  \\nL  \\nV  \\nL  \\nZF  \\nWe now give the idea of the proof of   and   in\\n  +   =  . (For a detailed exposition of\\nthe proof, the reader is referred to the standard sources. See for\\nexample Devlin’s chapter on constructibility in Barwise 1977;\\nsee also Kunen 1983, and Jech 2003.)  \\nCH  \\nAC  \\nZF  \\nV  \\nL  \\nAs concerns the  , the idea behind the proof of it in\\n  is simply the following: Gödel showed that assuming\\n  =  , every real number occurs on some countable\\nlevel of the  -hierarchy. Since every countable level is\\nitself countable (after all, there are only countably many possible\\ndefining formulas), and there are ω  countable\\nlevels, there must be only ω  real numbers.  \\nCH  \\nL  \\nV  \\nL  \\nL  \\n1  \\n1  \\nThe difficulty here, if not of the whole proof altogether, lies in\\nshowing that every real is constructed already on a countable level of\\nthe  -hierarchy. To show this Gödel argued as follows:\\nSuppose   is a real number thought of as a set of natural\\nnumbers. By a combination of the Levy Reflection principle and the\\nLöwenheim-Skolem Theorem there is a countable submodel <\\n , ∈ > of <  , ∈ > satisfying a\\nsufficiently large   part of the   axioms +\\n  =  , such that   belongs to  .\\nBy a simple procedure <  , ∈ > can be converted\\ninto a transitive model <  , ∈ >. This procedure,\\nused by Gödel already in 1937, was explicitly isolated by\\nMostowski (Mostowski 1949). The resulting model is referred to as the\\nMostowski Collapse.  \\nL  \\nA  \\nM  \\nL  \\nfinite  \\nZF  \\nV  \\nL  \\nA  \\nM  \\nM  \\nN  \\nLet us pause to discuss this important technique. Suppose <\\n ,  > is a well-founded model of the axiom of\\nextensionality. It is a consequence of the well-foundedness of the\\nbinary predicate   on  , and of the principle of\\ntransfinite recursion, that the equation π( ) =\\n{π( )\\u2009|\\u2009  ∈   ∧\\n } defines a unique function on  . The range\\n  of π is transitive, for if π( ) ∈\\n  and   ∈ π( ), then   =\\nπ( ) for some   ∈   with\\n , whence π( ) ∈  . The fact that\\nπ is an isomorphism between <  ,  > and\\n<  , ∈ > can be proved by transfinite induction on\\nelements on  , based again on the well-foundedness of\\n . The well-foundedness of <  ,  > is\\nin practice often the consequence of <  ,  >\\nbeing a submodel of some <  , ε\\n>.  \\nM  \\nE  \\nE  \\nM  \\nx  \\ny  \\ny  \\nM  \\nyEx  \\nM  \\nN  \\na  \\nN  \\ny  \\na  \\ny  \\nb  \\nb  \\nM  \\nbEa  \\nb  \\nN  \\nM  \\nE  \\nN  \\nM  \\nE  \\nM  \\nE  \\nM  \\nE  \\nV  \\nα  \\nWe now return to the proof of the   in  . We used\\nthe Mostowski Collapse to construct the transitive set  . As\\nit turns out, the real number   is still an element of <\\n , ∈ > . By basic properties of  , <\\n , ∈ > must be <  ,\\n∈ > for some α . Since   is countable, α\\nis countable too. (It can be shown that | |\\n= |α| + ℵ .) Thus   is constructible\\non a countable level, which was to have been shown.  \\nCH  \\nL  \\nN  \\nA  \\nN  \\nL  \\nN  \\nL  \\nα  \\nN  \\nL  \\nα  \\n0  \\nA  \\nAs for the  , Gödel exhibits a definable well-ordering,\\nthat is, a formula of set theory which defines, in  , a\\nwell-ordering of all of  . The formula is tedious to write\\ndown but the idea is a simple one: A set   precedes a set\\n  in the well-ordering if and only if either  \\noccurs in the  -hierarchy on an earlier level\\n  than  , or else they occur on\\nthe same level but   is defined by a shorter formula than\\n , or else they are defined by the same formula but the\\nparameters in the definition of   occur in   earlier\\nthan the parameters of  . This well-ordering of  \\nshows that the   holds in  .  \\nAC  \\nL  \\nL  \\nx  \\ny  \\nx  \\nL  \\nL  \\nα  \\ny  \\nx  \\ny  \\nx  \\nL  \\ny  \\nL  \\nAC  \\nL  \\nThis concludes the proof of the consistency of   and the\\n  in  .  \\nAC  \\nCH  \\nL  \\nWe note that Gödel proved more in his 1939 and 1940 than what was\\nshown here, namely he proved the Generalized Continuum Hypothesis in\\n  and hence that its consistency with  .  \\nL  \\nZF  \\n2.4.3 Consequences of Consistency  \\nAs noted above, it was suggested already in the 1920s that the\\n  might be independent of   or  . After\\nfirst conjecturing that the Axiom of Constructibility might be\\n“absolutely consistent,” meaning not falsifiable by any\\nfurther extension of models of   +   =\\n  , \\n in his 1947 “What is Cantor’s Continuum\\nHypothesis?” Gödel conjectured that the   would\\nbe shown to be independent. The main consequence of Gödel’s\\nresult, then, as far as the problem of proving the independence of the\\n  is concerned, was that it pointed mathematicians in the\\ndirection of adding non-constructible sets to a model of set theory in\\norder to establish the consistency of the negation of the  .\\nIn 1961 Dana Scott proved that the failure of the Axiom of\\nConstructibility follows from the existence of a measurable cardinal,\\ncontrary to a conjecture Gödel had made in 1940. (See Scott 1961.\\nA cardinal κ is said to be measurable if there is a\\nnon-principal κ-complete ultrafilter in the power-set Boolean\\nalgebra of κ.) In 1963, as noted, Paul Cohen proved the\\nconsistency of the negation of the   by adding\\nnon-constructible sets to an inner model.  \\nCH  \\nZF  \\nZFC  \\nZF  \\nV  \\nL  \\n[ ]  \\n17  \\nCH  \\nCH  \\nCH  \\nCH  \\nWhat other open questions of set theory could be solved by\\nGödel’s method? Gödel himself noted some consequences.\\nThey are related to so called projective sets of real numbers and\\nfinite sequences of real numbers. The simplest projective sets are the\\nclosed sets, also called Π -sets. A set is\\nΣ  if it is the projection of\\na Π -subset of the real plane. A\\nset is Δ  if it and its\\ncomplement are Σ . Gödel\\nobserved that there is both a non-Lebesgue measurable\\nΔ -set and an uncountable\\nΠ -set without a perfect subset in\\n . (A set of reals is perfect if it is closed, non-empty, and\\nhas no isolated points. Such sets have the size of the continuum.)\\nGödel gave a sketch of the proof in the 1951 second printing of\\nGödel 1940.  \\n1  \\n0  \\n1  \\n+1  \\nn  \\n1  \\nn  \\n1  \\n+1  \\nn  \\n1  \\n+1  \\nn  \\n1  \\n2  \\n1  \\n1  \\nL  \\nIt has turned out subsequently that the axiom   =  \\ngives a virtually complete extension of  . This means that,\\napart from sentences arising from Gödel’s incompleteness\\ntheorems, essentially all set-theoretical questions can be decided by\\nmeans of the axioms   =  . This is not to imply that\\nsuch results are in any way trivial. Indeed, it has turned out that\\n  is quite a complicated structure, despite its relatively\\nsimple description. As for settling open set-theoretical questions in\\n  the main step was the emergence of Jensen’s fine\\nstructure theory of   (Jensen 1972). Recalling that the\\nsuccessor step   in the definition of\\nthe constructible hierarchy adds to   all subsets of\\n  definable by first order formulas φ\\nover ( , ∈), fine structure theory,\\nroughly speaking, ramifies the step from  \\nto   into smaller steps according to the\\ncomplexity of the defining formula φ. Jensen established by means\\nof his fine structure a strengthening, denoted by ◊, of\\n , that he used to construct a Souslin tree in  ,\\nand a combinatorial principle □ that he used to show that the\\nSouslin Hypothesis is consistent with  .  \\nV  \\nL  \\nZFC  \\nV  \\nL  \\nL  \\nL,  \\nL  \\nL  \\nα +1  \\nL  \\nL  \\nα  \\nL  \\nα  \\nL  \\nα  \\nL  \\nα+1  \\nCH  \\nL  \\nCH  \\n2.4.4 Gödel’s view of the Axiom of Constructibility  \\nIf he did not think this way from the outset, Gödel soon came to\\nadopt the view that the Axiom of Constructibility was implausible. As\\nhe remarked at the end of his 1947 “What is Cantor’s\\nContinuum Hypothesis?”  \\n…it is very suspicious that, as against the numerous plausible\\npropositions which imply the negation of the continuum hypothesis, not\\none plausible proposition is known which would imply the continuum\\nhypothesis. (Gödel 1990, p. 186)  \\nGödel was compelled to this view of   by the\\n Leibnizian \\n idea that, rather than the universe being “small,” that\\nis, one with the minimum number of sets, it is more natural to think\\nof the set theoretic universe as being as large as\\n possible. This\\n idea would be reflected in his interest in maximality principles,\\ni.e., principles which are meant to capture the intuitive idea that\\nthe universe of set theory is maximal in the sense that nothing can be\\nadded; and in his conviction that maximality principles would\\neventually settle statements like the  . As Gödel put\\nit in a letter to Ulam in the late 1950s, about a maximality principle\\nof von Neumann:  \\nL  \\n[ ]  \\n18  \\n[ ]  \\n19  \\nCH  \\nThe great interest which this axiom has lies in the fact that it is a\\nmaximality principle, somewhat similar to Hilbert’s axiom of\\ncompleteness in geometry. For, roughly speaking, it says that any set\\nwhich does not, in a certain well defined way, imply an inconsistency\\nexists. Its being a maximum principle also explains the fact that this\\naxiom implies the axiom of choice. I believe that the basic problems\\nof set theory, such as Cantor’s continuum problem, will be\\nsolved satisfactorily only with the help of stronger axioms of this\\nkind, which in a sense are opposite or complimentary to the\\nconstructivistic interpretation of mathematics. (Ulam 1958, as quoted\\nin Gödel 1990, p. 168; original emphasis. Note that this is\\ndifferent from the very similar passage Gödel 2003b, p.295.)  \\nTwenty years earlier, in 1938, Gödel had written seemingly\\ndifferently about the Axiom of Constructibility:  \\nThe proposition   (i.e.,   =  ) added as a\\nnew axiom seems to give a natural completion of the axioms of set\\ntheory, in so far as it determines the vague notion of an arbitrary\\ninfinite set in a definite way. (Gödel 1986, p.27)  \\nA  \\nV  \\nL  \\nGödel may have meant by “natural completion” here\\n“the correct completion,” or he may have meant to say no\\nmore than that the Axiom of Constructibility determines the notion of\\nset in a definite way. In any case he used the term\\n“natural” differently in a conversation with Wang on\\nconstructibility in 1972 (Wang 1996, p. 144):  \\nGödel talked more about the relation between axioms of infinity\\nand the constructible universe…(he observed that) preliminary\\nconcepts such as that of constructible sets are necessary to arrive at\\nthe natural concept, such as that of set.  \\nThis is reminiscent of a remark of Hugh Woodin, that studying forcing\\nleads to a better understanding of   — the general\\nprinciple being that studying the models of a theory is not only\\nuseful to understand the theory itself, but useful to obtain a better\\npicture of   (Woodin 1988).  \\nV  \\nV  \\nFor more on Gödel’s program and on Gödel’s\\nprogram relative to the   the reader is referred e.g., to\\nSteel forthcoming and Feferman  . 2000. For more on\\nGödel’s result, its history , and its significance the\\nreader is referred to Floyd/Kanamori 2006 and Kennedy 2006.  \\nCH  \\net al  \\n2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic  \\nGödel’s interest in intuitionism was deep and long-lasting.\\nAlthough he himself did not subscribe to that view, he made a number\\nof important contributions to intuitionistic logic. Perhaps the\\nimportance he placed on the concept of evidence (see below) led to his\\nclose consideration of it.  \\nWe discuss Gödel’s results on intuitionistic logic in their\\nchronological order.  \\n2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued  \\nBoth many-valued logic, introduced by Łukasiewicz in the twenties\\n(Łukasiewicz 1970) and intuitionistic logic, formalized by\\nHeyting in 1930, fail to satisfy the law of excluded middle. It was\\ntherefore natural to ask whether intuitionistic logic can be presented\\nas a many-valued logic, and indeed a number of logicians in the 1920s\\nhad suggested just that. In his 1932 Gödel gave a simple argument\\nwhich shows that intuitionistic propositional logic cannot be thought\\nof as a finitely-valued logic. Precisely, Gödel proved two\\ntheorems:  \\n.\\n \\nThere is no realization with finitely many elements (truth values) for\\nwhich the formulas provable in  , and only those, are\\nsatisfied (that is, yield designated values for an arbitrary\\nassignment).  \\nTheorem 7  \\nH  \\n(  is intuitionistic propositional logic, after\\nHeyting.)  \\nH  \\n.\\n \\nInfinitely many systems lie between   and the system\\n  of the ordinary propositional calculus, that is,\\nthere is a monotonically decreasing sequence of systems all of which\\ninclude   as a subset and are included in\\n  as subsets.  \\nTheorem 8  \\nH  \\nA  \\nH  \\nA  \\nIn his proof he considered for each natural number   > 0\\nthe sentence  \\nn  \\n=  \\n  ≡\\n .  \\nF  \\nn  \\n∨  \\n1\\n≤   <   ≤  \\ni  \\nj  \\nn  \\np  \\ni  \\np  \\nj  \\nHe observed that in an  -valued logic the sentences\\n , for   >  ,\\nshould be derivable. However, Gödel showed,\\n  is not derivable from Heyting’s\\naxioms for any  .  \\nn  \\nF  \\nm  \\nm  \\nn  \\nF  \\nn  \\nn  \\nSubsequently Jaśkowski (Jaśkowski 1936) showed that\\nintuitionistic propositional logic can be given a many-valued\\nsemantics in terms of infinitely many truth-values. For further\\ndiscussion of many-valued logics, see for example the entry on\\n  \\n in this encyclopedia as well as van Stigt’s article on\\nintuitionistic logic in Mancosu 1998.  \\nmany-valued logic  \\n2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic  \\nWe now consider Gödel 1933e, in which Gödel showed, in\\neffect, that intuitionistic or Heyting arithmetic is only apparently\\nweaker than classical first-order arithmetic. This is because the\\nlatter can be interpreted within the former by means of a simple\\ntranslation, and thus to be convinced of the consistency of classical\\narithmetic, it is enough to be convinced of the consistency of Heyting\\narithmetic. Heyting arithmetic is defined to be the same as classical\\narithmetic, except that the underlying predicate logic is given by\\nintuitionistic axioms and rules of inference (see below).  \\nThis result extends the same assertion for the propositional case. Let\\n  denote the intuitionistic propositional logic, and\\n  denote its classical counterpart (as above).\\nInductively define:  \\nH  \\nA  \\n′  \\nA  \\n≡  \\n¬¬  (  atomic)  \\nA  \\nA  \\n(¬ )′  \\nA  \\n≡  \\n¬ ′  \\nA  \\n(  →  )′  \\nA  \\nB  \\n≡  \\n¬( ′ ∧\\n¬ ′)  \\nA  \\nB  \\n(  ∨  )′  \\nA  \\nB  \\n≡  \\n¬(¬ ′ ∧\\n¬ ′)  \\nA  \\nB  \\n(  ∧  )′  \\nA  \\nB  \\n≡  \\n′ ∧  ′  \\nA  \\nB  \\nThen,  \\n.\\n \\nLet   be a propositional formula. Then  \\n⊢   if and only if   ⊢\\n ′,  \\nTheorem 9  \\nF  \\nH  \\nF  \\nA  \\nF  \\nThe theorem follows easily from the result of Glivenko (1929) that\\n¬  follows from   if and only if\\n¬  follows from  , for any propositional\\nformula  .  \\nF  \\nH  \\nF  \\nA  \\nF  \\nGödel’s so-called double negation interpretation extends\\nTheorem 9 to a reduction of classical first order logic to\\nintuitionistic predicate logic. The translation in this case can be\\ntaken to map  ′ to   for atomic  .\\nMoreover, we let ∀ ( )′ =\\n∀ ′( ) :  \\nA  \\nA  \\nA  \\nxA  \\nx  \\nxA  \\nx  \\n.\\n \\nSuppose   is a first order formula. If   is provable\\nin classical first order logic, then  ′ is provable in\\nintuitionistic first order logic.  \\nTheorem 10  \\nA  \\nA  \\nA  \\nThe above result had been obtained independently by Gentzen (with\\nBernays), but upon hearing of Gödel’s result Gentzen\\nwithdrew his paper from publication. It had also been anticipated by\\nKolmogorov in his 1925 “On the Principle of the Excluded\\nMiddle,” (English translation van Heijenoort 1967) but that\\npaper was largely unknown to logicians who were outside of\\nKolmogorov’s circle.  \\nBernays has written (see Bernays’ entry on David Hilbert in\\nEdwards 1967) that this result of Gödel’s drew the\\nattention of the Hilbert school to two observations: first, that\\nintuitionistic logic goes beyond finitism, and secondly, that finitist\\nsystems may not be the only acceptable ones from the foundational\\npoint of view.  \\nThe following theorem for the case of arithmetic follows from Theorem\\n10:  \\n.\\n \\nSuppose   is a first order formula of arithmetic. If\\n  is provable in classical Peano arithmetic, then\\n ′ is provable in intuitionistic first order\\narithmetic.  \\nTheorem 11  \\nA  \\nA  \\nA  \\nFor a list of the axioms and rules of intuitionistic first order logic\\nsee Gödel 1958, reprinted with detailed introductory note by A.S.\\nTroelstra in Gödel 1990. See also Troelstra 1973, and\\nTroelstra’s “Aspects of constructive mathematics” in\\nBarwise 1977. For a detailed proof of the above theorem the reader is\\nreferred also to the latter.  \\n2.5.3 Intuitionistic Propositional Logic is Interpretable in  \\nS4  \\nThis result of Gödel’s (Gödel 1933f), which marks the\\nbeginning of provability logic, makes exact the difference between the\\nconcept of “provability in a specified formal system” and\\nthat of “provability by any correct means.”  \\nGödel had already noted this difference in the introduction to\\nhis 1929 thesis. The context was the following: Gödel entertains\\nthere the possibility that his proof of the Completeness Theorem might\\nbe circular, since the law of excluded middle was used to prove it.\\nThis is because while the Completeness Theorem asserts ‘a kind\\nof decidability,’ namely every quantificational formula is\\neither provable or a counterexample to it can be given, ‘the\\nprinciple of the excluded middle seems to express nothing other than\\nthe decidability of every problem’:  \\n… what is affirmed (by the law of excluded middle) is the\\nsolvability not at all through specified means but only through all\\nmeans that are   …  \\nin any way imaginable  \\n[ ]  \\n20  \\nGödel considers intuitionistic propositional logic (henceforth\\nIPL); he also considers a second system, classical propositional logic\\nenriched by an operator “B”, where the intended meaning of\\n“B” is “provable.” The axiom system now known\\nas   (for a list of these axioms see for example the\\nentry on\\n  \\n in this encyclopedia) is added to the standard axioms for classical\\npropositional logic together with a new rule of proof: from\\n , B  may be inferred. Let us call this second\\nsystem  . Gödel’s theorem states that\\n  is interpretable in   via the following\\ntranslation:  \\nS4  \\nmodal logic  \\nA  \\nA  \\nG  \\nIPL  \\nG  \\n¬  \\np  \\n≡  \\n~B  \\np  \\n⊃  \\np  \\nq  \\n≡  \\nB  → B  \\np  \\nq  \\n∨  \\np  \\nq  \\n≡  \\nB  ∨ B  \\np  \\nq  \\n∧  \\np  \\nq  \\n≡  \\nB  ∧ B  \\np  \\nq  \\nThat is,  \\n.\\n \\nLet   be a formula of  , and let  ′\\nbe its translation. Then   ⊢   implies\\n  ⊢  ′.  \\nTheorem 12  \\nA  \\nIPL  \\nA  \\nIPL  \\nA  \\nG  \\nA  \\nGödel conjectures that the converse implication must be true, and\\nindeed this was shown in McKinsey and Tarski 1948.  \\nThe difference between the two notions of provability: “provable\\nin a given formal system  ” and provability by any\\ncorrect means — manifests itself as a consequence of\\nGödel’s Second Incompleteness Theorem, as follows. Let\\n  contain Peano arithmetic, and let the operator B be\\ninterpreted as “provable in  ”. If the axioms of\\n  were valid for this interpretations of  ,\\nthen from  (0 ≠ 1) → (0 ≠ 1), the sentence\\n¬ (0 ≠ 1) would be provable, contradicting the Second\\nIncompleteness Theorem.  \\nS  \\nS  \\nS  \\nS4  \\nB  \\nB  \\nB  \\nFor further discussion of Gödel’s theorem, its antecedents\\nand its extensions, as well as its philosophical significance, the\\nreader is referred to A.S Troelstra’s introduction to\\n .  \\n1933f  \\n2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.  \\nGödel’s so-called Dialectica intepretation (Gödel\\n1958) delivers a relative consistency proof and justification for\\nHeyting arithmetic by means of a concrete interpretation involving a\\nsystem   of computable functionals of finite type. Taken\\ntogether with his 1933e, which reduces classical first order\\narithmetic to Heyting arithmetic, a justification in these terms is\\nalso obtained for classical first order arithmetic.  \\nT  \\nGödel’s inductive definition of the notion “function\\nof finite type” is as follows: (Gödel 1990, p. 245).  \\nThe functionals of type 0 are the natural numbers.  \\nIf  ,…,\\n  are types and we have already defined\\nwhat functionals of types\\n ,…,  are,\\nthen ( ,…,\\n ) is a type and a functional of that\\ntype assigns to every  -tuple of functionals of respective\\ntypes  ,…,\\n , a functional of type\\n .  \\nt  \\n0  \\nt  \\nk  \\nt  \\n0  \\nt  \\nk  \\nt  \\n0  \\nt  \\nk  \\nk  \\nt  \\n1  \\nt  \\nk  \\nt  \\n0  \\nGödel considers the quantifier free theory of these functionals\\nof finite type, denoted by  .   has the following\\nfeatures: the language of   contains variables of each type,\\nconstants for distinguished types, and a ternary predicate\\n=  for equality for type σ. Equality between\\nterms of the same type is decidable. The non-logical axioms and rules\\nfor   include the classical arithmetic axioms for 0 and\\nsuccessor, and the induction rule:  \\nT  \\nT  \\nT  \\nσ  \\nT  \\n( (0) ∧ ( ( ) →\\n ( ( )))) →\\n ( )  \\nF  \\nF  \\nx  \\n0  \\nF  \\nS  \\nx  \\n0  \\nF  \\nx  \\n0  \\nfor quantifier-free formulas  ( ). As\\nGödel remarks (Gödel 1990, p. 247), the axioms for\\n  are essentially those of primitive recursive arithmetic,\\nexcept that the variables can be of any finite type.  \\nF  \\nx  \\n0  \\nT  \\nGödel’s translation associates with every formula\\n ( ) of the language of Peano arithmetic a\\nformula  ′( ) =\\n∃ ∀ ( ,\\n ,  ) of the language of the theory\\n , where   is quantifier free and the (boldface)\\nbound variables are finite sequences of variables thought to range\\nover functionals of a finite type determined by the type of the\\nvariable. Intuitively,   is a concrete analogue of\\nthe abstract notion of a construction constituting the meaning of\\n .  \\nF  \\nx  \\nF  \\nx  \\ny  \\nz  \\nA  \\ny  \\nz  \\nx  \\nT  \\nA  \\ny  \\nF  \\nGödel’s theorem is as follows:  \\n.\\n \\nSuppose  ′ =\\n∃ ∀ ( ,\\n ,  ). If   is provable in\\nintuitionistic first order arithmetic, then there are computable\\nfunctionals   of finite type such that\\n ( ( ),  ,\\n ) is provable in  .  \\nTheorem 13  \\nF  \\ny  \\nz  \\nA  \\ny  \\nz  \\nx  \\nF  \\nQ  \\nA  \\nQ  \\nx  \\nz  \\nx  \\nT  \\nThe proof is by induction on the structure of the proof of  \\nin intuitionistic first order arithmetic. (For a treatment of the\\nproof in detail, the reader is referred to Troelstra 1986.)  \\nF  \\nThe importance of the theorem for foundations cannot be\\n overstated. \\n A discussion of its generalizations, of ensuing work on functional\\ninterpretations stimulated by the theorem due to Kreisel, Tait,\\nHoward, Feferman and others; its foundational and philosophical\\nsignificance; and finally its relation particularly to the earlier,\\ninformal, proof interpretation, so-called, given by\\nHeyting-Kolmogorov, will not be attempted here. Accordingly the reader\\nis referred to the large literature on the subject, e.g., the\\nabovementioned Troelstra 1986, Tait 1967, Feferman 1993 and Avigad\\n& Feferman 1998. For interesting recent developments, e.g., in the\\narea of relating Gödel’s Dialectica interpretation and\\nKreisel’s modified realizability, see Oliva 2006. See also van\\nOosten 2008.  \\n[ ]  \\n21  \\nA remark concerning the philosophical context in which Gödel\\npresented his translation, namely finitism. The question addressed in\\nthe introduction to the paper is what   notions must\\nbe added to finitary mathematics in order to obtain a consistency\\nproof for arithmetic. Equivalently: what does the finitary view\\npresuppose, which must be given up in the light of the Second\\nIncompleteness Theorem, if the consistency proof is to be\\nobtained:  \\nabstract  \\nIn any case Bernays’ remark teaches us to distinguish two\\ncomponents of the finitary attitude; namely, first, the constructive\\nelement, which consists in our being allowed to speak of mathematical\\nobjects only insofar as we can exhibit them or actually produce them\\nby means of a construction; second, the specifically finitistic\\nelement, which makes the further demand that the objects about which\\nwe make statements, with which the constructions are carried out and\\nwhich we obtain by means of these constructions, are\\n‘intuitive’, that is, are in the last analysis\\nspatiotemporal arrangements of elements whose characteristics other\\nthan their identity or nonidentity are irrelevant.… It is the\\nsecond requirement that must be dropped. This fact has hitherto been\\ntaken into account by our adjoining to finitary mathematics parts of\\nintuitionistic logic and the theory of ordinals. In what follows we\\nshall show that, for the consistency proof of number theory, we can\\nuse, instead, the notion of computable function of finite type on the\\nnatural numbers and certain rather elementary principles of\\nconstruction for such functions. (Gödel 1990, p.245).  \\nAside from its technical contribution, then, Gödel’s\\n1958/72 is one of Gödel’s most important philosophical\\nworks; notable for its analysis of the nature of finitary mathematics,\\nas well as its analysis of the notions of “intuitive,” as\\nin “intuitive knowledge,” and that of abstract versus\\nconcrete evidence.  \\nIn the next section, we turn to Gödel’s philosophical\\nviews. But interested readers may wish to read a brief discussion\\nabout Gödel’s Nachlass, important source of philosophical\\nmaterial by Gödel:  \\nSupplement Document: Gödel’s Documents  \\n3. Gödel’s Philosophical Views  \\nGödel’s philosophical views can be broadly characterized by\\ntwo points of focus, or, in modern parlance, commitments. These are:\\nrealism, namely the belief that mathematics is a descriptive science\\nin the way that the empirical sciences are. The second commitment is\\nto a form of Leibnizian rationalism in philosophy; and in fact\\nGödel’s principal philosophical influences, in this regard\\nparticularly but also many others, were Leibniz, Kant and Husserl.\\n(For further discussion of how these philosophers influenced\\nGödel, see van Atten and Kennedy 2003.)  \\nThe terms “Gödel’s realism” and\\n“Gödel’s rationalism” must be prefaced with a\\ndisclaimer: there is no single view one could associate with each of\\nthese terms. Gödel’s realism underwent a complex\\ndevelopment over time, in both the nature of its ontological claims as\\nwell as in Gödel’s level of commitment to those claims.\\nSimilarly Gödel’s rationalism underwent a complex\\ndevelopment over time, from a tentative version of it at the\\nbeginning, to what was adjudged to be a fairly strong version of it in\\nthe 1950s. Around 1959 and for some time afterward Gödel fused\\nhis rationalistic program of developing exact philosophy with the\\nphenomenological method as developed by Husserl.  \\nWe examine these two strains of Gödel’s thinking below:  \\n3.1 Gödel’s Rationalism  \\nGödel’s rationalism has its roots in the Leibnizian thought\\nthat the world, not that which we immanently experience but that which\\nitself gives rise to immanent experience, is perfect and beautiful,\\nand therefore rational and ordered. Gödel’s justification\\nof this belief rests partly on an inductive generalization from the\\nperfection and beauty of mathematics:  \\nRationalism is connected with Platonism because it is directed to the\\nconceptual aspect rather than toward the (real) world. One uses\\ninductive evidence…Mathematics has a form of\\nperfection…We may expect that the conceptual world is perfect,\\nand, furthermore, that objective reality is beautiful, good, and\\nperfect. (Wang 1996, 9.4.18)  \\nOur total reality and total experience are beautiful and\\nmeaningful—this is also a Leibnizian thought. We should judge\\nreality by the little which we truly know of it. Since that part which\\nconceptually we know fully turns out to be so beautiful, the real\\nworld of which we know so little should also be beautiful.\\n(9.4.20)  \\nAlthough the roots of Gödel’s belief in rationalism are\\nmetaphysical in nature, his long-standing aspirations in that domain\\nhad always been practical ones. Namely, to develop exact methods in\\nphilosophy; to transform it into an exact science, or  , to use Husserl’s term.  \\nstrenge\\nWissenschaft  \\nWhat this means in practice is taking the strictest view possible of\\nwhat constitutes the   grounds for the acceptance\\nof an assertion; put another way, a level of rigor is aspired to in\\nphilosophical arguments approaching that which is found in\\nmathematical proofs. A formulation of the view—one which is\\nsomewhat phenomenologically colored (see below)—can be found in\\na document in the Gödel Nachlass. This is a fourteen item list\\nGödel drew up in about 1960, entitled “My Philosophical\\nViewpoint.” Two items on the list are relevant here:  \\ndialectical  \\nThere are systematic methods for the solution of all problems\\n(also art, etc.).  \\nThere is a scientific (exact) philosophy and theology, which deals\\nwith concepts of the highest abstractness; and this is also most\\nhighly fruitful for science.  \\n(The list was transcribed by Cheryl Dawson and was published in\\n , p. 316.)  \\nWang 1996  \\nGödel’s earlier conception of rationalism refers to\\nmathematical rigor and includes the concept of having a genuine proof,\\nand is therefore in some sense a more radical one than that to which\\nhe would later subscribe. One can see it at work at the end of the\\nGibbs lecture, after a sequence of arguments in favor of realism are\\ngiven:  \\nOf course I do not claim that the foregoing considerations amount to a\\nreal proof of this view about the nature of mathematics. The most I\\ncould assert would be to have disproved the nominalistic view, which\\nconsiders mathematics to consist solely in syntactical conventions and\\ntheir consequences. Moreover, I have adduced some strong arguments\\nagainst the more general view that mathematics is our own creation.\\nThere are, however, other alternatives to Platonism, in particular\\npsychologism and Aristotelian realism. In order to establish Platonic\\nrealism, these theories would have to be disproved one after the\\nother, and then it would have to be shown that they exhaust all\\npossibilities. I am not in a position to do this now; however I would\\nlike to give some indications along these lines. (Gödel 1995, p.\\n321–2).  \\n(For a penetrating analysis of this passage see Tait 2001.) Such an\\nanalysis must be based on conceptual analysis:  \\nI am under the impression that after sufficient clarification of the\\nconcepts in question it will be possible to conduct these discussions\\nwith mathematical rigour and that the result will then be…that\\nthe Platonistic view is the only one tenable. (Gödel 1995, p.\\n322).  \\nAlong with the methodological component, as can be seen from the items\\non Gödel’s list, there was also an “optimistic”\\ncomponent to Gödel’s rationalism: once the appropriate\\nmethods have been developed, philosophical problems such as, for\\nexample, those in ethics (e.g., item 9 on the list is: “Formal\\nrights comprise a real science.”) can be decisively solved. As\\nfor mathematical assertions, such as the Continuum Hypothesis in set\\ntheory, once conceptual analysis has been carried out in the right\\nway, that is, once the basic concepts, such as that of\\n“set,” have been completely clarified, the Continuum\\nHypothesis should be able to be decided.  \\nAlthough at the time of the Gibbs lecture the analogy in\\nGödel’s mind between philosophical and mathematical\\nreasoning may have been a very close one, Gödel’s view at\\nother periods was that the envisaged methods will not be mathematical\\nin nature. What was wanted was a general, informal science of\\nconceptual analysis.  \\nPhilosophy is more general than science. Already the theory of\\nconcepts is more general than mathematics…True philosophy is\\nprecise but not specialized.  \\nPerhaps the reason why no progress is made in mathematics (and there\\nare so many unsolved problems), is that one confines oneself to the\\next[ensional]—thence also the feeling of disappointment in the\\ncase of many theories, e.g., propositional logic and formalisation\\naltogether. (Wang 1996, 9.3.20,\\n 9.3.21)  \\n[ ]  \\n22  \\n(See notebook Max IV, p. 198 (Gödel Nachlaß, Firestone\\nLibrary, Princeton, item 030090). Transcription Cheryl Dawson;\\ntranslation from the German ours; amendment ours. Gödel’s\\ndating of Max IV indicates that it is from May 1941 to April 1942. See\\nalso Gödel’s letter to Bernays, Gödel 2003a, p.\\n283.)  \\nAn important source for understanding Gödel’s advance\\ntoward a general theory of concepts are Gödel’s remarks on\\nconceptual analysis published by Hao Wang in  .\\nIn remark 8.6.10 for example, Gödel expresses the belief that\\nextensionality fails for concepts, contrary to what he said in his\\n1944 “Russell’s Mathematical Logic,” a remark which\\nhe now wishes to retract:  \\nLogical Journey  \\nI do not (no longer) believe that generally sameness of range is\\nsufficient to exclude the distinctness of two concepts.  \\nIn some of Gödel’s later discussions another component of\\nconceptual analysis emerges, namely the project of finding the\\nso-called primitive terms or concepts, and their relations. These are\\nroughly terms or concepts which comprise a theoretical “starting\\npoint,” on the basis of their meaning being completely definite\\nand clear. For example, the concept of “the application of a\\nconcept to another concept” is a primitive term, along with\\n“force”. (Wang 1996, 9.1.29).  \\nHe spoke to Wang about the general project in 1972:  \\nPhenomenology is not the only approach. Another approach is to find a\\nlist of the main categories (e.g., causation, substance, action) and\\ntheir interrelations, which, however, are to be arrived at\\nphenomenologically. The task must be done in the right manner. (Wang\\n1996, 5.3.7).  \\nGödel spoke with Sue Toledo between 1972 and 1975 about the\\nproject of finding primitive terms, as well as other aspects of\\nphenomenology. See Toledo 2011. We discuss Gödel’s\\ninvolvement with phenomenology further in the supplementary document\\n  .  \\nGödel’s Turn to Phenomenology  \\nThe judgement levied upon Gödel’s rationalism by\\ncontemporary philosophers was a harsh one. (See for example Gödel\\n1995, pp. 303–4). Nevertheless Gödel himself remained\\noptimistic. As he commented to Wang:  \\nIt is not appropriate to say that philosophy as rigorous science is\\nnot realizable in the foreseeable future. Time is not the main factor;\\nit can happen anytime when the right idea appears. (Wang 1996,\\n4.3.14).  \\nGödel concluded his 1944 on a similarly optimistic note.  \\n3.2 Gödel’s Realism  \\nGödel’s realist views were formulated mostly in the context\\nof the foundations of mathematics and set theory.  \\nWe referred above the list “What I believe,” thought to\\nhave been written in 1960 or thereabouts. Out of 14 items, only two\\nrefer to realism, remarks 10 and 12:  \\nMaterialism is false.  \\nConcepts have an objective existence.  \\nGödel published his views on realism for the first time in his\\n1944. The following is one of his most quoted passages on the\\nsubject:  \\nClasses and concepts may, however, also be conceived as real objects,\\nnamely classes as “pluralities of things,” or as\\nstructures consisting of a plurality of things and concepts as the\\nproperties and relations of things existing independently of our\\ndefinitions and constructions.  \\nIt seems to me that the assumption of such objects is quite as\\nlegitimate as the assumption of physical bodies and there is quite as\\nmuch reason to believe in their existence. They are in the same sense\\nnecessary to obtain a satisfactory system of mathematics as physical\\nbodies are necessary for a satisfactory theory of our sense\\nperceptions and in both cases it is impossible to interpret the\\npropositions one wants to assert about these entities as propositions\\nabout the “data,” i.e., in the latter case the actually\\noccurring sense perceptions.  \\nGödel’s reference to the impossibility of interpreting\\nempirical laws, or more precisely, instantiations of them—the\\nstatements “one wants to assert,”—as statements\\nabout sense perceptions, is likely an endorsement of the (then)\\ncontemporary critique of phenomenalism. The critique was based on the\\nobservation that sense data are so inextricably bound up with the\\nconditions under which they are experienced, that no correspondence\\nbetween statements about those and the statements “we want to\\nassert” can be given (see Chisholm 1948 for example). More\\ngenerally Gödel was against verificationism, namely the idea that\\nthe meaning of a statement is its mode of verification.  \\nThe analogical point in the first part of the passage was amplified by\\nGödel in the draft manuscript “Is Mathematics a Syntax of\\nLanguage?”:  \\nIt is arbitrary to consider “This is red” an immediate\\ndatum, but not so to consider the proposition expressing modus ponens\\nor complete induction (or perhaps some simpler propositions from which\\nthe latter follows). (Gödel 1995, p. 359)  \\nSome writers have interpreted Gödel in this and similar passages\\npragmatically, attributing to him the view that because empirical\\nstatements are paradigmatic of successful reference, reference in the\\ncase of abstract concepts should be modelled causally. (See Maddy\\n1990.) Interpreting reference to   objects this way,\\nit is argued, addresses the main difficulty associated with realism,\\nthe problem how we can come to have knowledge of abstract objects.\\nOthers have argued that Gödel had no paradigm case in mind; that\\nfor him both the empirical and the abstract case are either equally\\nproblematic, or equally unproblematic. (See Tait 1986.) The latter\\nview is referred to as epistemological parity in van Atten and Kennedy\\n2003. (See also Kennedy and van Atten 2004.)  \\nabstract  \\nIn his 1947 “What is Cantor’s Continuum Problem?”,\\nGödel expounds the view that in the case of meaningful\\npropositions of mathematics, there is always a fact of the matter to\\nbe decided in a yes or no fashion. This is a direct consequence of\\nrealism, for if there exists a domain of mathematical objects or\\nconcepts, then any meaningful proposition concerning them must be\\neither true or\\n false. \\n The Continuum Hypothesis is Gödel’s example of a\\nmeaningful question. The concept “how many” leads\\n“unambiguously” to a definite meaning of the hypothesis,\\nand therefore it should be decidable—at least in principle. Most\\nstrikingly Gödel does not leave the matter there but goes on to\\noffer a practical strategy for determining the value of the continuum,\\nas well as the truth value of other axioms extending  .\\nSpecifically, he offers two criteria for their decidability: the first\\ninvolves conceptual analysis and is associated with Gödel’s\\nrationalistic program. (See the above section on Gödel’s\\nrationalism.) Secondly one must keep an eye on the so-called success\\nof the axiom, as a check or indicator of which direction to look to\\nfor the solution of its truth. For example, Gödel notes in the\\npaper that none of the consequences of the Axiom of Constructibility\\nare very plausible. It is, then, likely false. See Maddy 2011 and\\nKoellner 2014 for discussion of intrinsic vs extrinsic justifications\\nfor new axioms of set theory.  \\n[ ]  \\n23  \\nZFC  \\nFor further discussion of Gödel’s philosophical views see\\nthe supplementary documents:  \\nGödel’s Turn to Phenomenology  \\nand  \\nA Philosophical Argument About the Content of Mathematics  \\nBibliography  \\nPrimary Sources  \\nGödel’s Writings  \\nThe Gödel Nachlass is located at Firestone Library of Princeton\\nUniversity with the exception of Gödel’s preprint\\ncollection, which is housed at the library of the Institute for\\nAdvanced Study. The Nachlass itself is the property of the Institute\\nbut a microfilm copy of it may be purchased from Brill. All of\\nGödel’s published work, together with a large number of the\\nunpublished material from the Nachlass, together with a selection of\\nGödel’s correspondence is published in  .  \\nKurt Gödel,\\nCollected Works, Volumes I-V  \\nThe Collected Papers of Kurt Gödel  \\n1986,  .\\nS. Feferman, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort\\n(eds.), Oxford: Oxford University Press.  \\nCollected Works. I: Publications 1929–1936  \\n1990,  .\\nS. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van\\nHeijenoort (eds.), Oxford: Oxford University Press.  \\nCollected Works. II: Publications 1938–1974  \\n1995,  . S. Feferman, J. Dawson, S. Kleene, G. Moore, R.\\nSolovay, and J. van Heijenoort (eds.), Oxford: Oxford University\\nPress.  \\nCollected Works. III: Unpublished essays and\\nlectures  \\n2003a,  . S.\\nFeferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van\\nHeijenoort (eds.), Oxford: Oxford University Press.  \\nCollected Works. IV: Correspondence A-G  \\n2003b,  . S.\\nFeferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van\\nHeijenoort (eds.), Oxford: Oxford University Press.  \\nCollected Works. V: Correspondence H-Z  \\nSelected Works of Kurt Gödel  \\n[1929]  \\n“I”,  . Reprinted in Gödel 1986, pp. 60–101.  \\nDissertation, University of\\nVienna  \\n[1930]  \\n“Die Vollständigkeit der Axiome des\\nlogischen Funktionenkalküls”,  , 37: 349–360. Reprinted in Gödel\\n1986, pp. 102–123.  \\nMonatshefte für\\nMathematik und Physik  \\n[1931]  \\n“Über formal unentscheidbare Sätze\\nder Principia Mathematica und verwandter Systeme, I”,\\n , 38:\\n173–198. Reprinted in Gödel 1986, pp. 144–195.  \\nMonatshefte für Mathematik und Physik  \\n[1932]  \\n“Zum intuitionistischen\\nAussagenkalkül”,  , 69: 65–66. Reprinted in Gödel\\n1986, pp. 222–225.  \\nAnzeiger der Akademie der\\nWissenschaften in Wien  \\n[1933e]  \\n“Zur intuitionistischen Arithmetik und\\nZahlentheorie”,  , 4: 34–38. Reprinted in Gödel 1986, pp.\\n286–295.  \\nErgebnisse eines mathematischen\\nKolloquiums  \\n[1933f]  \\n“Eine Interpretation des intuitionistischen\\nAussagenkalküls”,   4, 39–40. Reprinted in Gödel 1986, pp.\\n300–301.  \\nErgebnisse eines mathematischen\\nKolloquiums  \\n[1933i]  \\n“Zum Entscheidungsproblem des logischen\\nFunctionenkalküls”,  , 40: 433–443. Reprinted in Gödel 1986, pp.\\n306–326.  \\nMonatshefte für Mathematik und\\nPhysik  \\n[*1933o]  \\n“The present situation in the foundations of\\nmathematics”, manuscript. Printed in Gödel 1995, pp.\\n45–53.  \\n[1934c]  \\nReview of Skolem (1933).  , 7: 193–194. Reprinted in\\nGödel 1986, pp. 379–380.  \\nZentralblatt für\\nMathematik und ihre Grenzgebiete  \\n[1936a]  \\n“Über die Länge von\\nBeweisen”,  ,\\n7: 23–24. Reprinted in Gödel 1986, pp. 395–399.  \\nErgebnisse eines mathematischen Kolloquiums  \\n[1939a]  \\n“Consistency proof for the generalized\\ncontinuum hypothesis”,  , 25: 220–224. Reprinted in Gödel\\n1990, pp. 28–32.  \\nProceedings of the National Academy\\nof Sciences, U.S.A.  \\n[1940]  \\n“The Consistency of the Continuum\\nHypothesis”,  , Volume 3,\\nPrinceton: Princeton University Press. Reprinted in Gödel 1990,\\npp. 33–101.  \\nAnnals of Mathematics Studies  \\n[*1941]  \\n“In what sense is intuitionistic logic\\nconstructive?”, lecture manuscript. Printed in Gödel 1995,\\npp. 189–200.  \\n[1944]  \\n“Russell’s mathematical logic”,\\n  (Library of Living\\nPhilosophers), P. Schilpp (ed.), New York: Tudor, 1951, pp.\\n123–153. Reprinted in Gödel 1990, pp. 119–141.  \\nThe Philosophy of Bertrand Russell  \\n[*1946/9-B2]  \\n“Some observations about the relationship\\nbetween theory of relativity and Kantian philosophy”,\\nmanuscript. Printed in Gödel 1995, pp. 230–246.  \\n[*1946/9-C1]  \\n“Some observations about the relationship\\nbetween theory of relativity and Kantian philosophy”,\\nmanuscript. Printed in Gödel 1995, pp. 247–259.  \\n[1947]  \\n“What is Cantor’s continuum\\nproblem?”,  , 54: 515–525.\\nReprinted in Gödel 1990, pp. 176–187.  \\nAmer. Math. Monthly  \\n[1949a]  \\n“A remark on the relationship between\\nrelativity theory and idealistic philosophy”,   (Library of Living Philosophers),\\nP. Schilpp (ed.), La Salle, IL: Open Court, 1949, pp. 555–562.\\nReprinted in Gödel 1990, pp. 202–207.  \\nAlbert\\nEinstein: Philosopher-Scientist  \\n[1949]  \\n“An Example of a New Type of Cosmological\\nSolutions of Einstein’s Field Equations of Gravitation,”\\n , 21: 447–450. Reprinted in\\nGödel 1990, pp. 190–198.  \\nReviews of Modern Physics  \\n[*1951]  \\n“Some basic theorems on the foundations of\\nmathematics and their implications”, lecture manuscript. Printed\\nin Gödel 1995, pp. 304–323.  \\n[*1953/9-III]  \\n“Is mathematics a syntax of language?”,\\nlecture manuscript. Printed in Gödel 1995, pp.\\n334–356.  \\n[*1953/9-V]  \\n“Is mathematics a syntax of language?,”\\nlecture manuscript. Printed in Gödel 1995, pp.\\n356–362.  \\n[1958]  \\n“Über eine bisher noch nicht\\nbenützte Erweiterung des finiten Standpunktes”,\\n , 12: 280–287. Reprinted in Gödel 1990,\\npp. 240–251.  \\nDialectica  \\n[*1961/?]  \\n“The modern development of the foundations of\\nmathematics in light of philosophy”, manuscript. Printed in\\nGödel 1995, pp. 374–387.  \\n[1964]  \\n“What is Cantor’s continuum\\nproblem? , revised version of Gödel 1947, in\\nBenacerraf, P. and Putnam, H. (eds.), 1983,  , Cambridge: Cambridge\\nUniversity Press. Reprinted in Gödel 1990, pp.\\n254–270.  \\n”  \\nPhilosophy of\\nmathematics: selected readings (2nd ed.)  \\n[*1970]  \\n“Ontological proof”, manuscript.\\nPrinted in Gödel 1995, pp. 403–404.  \\n[*1970a]  \\n“Some considerations leading to the probable\\nconclusion that the true power of the continuum is\\nℵ ”, manuscript. Printed in Gödel 1995,\\npp. 420–422.  \\n2  \\n[*1970b]  \\n“A proof of Cantor’s continuum\\nhypothesis from a highly plausible axioms about orders of\\ngrowth”, manuscript. Printed in Gödel 1995, pp.\\n422–423.  \\nSecondary Sources  \\nAvigad, J. and S. Feferman, 1998, “Gödel’s\\nFunctional (‘Dialectica’) Interpretation”, in\\n  (Studies in Logic and the\\nFoundations of Mathematics, Volume 137), Samuel Buss (ed.), Amsterdam:\\nNorth-Holland, pp. 337-405.  \\nHandbook of Proof Theory  \\nAwodey, S. and A. W. Carus, 2010, “Gödel and\\nCarnap”, in  ,\\nSolomon Feferman, Charles Parsons & Stephen G. Simpson (eds.),\\nCambridge: Cambridge University Press.  \\nKurt Gödel: Essays for his Centennial  \\nBaaz, M., and C. Papadimitriou, D.Scott, H. Putnam, and C. Harper\\n(eds.), 2011,  , Cambridge: Cambridge University Press.  \\nKurt Gödel and the Foundations of Mathematics:\\nHorizons of Truth  \\nBadesa, C., and P. Mancosu, and R. Zach, 2009, “The\\nDevelopment of Mathematical Logic from Russell to Tarski,\\n1900–1935”, in Leila Haaparanta (ed.),  . New York and Oxford: Oxford University\\nPress:318–470..  \\nThe History of\\nModern Logic  \\nBarwise, Jon (ed.), 1977,  \\n(Studies in Logic and the Foundations of Mathematics, Volume 90),\\nAmsterdam: North-Holland Publishing Co.  \\nHandbook of Mathematical Logic  \\nBehmann, Heinrich, 1922, “Beiträge, Algebra, Logik,\\ninsbesodere zum Entscheidungsproblem”,  , 86: 419–432.  \\nMathematische\\nAnnalen  \\nBenacerraf, P. and H. Putnam (eds.), 1983,  , Cambridge: Cambridge University\\nPress, 2nd edition.  \\nPhilosophy of\\nMathematics: Selected Readings  \\nBernays, Paul, 1926, “Axiomatische Untersuchung des\\nAussagen-Kalkuls der ‘Principia Mathematica’”,\\n , 25(1): 305–320.  \\nMathematisches Zeitschrift  \\nBezboruah, A., and J.C. Sheperdson, 1976,\\n“Gödel’s second incompleteness theorem for\\n\\\\(Q\\\\)”,  , 41 (2):\\n503–512.  \\nJournal of Symbolic Logic  \\nBolzano, Bernard, 1969,  , Sections\\n349–391, in  ,\\nReihe I/Band 13, edited and with an introduction by Jan Berg,\\nStuttgart-Bad Cannstatt: Frommann Holzboog.  \\nWissenschaftslehre  \\nBernard Bolzano — Gesamtausgabe  \\nBurgess, John, 2009, “”Intuitions of Three Kinds in\\nGödel’s Views on the Continuum“”, in\\n Kennedy, J. (ed.) Cambridge: Cambridge\\nUniversity Press, 2014.  \\nInterpreting Gödel  \\nBuss, Samuel R., 1994, “On Gödel’s Theorems on\\nLengths of Proofs. I. Number of Lines and Speedup for\\nArithmetics”,  , 59(3):\\n737–756.  \\nJournal of Symbolic Logic  \\nChisholm, R., 1948, “The Problem of Empiricism”,\\n , 45: 512–7.  \\nThe Journal of Philosophy  \\nCohen, Paul, 1963, “The Independence of the Continuum\\nHypothesis”,  , 50: 1143–1148.  \\nProceedings of the National Academy of Sciences\\nof the U.S.A.  \\nCrocco, G., 2003, “Gödel, Carnap and the Fregean\\nHeritage”,  , 27:\\n171–191.  \\nHistory and Philosophy of Logic  \\n–––, 2006, “Gödel on Concepts”,\\n , 137(1,2): 21–41.  \\nSynthese  \\nDawson, Jr., John W., 1997,  , Wellesley, MA: A. K. Peters, Ltd.  \\nLogical dilemmas: The Life and\\nWork of Kurt Gödel  \\nDehornoy, Patrick, 2004, “Progrès récents sur\\nl’hypothèse du continu (d’après\\nWoodin)”,  , 294: viii,\\n147–172.  \\nAstérisque  \\nDetlefsen, Michael, 1986,  , Dordrecht: D. Reidel.  \\nHilbert’s Program: An essay on\\nmathematical instrumentalism  \\n–––, 2001, “What Does Gödel’s\\nSecond theorem Say?”,  , 9(1):\\n37–71.  \\nPhilosophia Mathemathica  \\n–––, 2014, “Completeness and the Ends of\\nAxiomatization”, in  , Kennedy,\\nJ. (ed.) Cambridge: Cambridge University Press, 2014.  \\nInterpreting Gödel  \\nDreben, B. and J. van Heijenoort, 1986, “Introductory Note\\nto 1929, 1930 and 1930a”, in Gödel 1986, pp.\\n44–59.  \\nEdwards, Paul (ed.), 1967,  , New York: MacMillan.  \\nThe Encyclopedia of\\nPhilosophy  \\nEhrenfeucht, A. and J. Mycielski, 1971, “Abbreviating Proofs\\nby Adding New Axioms”,  , 77: 366–367.  \\nBulletin of the American Mathematical\\nSociety  \\nFeferman, Solomon, 1960/1961, “Arithmetization of\\nMetamathematics in a General Setting”,  , 49: 35–92.  \\nFundamenta\\nMathematicae  \\n–––, 1993, “Gödel’s Dialectica\\nInterpretation and Its Two-way Stretch”, in   (Lecture Notes in Computer Science, Volume\\n713), G. Gottlob, A. Leitsch, and D. Mundici (eds.), Berlin: Springer,\\npp. 23–40.  \\nComputational\\nLogic and Proof Theory  \\n–––, 1986, “Gödel’s Life and\\nWork”, in Gödel 1986, pp. 1–34.  \\n–––, 1988, “Hilbert’s Program\\nRelativized: Proof-Theoretical and Foundational Reductions”,\\n , 53: 364–384.  \\nJournal of Symbolic Logic  \\n–––, 1996, “Proof Theory”, in\\n , D. Borchrt (ed.),\\nNew York: MacMillan, pp. 466–469.  \\nThe Encyclopedia of Philosophy Supplement  \\nFeferman, S., and H. Friedman, P. Maddy, and J. Steel, 2000,\\n“Does Mathematics Need New Axioms?”,  , 6(4): 401–446.  \\nBulletin of\\nSymbolic Logic  \\nFeferman, S., C. Parsons, and S. Simpson (eds.), 2010,   (Lecture Notes in Logic,\\n33), Cambridge: Cambridge University Press.  \\nKurt\\nGödel: Essays for his Centennial  \\nFeigl, H. and A. Blumberg, 1931, “Logical Positivism. A New\\nMovement in European Philosophy”,  , 28: 281–296.  \\nJournal of\\nPhilosophy  \\nFloyd, J. and A. Kanamori, 2006, “How Gödel Transformed\\nSet Theory”,  , 53(4): 419–427.  \\nNotices of the American Mathematical\\nSociety  \\nFolina, Janet, 2014, “Gödel on How to Have your\\nMathematics and Know it Too”, in  , Kennedy, J. (ed.) Cambridge: Cambridge University\\nPress, 2014.  \\nInterpreting\\nGödel  \\nFøllesdal, Dagfinn, 1995, “Gödel and\\nHusserl”, in   (Synthese\\nLibrary, Volume 251), J. Hintikka (ed.), Dordrecht, Boston: Kluwer,\\npp. 427–446.  \\nFrom Dedekind to Gödel  \\nForeman, Matthew, 1998, “Generic Large Cardinals: New Axioms\\nfor Mathematics?”, in  , Extra\\nVolume, Proceedings of the International Congress of Mathematicians,\\nII, pp. 11–21\\n [ \\n (in compressed Postscript)].  \\nDocumenta Mathematica  \\navailable online  \\nFranks, Curtis, 2009, “The Autonomy of Mathematical\\nKnowledge: Hilbert’s Program Revisited”, Cambridge:\\nCambridge University Press.  \\n–––, 2011, “Stanley Tennenbaum’s\\nSocrates”, in  , Kennedy, J. and Kossak, R.,\\n(eds.), Lecture Notes in Logic, 36, Cambridge: Cambridge University\\nPress, 2011.  \\nSet Theory, Arithmetic and Foundations of\\nMathematics: Theorems, Philosophies  \\n–––, 2014, “Logical Completeness, Form and\\nContent: An Archaeology”, in  ,\\nKennedy, J. (ed.) Cambridge: Cambridge University Press, 2014.  \\nInterpreting Gödel  \\nGaifman, H., 2000, “What Godel’s Incompleteness Result\\nDoes and Does Not Show”,  , 97 (8):\\n462–471.  \\nJournal of Philosophy  \\nGarson, James, 2003, “Modal Logic”, in  , Fall 2003 Edition, Edward N.\\nZalta (ed.), URL =\\n < >.  \\nThe\\nStanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/fall2003/entries/logic-modal/  \\nGlivenko, V., 1929, “Sur quelques points de la logique de m.\\nBrouwer.”,  , 15: 183–188.  \\nAcadémie Royale de Belgique, Bulletin de\\nla Classe des Sciences  \\nGottwald, Siegfried, 2004, “Many-valued Logic”, in\\n , Winter 2004 Edition,\\nEdward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/win2004/entries/logic-manyvalued/  \\nGödel, Rudolf, 1983, “History of the Gödel\\nFamily”, Susan Simonsin (trans.), in Weingartner and Schmetterer\\n1987, pp. 11–27.  \\nHauser, Kai, 2006, “Gödel’s Program Revisited,\\nPart 1: the Turn to Phenomenology”,  , 12 (4): 529–590.  \\nBulletin of Symbolic\\nLogic  \\nHeyting, Arendt, 1930, “Die formalen Regeln der\\nintuitionistischen Logik”,  ,\\nII, pp. 42–56.  \\nSitzungsberichte der Preussischen\\nAkademie der Wissenschaften, physikalisch-mathematische Klasse  \\nHilbert, David, 1926, “Über das Unendliche”,\\n , 95: 161–190.  \\nMathematische Annalen  \\nHilbert, D. and W. Ackermann, 1928,  , Berlin: Springer-Verlag.  \\nGrundzüge der\\ntheoretischen Logik  \\nHilbert, D. and P. Bernays, 1934,  , Volume 1, Berlin: Springer-Verlag.  \\nGrundlagen der\\nMathematik  \\n–––, 1939,  ,\\nVolume II, Berlin: Springer-Verlag.  \\nGrundlagen der Mathematik  \\nHodges, Wilfrid, 2005, “Model Theory”, in  , Fall 2005 Edition, Edward N.\\nZalta (ed.), URL =\\n < >.  \\nThe\\nStanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/fall2005/entries/model-theory/  \\nHusserl, Edmund, 1911, “Philosophie als strenge\\nWissenschaft”,  , 1: 289–341.  \\nLogos  \\nJaśkowski, Stanisław, 1936, “Investigations into\\nthe System of Intuitionist Logic”,  , 34(2)\\n(1975): 117–120. (Translated by S. McCall from the French\\n“Rechereches sur le système de la logique\\nintuitioniste” in  , Volume VI, Hermann, Paris, 1936, pp.\\n58–61.)  \\nStudia Logica  \\nActes du Congrés International de\\nPhilosophie Scientifique  \\nJech, Thomas, 2003,  , (Springer Monographs in\\nMathematics), Berlin: Springer-Verlag. 3rd millennium edition, revised\\nand expanded.  \\nSet theory  \\nJensen, R. Björn, 1972, “The Fine Structure of the\\nConstructible Hierarchy” (with a section by Jack Silver),\\n , 4: 229–308; Erratum, 4\\n(1972): 443.  \\nAnnals of Mathematical Logic  \\nKanamori, Aki, 1996, “The Mathematical Development of Set\\ntheory from Cantor to Cohen.”  , 2(1): 1–71.  \\nBulletin of Symbolic\\nLogic  \\n–––, 2006, “Levy and Set Theory”,\\n , 140(3): 233–252.  \\nAnnals of Pure and Applied Logic  \\nKennedy, Juliette, 2006, “Incompleteness — A Book\\nReview,”  ,\\n53(4): 448–455.  \\nNotices of the American Mathematical Societ  \\n–––, 2011, “Gödel’s Thesis: An\\nAppreciation” in  , M. Baaz, C. Papadimitriou, D.\\nScott, H. Putnam, and C. Harper (eds.), Cambridge: Cambridge\\nUniversity Press 95–110.  \\nKurt Gödel and the Foundations of\\nMathematics: Horizons of Truth  \\n–––, 2013, “On Formalism Freeness:\\nImplementing Gödel’s 1946 Princeton Bicentennial\\nLecture”,  , 19(3):\\n351–393.  \\nBulletin of Symbolic Logic  \\n–––, 2014, “Gödel’s 1946\\nPrinceton Bicentennial Lecture: An Appreciation”, in\\n , Cambridge:\\nCambridge University Press.  \\nInterpreting Gödel: Critical Essays  \\nKennedy, Juliette (ed.), 2014,  , Cambridge: Cambridge University Press.  \\nInterpreting Gödel:\\nCritical Essays  \\nKennedy, J. and van Atten, M., 2003, “On the Philosophical\\nDevelopment of Kurt Gödel”,  , 9(4): 425–476. Reprinted in  , Solomon Feferman, Charles Parsons and\\nStephen G. Simpson (eds.), Cambridge: Cambridge University Press.  \\nBulletin of Symbolic\\nLogic  \\nKurt Gödel:\\nEssays for his Centennial  \\n–––, 2004, “Gödel’s Modernism:\\nOn Set-theoretic Incompleteness”,  , 25(2): 289–349. (See the Erratum in\\n , 26(1) (2005), page\\nfacing contents.)  \\nGraduate Faculty\\nPhilosophy Journal  \\nGraduate Faculty Philosophy Journal  \\n–––, 2009, “Gödel’s Modernism:\\nOn Set-theoretic Incompleteness, Revisited”, in  , S.\\nLinström, E. Palmgren, K. Segerberg, and V. Stoltenberg-Hansen\\n(eds.), Berlin: Springer: 303–356.  \\nLogicism,\\nIntuitionism and Formalism: What has become of them?  \\n–––, 2009, “Gödel’s\\nLogic”, in D. Gabbay and J. Woods (eds.),  , Volume 5,\\nAmsterdam: Elsevier: 449–509.  \\nThe Handbook of\\nthe History of Logic: Logic from Russell to Gödel  \\nKleene, S. C., 1987, “Gödel’s Impression on\\nStudents of Logic in the 1930s”, in Weingartner and Schmetterer\\n1987, pp. 49–64.  \\nKoellner, Peter, 2014, “Large Cardinals and\\nDeterminacy”,  \\n(Spring Edition), Edward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/spr2014/entries/large-cardinals-determinacy/  \\nKreisel, Georg, 1980, “Kurt Gödel, 28 April 1906\\n– 14 January 1978”,  , 26: 148–224. Corrigenda, 27 (1981): 697;\\nfurther corrigenda, 28 (1982): 697.  \\nBiographical Memoirs of Fellows of\\nthe Royal Society  \\n–––, 1988, “Review of Kurt Gödel:\\n , Volume I”,  , 29(1): 160–181.  \\nCollected works  \\nNotre Dame Journal of\\nFormal Logic  \\n–––, 1990, “Review of Kurt Gödel:\\n , Volume II”,  , 31(4): 602–641.  \\nCollected Works  \\nNotre Dame Journal of\\nFormal Logic  \\n–––, 1998, “Second Thoughts Around Some of\\nGödel’s Writings: A Non-academic Option”,\\n , 114(1): 99–160.  \\nSynthese  \\nKripke, Saul, 2009, “The collapse of the Hilbert program:\\nwhy a system cannot prove its own 1-consistency”,  , 15 (2): 229–231.  \\nBulletin\\nof Symbolic Logic  \\nKunen, Kenneth, 1983,  , (Studies in Logic and the Foundations of\\nMathematics, Volume 102), Amsterdam: North-Holland Publishing Co.\\nReprint of the 1980 original.  \\nSet Theory: An Introduction to\\nIndependence Proofs  \\nLöb, M. H., 1956, “Formal Systems of Constructive\\nMathematics”,  , 21:\\n63–75.  \\nJournal of Symbolic Logic  \\nLöwenheim, L., 1915, “Über Möglichkeiten im\\nRelativkalkül”,  , 76(4):\\n447–470.  \\nMathematische Annalen  \\nŁukasiewicz, Jan, 1970,  , (Studies in\\nLogic and the Foundations of Mathematics), L. Borkowski (ed.),\\nAmsterdam: North-Holland Publishing Co.  \\nSelected works  \\nMaddy, Penelope, 1990,  , New York:\\nClarendon Press.  \\nRealism in Mathematics  \\nMaddy, Penelope, 2011,  , Oxford:\\nOxford University Press.  \\nDefending the Axioms  \\nMal’cev, Anatoli Ivanovic, 1971,   (Studies in\\nLogic and the Foundations of Mathematics, Volume 66), translated,\\nedited, and provided with supplementary notes by Benjamin Franklin\\nWells, III, Amsterdam: North-Holland Publishing Co.  \\nThe Metamathematics of\\nAlgebraic Systems. Collected Papers: 1936–1967  \\nMancosu, Paolo, 1998,  , Oxford: Oxford\\nUniversity Press.  \\nFrom Brouwer to Hilbert. The Debate on\\nthe Foundations of Mathematics in the 1920s  \\n–––, 2004, “Review of Kurt Gödel,\\n , Volumes IV and V”,  , 45: 109–125.  \\nCollected Works  \\nNotre Dame\\nJournal of Formal Logic  \\nMartin, D.A., 2005, “Gödel’s Conceptual\\nRealism”,  , 11:\\n207–224.  \\nBulletin of Symbolic Logic  \\nMcKinsey, J. C. C. and A. Tarski, 1948, “Some Theorems About\\nthe Sentential Calculi of Lewis and Heyting”,  , 13: 1–15.  \\nJournal of\\nSymbolic Logic  \\nMostowski, Andrzej, 1949, “An Undecidable Arithmetical\\nStatement”,  , 36:\\n143–164.  \\nFundamenta Mathematicae  \\n–––, 1982,  , Westport, CT: Greenwood Press. Reprint of the 1952\\noriginal.  \\nSentences Undecidable in\\nFormalized Arithmetic: An Exposition of the Theory of Kurt\\nGödel  \\nOliva, Paulo, 2006, “Unifying Functional\\nInterpretations”,  ,\\n47(2): 263–290.  \\nNotre Dame Journal of Formal Logic  \\nParikh, Rohit, 1971, “Existence and Feasibility in\\nArithmetic”,  , 36:\\n494–508.  \\nJournal of Symbolic Logic  \\nParsons, Charles, 1995a, “Platonism and Mathematical\\nIntuition in Kurt Gödel’s Thought”,  , 1(1): 44–74.  \\nBulletin of\\nSymbolic Logic  \\n–––, 1995b, “Quine and Gödel on\\nAnalyticity”, in  , Cambridge:\\nCambridge University Press, pp. 297–313.  \\nOn Quine: New Essays  \\n–––, 2000, “Reason and Intuition”,\\n , 125(3): 299–315.  \\nSynthese  \\n–––, 2002, “Realism and the Debate on\\nImpredicativity, 1917–1944”, in  ,\\n(Lecture Notes in Logic, Volume 15), W. Sieg, R. Sommer, and C.\\nTalcott (eds.), Urbana, IL: Association of Symbolic Logic, pp.\\n372–389.  \\nReflections on the\\nFoundations of Mathematics: Essays in Honor of Solomon Feferman  \\n–––, 2010, “Gödel and Philosophical\\nIdealism” , 18 (2):\\n166–192.  \\nPhilosophia Mathematica  \\n–––, 2014, “Analyticity for\\nRealists”, in  , Kennedy, J.\\n(ed.) Cambridge: Cambridge University Press, 2014.  \\nInterpreting Gödel  \\nPoonen, Bjorn, 2014, “Undecidable Problems: A\\nSampler”, in  ,\\nCambridge: Cambridge University Press.  \\nInterpreting Gödel: Critical Essays  \\nPost, Emil L., 1921, “Introduction to a General Theory of\\nElementary Propositions”,  , 43(3): 163–185.  \\nAmerican Journal of\\nMathematics  \\nPudlák, Pavel, 1996, “On the lengths of proofs of\\nconsistency: a survey of results”,  , 2: 65-86.  \\nAnnals of the Kurt\\nGödel Society  \\nRaatikainen, P., 2005, “On the Philosophical Relevance of\\nGödel’s Incompleteness Theorems”,  , 59 (4): 513–534.  \\nRevue\\nInternationale de Philosophie  \\nRogers, Jr., Hartley, 1967,  , New York: McGraw-Hill Book Co.  \\nTheory of Recursive Functions and\\nEffective Computability  \\nRosser, J.B., 1936, “Extensions of Some Theorems of\\nGödel and Church”,  ,\\n1(3): 87–91.  \\nJournal of Symbolic Logic  \\nScott, Dana, 1961, “Measurable Cardinals and Constructible\\nSets”,   (Série des Science, Mathématiques,\\nAstronomiques et Physiques), 9: 521–524.  \\nBulleint de l’Academie Polonaise des\\nSciences  \\nShelah, Saharon, 2014, “Reflecting on Logical Dreams”,\\nin  , Cambridge:\\nCambridge University Press.  \\nInterpreting Gödel: Critical Essays  \\nSieg, Wilfried, 1988, “Hilbert’s Program Sixty Years\\nLater”,  , 53(2):\\n338–348.  \\nJournal of Symbolic Logic  \\n–––, 1990, “Relative Consistency and\\nAccessible Domains”,  , 84(2):\\n259–297.  \\nSynthese  \\n–––, 1999, “Hilbert’s Programs:\\n1917–1922”,  , 5(1):\\n1–44.  \\nBulletin of Symbolic Logic  \\n–––, 2006, “Gödel on\\nComputability”,  , 14:\\n189–207.  \\nPhilosophia Mathematica  \\nSierpinski, Wacław, 1947, “L’hypothèse\\ngénéralisée du continu et l’axiome du\\nchoix”,  , 34: 1–5.  \\nFundamenta Mathematicae  \\nSigmund, Karl, 2006, “Pictures at an Exhibition”,\\n , 53(4):\\n428–432.  \\nNotices of the American Mathematical Society  \\nSkolem, Thoralf, 1920, “Logisch-kombinatorische\\nUntersuchungen über die Erfüllbarkeit oder Beweisbarkeit\\nmathematischer Sätze nebst einem Theoreme über dichte\\nMengen”,  , I.  ,\\nNumber 4, pp. 1–36. Reprinted in Skolem 1970, pp.\\n103–136.  \\nSkrifter utgit av Videnskappsselskapet i\\nKristiania  \\nMatematisk-naturvidenskabelig klasse  \\n–––, 1923, “Einige Bemerkungen zur\\naxiomatischen Begründung der Mengenlehre”,\\n ,\\nHelsinki, pp. 217–232. Reprinted in Skolem 1970, pp.\\n137–152.  \\nMatematikerkongressen i Helsingfors den 4–7 Juli 1922, Den\\nfemte skandinaviska matematikerkongressen, Redogörelse  \\n–––, 1933, “Über die\\nUnmöglichkeit einer vollständigen Charakterisierung der\\nZahlenreihe mittels eines endlichen Axiomensystems”,  , 10: 73–82.  \\nNorsk\\nMatematisk forenings skrifter  \\n–––, 1970,  ,\\nJens Erik Fenstad (ed.), Oslo: Universitetsforlaget.  \\nSelected Works in Logic  \\nSmith, David Woodruff, 2005, “Phenomenology”, in\\n  (Winter Edition),\\nEdward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/win2005/entries/phenomenology/  \\nSolovay, Robert, 1990, “Introductory Note to 1938, 1939,\\n1939a, 1940”, in Gödel 1990, pp. 1–25.  \\nSteel, John, 2000, “Mathematics Needs New Axioms”,\\n , 6(4): 422–433.  \\nBulletin of Symbolic Logic  \\nSteel, John, 2014, “Gödel’s Program”, in\\n , Kennedy, J. (ed.) Cambridge:\\nCambridge University Press, 2014.  \\nInterpreting Gödel  \\nTait, William, 1967, “Intensional Interpretations of\\nFunctionals of Finite Type I,”  , 32(2): 198–212.  \\nJournal of Symbolic\\nLogic  \\n–––, 1981, “Finitism”,  , 78: 524–556. Reprinted in Tait 2005, pp.\\n21–42.  \\nJournal\\nof Philosophy  \\n–––, 1986, “Truth and Proof: The Platonism\\nof Mathematics”,  , 69(3): 341–370.\\nReprinted in Tait 2005, pp. 61–88.  \\nSynthese  \\n–––, 2001, “Gödel’s Unpublished\\nPapers on Foundations of Mathematics”,  , 9(1): 87–126. Reprinted in Tait 2005, pp.\\n276–313.  \\nPhilosophia\\nMathematica  \\n–––, 2002, “Remarks on Finitism”, in\\n  (Lecture Notes in Logic, Volume 15), W. Sieg, R.\\nSommer, and C. Talcott (eds.), Urbana, IL: Association of Symbolic\\nLogic, pp. 410–419. Reprinted in Tait 2005, pp.\\n43–53.  \\nReflections on the Foundations of Mathematics: Essays in Honor of\\nSolomon Feferman  \\n–––, 2005,   (Logic\\nand Computation in Philosophy), New York: Oxford University\\nPress.  \\nThe Provenance of Pure Reason:\\nEssays in the Philosophy of Mathematics and its History  \\n–––, 2006, “Gödel’s\\ncorrespondence on proof theory and constructive\\nmathematics” , 14 (1):\\n76–111.  \\nPhilosophia Mathematica  \\n–––, 2006, “Gödel’s\\ninterpretation of intuitionism”, , 14 (2): 208–228.  \\nPhilosophia\\nMathematica  \\nTaussky-Todd, Olga, 1983, “Remembrances of Kurt\\nGödel”, in Weingartner and Schmetterer 1987, pp.\\n29–41.  \\nTieszen, Richard, 1992, “Kurt Gödel and\\nPhenomenology”,  , 59(2):\\n176–194.  \\nPhilosophy of Science  \\n–––, 2002, “Gödel and the Intuition\\nof Concepts”,  , 133 (3): 363–391.  \\nSynthese  \\n–––, 2005,  , Cambridge: Cambridge University\\nPress.  \\nPhenomenology, Logic and the\\nPhilosophy of Mathematics  \\n–––, 2011,  , Oxford: Oxford University\\nPress.  \\nAfter Gödel: Platonism and\\nRationalism in Mathematics and Logic  \\nToledo, Sue, 2011, “Sue Toledo’s Notes of her\\nConversations with Kurt Gödel in 1972-5”, in   (Lecture Notes in Logic, 36), Kennedy, J. and\\nKossak, R., (eds.), Cambridge: Cambridge University Press,\\nforthcoming.  \\nSet\\nTheory, Arithmetic and Foundations of Mathematics: Theorems,\\nPhilosophies  \\nTragesser, Robert, 1977,  , Ithaca:\\nCornell University Press.  \\nPhenomenology and Logic  \\n–––, 1984,  , (Series: Modern European Philosophy), Cambridge:\\nCambridge University Press.  \\nHusserl and Realism in Logic and\\nMathematics  \\n–––, 1989, “Sense Perceptual Intuition,\\nMathematical Existence, and Logical Imagination”,  , 4(2): 154–194.  \\nPhilosphia\\nMathematica  \\nTroelstra, A. S., 1986, “Note to   and\\n ”, in Gödel 1990, pp. 217–241.  \\n1958  \\n1972  \\nTroelstra, A. S. (ed.), 1973,  , (Lecture Notes in\\nMathematics, Volume 344), Berlin: Springer-Verlag.  \\nMetamathematical Investigation\\nof Intuitionistic Arithmetic and Analysis  \\nTuring, A. M., 1937, “On Computable Numbers, with an\\nApplication to the Entscheidungsproblem”,   (Series 2), 42: 230–265.  \\nProceedings of the\\nLondon Mathematical Society  \\nvan Atten, Mark, 2005, “On Gödel’s Awareness of\\nSkolem’s Helsinki Lecture”,  , 26(4): 321–326.  \\nHistory and Philosophy of\\nLogic  \\n–––, 2006, “Two Draft Letters from\\nGödel on Self-knowledge of Reason”,  , 14(2): 255–261.  \\nPhilosophia\\nMathematica  \\n–––, 2015, “Essays on Gödel’s\\nReception of Leibniz, Husserl and Brouwer”, Springer.  \\nvan Heijenoort, J. (ed.), 1967,  , Cambridge, MA:\\nHarvard University Press.  \\nFrom Frege to Gödel: A\\nsourcebook in mathematical logic, 1879–1931  \\nvan Oosten, Jaap, 2008,   (Studies in Logic and Foundations of\\nMathematics: Volume 152), Amsterdam: Elsevier.  \\nRealizability: An Introduction to its\\nCategorical Side  \\nvon Neumann, John, 2005,   (History of Mathematics, Volume 27), foreword by P. Lax,\\nintroduction by Marina von Neumann Whitman, preface and introductory\\ncomments by Miklós Rédei (ed.), Providence, RI: American\\nMathematical Society.  \\nJohn von Neumann: Selected\\nLetters  \\nVäänänen, Jouko, 2014, “Multiverse Set Theory\\nand Absolutely Undecidable Propositions”, in  , J. Kennedy (ed.), Cambridge: Cambridge University\\nPress, 2014.  \\nInterpreting\\nGödel  \\nWang, Hao, 1957, “The Axiomatization of Arithmetic”,\\n , 22: 145–158.  \\nJournal of Symbolic Logic  \\n–––, 1973,  , London: Routledge.  \\nFrom Mathematics to\\nPhilosophy  \\n–––, 1981, “Some Facts about Kurt\\nGödel”,  , 46(3):\\n653–659.  \\nJournal of Symbolic Logic  \\n–––, 1987,  , Cambridge, MA: MIT Press.  \\nReflections on Kurt\\nGödel  \\n–––, 1993,  , New York: Dover Publications Inc., 2nd edition.  \\nPopular Lectures on Mathematical\\nLogic  \\n–––, 1996,   (Representation and Mind), Cambridge,\\nMA: MIT Press.  \\nA Logical Lourney: From\\nGödel to Philosophy  \\nWeingartner, P., and L. Schmetterer (eds.), 1987,  , (History of Logic,\\nNumber 4), Naples: Bibliopolis.  \\nGödel\\nRemembered: Salzburg 10–12 July 1983  \\nWilkie, Alex, and J.B. Paris, 1987, “On the scheme of\\ninduction for bounded arithmetic formulas”, 35:\\n261–302.  \\nWoodin, W. Hugh, 1988, “Supercompact Cardinals, Sets of\\nReals, and Weakly Homogeneous Trees”,  , 85(18):\\n6587–6591.  \\nProceedings of the\\nNational Academy of Sciences of the U.S.A.  \\n–––, 2001a, “The Continuum Hypothesis.\\nI”,  ,\\n48(6): 567–576.  \\nNotices of the American Mathematical Society  \\n–––, 2001b, “The Continuum Hypothesis.\\nII”,  ,\\n48(7): 681–690.  \\nNotices of the American Mathematical Society  \\n–––, 2002, “Correction: ‘The\\nContinuum Hypothesis. II’”,  , 49(1): 46.  \\nNotices of the American\\nMathematical Society  \\nYourgrau, Palle, 2005,  , New York: Basic Books.  \\nA World Without Time. The Forgotten\\nLegacy of Gödel and Einstein  \\nZach, Richard, 1999, “Completeness Before Post: Bernays,\\nHilbert, and the Development of Propositional Logic”,\\n , 5(3): 331–366.  \\nBulletin of Symbolic Logic  \\n–––, 2003, “Hilbert’s\\nProgram”, in  \\n(Fall Edition), Edward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/fall2003/entries/hilbert-program/'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Academic Tools'}, page_content='Academic Tools'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Academic Tools'}, page_content='.  \\nHow to cite this entry  \\nat the\\n  .  \\nPreview the PDF version of this entry  \\nFriends of the SEP Society  \\nat the Internet Philosophy Ontology Project (InPhO).  \\nLook up topics and thinkers related to this entry  \\nat  , with links to its database.  \\nEnhanced bibliography for this entry  \\nPhilPapers  \\nOther Internet Resources  \\nAvigad, Jeremy,\\n “ ”,\\n manuscript in PDF available online.  \\nGödel and the metamathematical tradition  \\nKoellner, Peter,\\n “ ”,\\n manuscript in PDF available online.  \\nTruth in Mathematics:The question of Pluralism  \\n.  \\nThe Bernays Project  \\nRelated Entries  \\n|\\n   |\\n   |\\n   |\\n   |\\n   |\\n   |\\n   |\\n   |\\n   |\\n   |\\n   |  \\nGödel, Kurt: incompleteness theorems  \\nHilbert, David: program in the foundations of mathematics  \\nHusserl, Edmund  \\nLeibniz, Gottfried Wilhelm  \\nmathematics, philosophy of: intuitionism  \\nmathematics, philosophy of: Platonism  \\nmodel theory  \\nmodel theory: first-order  \\nphenomenology  \\nrealism  \\nset theory  \\nset theory: continuum hypothesis  \\nset theory: large cardinals and determinacy'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Academic Tools', 'Header 3': 'Acknowledgments'}, page_content='Acknowledgments'),\n",
       " Document(metadata={}, page_content='This entry was very much improved by discussion and correspondence\\nwith the following: Aki Kanamori, who made helpful corrections and\\ncomments to section 2.4; Jouko Väänänen, whose\\nexpertise in all areas of mathematical logic the author benefited from\\nin a great many invaluable discussions regarding the material in\\nsection 2; my sub-editor Richard Zach, whose many important and\\nhelpful suggestions led to a vast improvement of this entry, and an\\nanonymous referee for helpful comments and corrections. The author is\\ngrateful to the NWO for their support during the last period of the\\nwriting of this entry, to the Institute for Advanced Study for their\\nhospitality during the writing of this entry, and to Marcia Tucker of\\nthe IAS and the Rare Books and Special Collections department of\\nFirestone Library for all of their assistance over the years .  \\nby\\n\\n \\n \\n< >  \\nCopyright © 2015  \\nJuliette Kennedy  \\njuliette kennedy helsinki fi  \\n.  \\n@  \\n.  \\nOpen access to the SEP is made possible by a world-wide funding initiative. \\n    The Encyclopedia Now Needs Your Support \\n    Please Read How You Can Help Keep the Encyclopedia Free  \\nEnd footer menu  \\n    End mirrors  \\n    End site credits'),\n",
       " Document(metadata={'Header 4': 'Browse'}, page_content='Browse'),\n",
       " Document(metadata={'Header 4': 'Browse'}, page_content=\"Table of Contents  \\nWhat's New  \\nRandom Entry  \\nChronological  \\nArchives\"),\n",
       " Document(metadata={'Header 4': 'About'}, page_content='About'),\n",
       " Document(metadata={'Header 4': 'About'}, page_content='Editorial Information  \\nAbout the SEP  \\nEditorial Board  \\nHow to Cite the SEP  \\nSpecial Characters  \\nAdvanced Tools  \\nAccessibility  \\nContact'),\n",
       " Document(metadata={'Header 4': 'Support SEP'}, page_content='Support SEP'),\n",
       " Document(metadata={'Header 4': 'Support SEP'}, page_content='Support the SEP  \\nPDFs for SEP Friends  \\nMake a Donation  \\nSEPIA for Libraries'),\n",
       " Document(metadata={'Header 4': 'Mirror Sites'}, page_content='Mirror Sites'),\n",
       " Document(metadata={}, page_content=\"View this site from another server:  \\nUSA (Main Site)  \\nPhilosophy, Stanford University  \\nInfo about mirror sites  \\nThe Stanford Encyclopedia of Philosophy is   by  , Department of Philosophy, Stanford University  \\ncopyright © 2023  \\nThe Metaphysics Research Lab  \\nLibrary of Congress Catalog Data: ISSN 1095-5054  \\n$('.dropdown-toggle').dropdown();\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://plato.stanford.edu/entries/goedel/\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\")\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text_from_url(url)\n",
    "\n",
    "html_header_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
