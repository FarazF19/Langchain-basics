# ğŸ§  LangChain Basics â€“ From Data to GenAI App

This repository demonstrates my journey into the **LangChain ecosystem**, where I explored the core building blocks needed to create **GenAI applications**. The project walks through the essential phases of:

- ğŸ”„ Data ingestion & transformation
- ğŸ“š Chunking and vectorizing documents
- ğŸ§  Embedding generation with **HuggingFace** & **OpenAI**
- ğŸ“¦ Using **Vectorstores** like **FAISS** and **ChromaDB**
- ğŸ” Building and using **retrievers**
- ğŸ¤– Creating a **basic RAG (Retrieval-Augmented Generation)** GenAI app

> ğŸ“Œ This project uses **LangChain**, **OpenAI GPT-4o**, **Chroma** and **FAISS** vectorstore for storing document embeddings.

---

## ğŸš€ What I Learned

âœ… Basics of **LangChain**: From ingestion to retrieval  
âœ… How to use **Ollama** for local LLMs like Llama 2 & Gemma  
âœ… Creating **document loaders** from websites  
âœ… Splitting text into chunks for embedding  
âœ… Using **OpenAI Embeddings**  
âœ… Storing & retrieving vectors with **FAISS** and **ChromaDB**  
âœ… Using retrievers in chains  
âœ… Building a **simple GenAI RAG app** using LangChain

---

## ğŸ› ï¸ Technologies Used

| Tool / Library         | Purpose                         |
| ---------------------- | ------------------------------- |
| `LangChain`            | Framework for GenAI apps        |
| `OpenAI GPT-4o`        | LLM used in the final chain     |
| `FAISS`, `ChromaDB`    | Vector databases for embeddings |
| `dotenv`               | Securely load API keys          |
| `Ollama` (optional)    | Run open-source LLMs locally    |
| `LangSmith` (optional) | For observability & tracing     |

---

## ğŸ“¦ Project Workflow

Here's the code breakdown in logical steps:

### 1. ğŸŒ Load Environment Variables

```python
import os
from dotenv import load_dotenv

load_dotenv()

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = os.getenv("LANGCHAIN_PROJECT")
2. ğŸ“° Data Ingestion from a Website
python
Copy
Edit
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://docs.smith.langchain.com/evaluation/tutorials/evaluation")
docs = loader.load()
3. âœ‚ï¸ Text Splitting
python
Copy
Edit
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
documents = text_splitter.split_documents(docs)
4. ğŸ§¬ Embedding Creation using OpenAI
python
Copy
Edit
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
5. ğŸ“š Storing Embeddings in FAISS Vector Store
python
Copy
Edit
from langchain_community.vectorstores import FAISS

vectordb = FAISS.from_documents(documents=documents, embedding=embeddings)
6. ğŸ” Search Similar Chunks
python
Copy
Edit
query = "Each datapoint should consist of, at the very least, the inputs to the application"
result = vectordb.similarity_search(query)
print(result[0].page_content)
7. ğŸ¤– LLM Setup for Response Generation
python
Copy
Edit
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o")
8. ğŸ”— Create Document Chain with a Prompt
python
Copy
Edit
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template("""
Answer the following question based on the content:
<context>
{context}
</context>
""")

document_chain = create_stuff_documents_chain(llm, prompt)
9. ğŸ§  Basic Document Invocation Example
python
Copy
Edit
from langchain_core.documents import Document

document_chain.invoke({
    "input": query,
    "context": [Document(page_content=result[0].page_content)]
})
10. ğŸ” Full Retrieval Chain Pipeline
python
Copy
Edit
retriever = vectordb.as_retriever()

from langchain.chains import create_retrieval_chain

retrieval_chain = create_retrieval_chain(retriever, document_chain)
response = retrieval_chain.invoke({"input": query})
print(response)
ğŸ“ Folder Structure
bash
Copy
Edit
â”œâ”€â”€ .env                     # API keys and project secrets
â”œâ”€â”€ main.py                  # Full code for ingestion to RAG app
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md                # This file
ğŸ“¸ Architecture

ğŸ§‘â€ğŸ’» Author
Muhammad Faraz
ğŸ’¼ AI Full Stack Developer
ğŸ”— Connect on LinkedIn

Iâ€™m currently diving deep into AI Agents, LLMOps, and GenAI frameworks. Open to collaboration and freelance/remote roles.

ğŸ“¬ Contact
Want to collaborate or hire? Feel free to connect!
```
